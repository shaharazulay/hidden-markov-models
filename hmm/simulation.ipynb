{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _chain import Chain, f_phi, f_psi\n",
    "from _chain_torch import Chain as ChainTorch\n",
    "from _loss import HingeLoss\n",
    "from _data_utils import ChainDataset, count_parameters\n",
    "\n",
    "from _chain_bp_loss import belief_propagation_cross_entropy_loss  # remove wheb ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Binary HMM "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> phi(x,_i y_i) represents the data term\n",
    ">>> phi(y_i, y_i+1) represents the smoothness term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = f_phi(b=[-0.8, 1])\n",
    "psi = f_psi(j=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50 # chain length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = Chain(length=T, phi=phi, psi=psi, possible_values=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_values = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.88 s, sys: 25.9 ms, total: 5.9 s\n",
      "Wall time: 5.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X_dataset = []\n",
    "y_dataset= []\n",
    "\n",
    "for i in range(N):\n",
    "    x = np.random.rand(T)\n",
    "    x_binary = 1 * (x > 0.5)\n",
    "    \n",
    "    chain.update_observed(x_binary)\n",
    "    y = chain.get_max_apostriori_beliefs()\n",
    "\n",
    "    X_dataset.append(x_binary)\n",
    "    y_dataset.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn to numpy arrays\n",
    "X_dataset = np.array([np.array(xi) for xi in X_dataset])\n",
    "y_dataset = np.array([np.array(yi) for yi in y_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2e0c6fd0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(1000)\n",
    "plot(X_dataset[i], 'o')\n",
    "plot(y_dataset[i] + 0.05, 'ro')\n",
    "legend(['observations', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    features = [\n",
    "        'x.current=' + str(x)\n",
    "    ]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(y):\n",
    "    return str(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for xseq, yseq in zip(X_dataset, y_dataset):\n",
    "    X_features = [extract_features(x_i) for x_i in xseq]\n",
    "    y_labels = [extract_labels(y_i) for y_i in yseq]\n",
    "    \n",
    "    X.append(X_features)\n",
    "    y.append(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 ms, sys: 3.43 ms, total: 219 ms\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0,\n",
    "    c2=0,  # regulate this up to 1 if needed\n",
    "    max_iterations=5000,\n",
    "    all_possible_transitions=True,\n",
    "    all_possible_states=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      4218\n",
      "           1      1.000     1.000     1.000      5782\n",
      "\n",
      "   micro avg      1.000     1.000     1.000     10000\n",
      "   macro avg      1.000     1.000     1.000     10000\n",
      "weighted avg      1.000     1.000     1.000     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:\n",
      "1      -> 1       316.777794\n",
      "0      -> 0       298.725545\n",
      "1      -> 0       -306.779830\n",
      "0      -> 1       -308.723509\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States:\n",
      "232.976842 1        x.current=1\n",
      "203.618869 0        x.current=0\n",
      "-203.618869 1        x.current=0\n",
      "-232.976842 0        x.current=1\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"States:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training MPNN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64 # len(X_train) # 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ChainDataset(X_train, y_train)\n",
    "testset = ChainDataset(X_test, y_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = Variable(torch.tensor([1.5]), requires_grad=True)\n",
    "b = Variable(torch.tensor([-.5, 1.]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([j, b], lr=init_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "hinge_loss = HingeLoss(margin=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChainTorch(length=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay_lr(optimizer, epoch):\n",
    "    lr = init_lr * (0.5 ** (epoch // 80))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 1.5,  b0: -0.5, b1: 1.0\n",
      "JGrad: tensor([-0.4982]),  bGrad: tensor([5.7505, 2.8125])\n",
      "J: 1.5999999046325684,  b0: -0.5999999642372131, b1: 0.9000000357627869\n",
      "JGrad: tensor([-1.3927]),  bGrad: tensor([2.3553, 2.1628])\n",
      "J: 1.6926288604736328,  b0: -0.6902185678482056, b1: 0.801517128944397\n",
      "JGrad: tensor([-1.8558]),  bGrad: tensor([-2.8567, -1.1779])\n",
      "J: 1.7872079610824585,  b0: -0.7268701791763306, b1: 0.749415934085846\n",
      "JGrad: tensor([-0.5595]),  bGrad: tensor([-6.4184, -7.6943])\n",
      "J: 1.8759561777114868,  b0: -0.7089552879333496, b1: 0.783065676689148\n",
      "JGrad: tensor([-0.7949]),  bGrad: tensor([-6.2253, -6.1950])\n",
      "J: 1.9641926288604736,  b0: -0.6661532521247864, b1: 0.8381059169769287\n",
      "JGrad: tensor([-1.2086]),  bGrad: tensor([1.2709, 0.7545])\n",
      "J: 2.0552518367767334,  b0: -0.6353617906570435, b1: 0.881698727607727\n",
      "JGrad: tensor([-0.8400]),  bGrad: tensor([3.2288, 2.1056])\n",
      "J: 2.1458959579467773,  b0: -0.6234073042869568, b1: 0.9091455936431885\n",
      "JGrad: tensor([-0.2825]),  bGrad: tensor([6.3074, 3.3676])\n",
      "J: 2.2301647663116455,  b0: -0.6375615000724792, b1: 0.9174519777297974\n",
      "JGrad: tensor([-0.1267]),  bGrad: tensor([5.0581, 2.0008])\n",
      "J: 2.306993246078491,  b0: -0.6666457653045654, b1: 0.9161791801452637\n",
      "JGrad: tensor([0.0539]),  bGrad: tensor([6.0964, 2.5089])\n",
      "J: 2.374668598175049,  b0: -0.709561824798584, b1: 0.9047043919563293\n",
      "JGrad: tensor([-0.4003]),  bGrad: tensor([2.1153, 0.5317])\n",
      "J: 2.441227436065674,  b0: -0.7541906833648682, b1: 0.8922463655471802\n",
      "JGrad: tensor([-0.5040]),  bGrad: tensor([-0.6888, -1.3322])\n",
      "J: 2.508246660232544,  b0: -0.7921597957611084, b1: 0.8865509033203125\n",
      "JGrad: tensor([-0.1825]),  bGrad: tensor([-1.7612, -2.9523])\n",
      ">>>\t epoch 1:: loss = 1.9345812797546387, validation loss = 2.147596597671509\n",
      "J: 2.571453809738159,  b0: -0.8207795023918152, b1: 0.8932730555534363\n",
      "JGrad: tensor([-0.1409]),  bGrad: tensor([-5.6006, -6.2640])\n",
      "J: 2.630739688873291,  b0: -0.8289156556129456, b1: 0.9208260774612427\n",
      "JGrad: tensor([-0.4684]),  bGrad: tensor([-4.5994, -4.7731])\n",
      "J: 2.691178560256958,  b0: -0.8231004476547241, b1: 0.96039217710495\n",
      "JGrad: tensor([-0.1911]),  bGrad: tensor([-2.9906, -3.9609])\n",
      "J: 2.7488858699798584,  b0: -0.8095759749412537, b1: 1.0078922510147095\n",
      "JGrad: tensor([-0.4736]),  bGrad: tensor([1.4672, 0.5479])\n",
      "J: 2.8081390857696533,  b0: -0.8014541268348694, b1: 1.049160361289978\n",
      "JGrad: tensor([-0.2429]),  bGrad: tensor([1.5099, 0.2016])\n",
      "J: 2.8656582832336426,  b0: -0.7983536124229431, b1: 1.0859662294387817\n",
      "JGrad: tensor([0.5754]),  bGrad: tensor([5.0404, 0.7941])\n",
      "J: 2.9079554080963135,  b0: -0.809415340423584, b1: 1.1167160272598267\n",
      "JGrad: tensor([-0.0122]),  bGrad: tensor([8.3037, 4.8163])\n",
      "J: 2.94661545753479,  b0: -0.8394671082496643, b1: 1.1278539896011353\n",
      "JGrad: tensor([-0.2558]),  bGrad: tensor([2.7743, 1.2993])\n",
      "J: 2.9858009815216064,  b0: -0.8735429048538208, b1: 1.1337440013885498\n",
      "JGrad: tensor([-0.2260]),  bGrad: tensor([2.3519, 1.1101])\n",
      "J: 3.025054454803467,  b0: -0.9103060960769653, b1: 1.1354634761810303\n",
      "JGrad: tensor([-0.4779]),  bGrad: tensor([-0.0018, -0.2249])\n",
      "J: 3.06817364692688,  b0: -0.9437747001647949, b1: 1.1377724409103394\n",
      "JGrad: tensor([-0.2315]),  bGrad: tensor([-2.0981, -2.5917])\n",
      "J: 3.1111440658569336,  b0: -0.9686885476112366, b1: 1.1484053134918213\n",
      "JGrad: tensor([-0.3987]),  bGrad: tensor([-1.5738, -1.5764])\n",
      "J: 3.1565661430358887,  b0: -0.9872227907180786, b1: 1.1632871627807617\n",
      "JGrad: tensor([0.7170]),  bGrad: tensor([ 3.0897, -0.8876])\n",
      ">>>\t epoch 2:: loss = 1.4172990322113037, validation loss = 1.4822076559066772\n",
      "J: 3.185281753540039,  b0: -1.0119646787643433, b1: 1.1798076629638672\n",
      "JGrad: tensor([-0.5299]),  bGrad: tensor([-4.6857, -3.8551])\n",
      "J: 3.2197532653808594,  b0: -1.0219078063964844, b1: 1.20720374584198\n",
      "JGrad: tensor([-0.0978]),  bGrad: tensor([-1.0866, -2.0014])\n",
      "J: 3.2527613639831543,  b0: -1.0281306505203247, b1: 1.2386412620544434\n",
      "JGrad: tensor([-0.3585]),  bGrad: tensor([-1.3975, -1.5117])\n",
      "J: 3.2886176109313965,  b0: -1.0301183462142944, b1: 1.2722371816635132\n",
      "JGrad: tensor([-0.7153]),  bGrad: tensor([-3.7894, -2.5687])\n",
      "J: 3.3323400020599365,  b0: -1.0219823122024536, b1: 1.311111330986023\n",
      "JGrad: tensor([-0.4354]),  bGrad: tensor([0.1866, 0.2543])\n",
      "J: 3.3790509700775146,  b0: -1.0150645971298218, b1: 1.3456610441207886\n",
      "JGrad: tensor([0.1007]),  bGrad: tensor([3.4078, 1.3945])\n",
      "J: 3.419904947280884,  b0: -1.017868161201477, b1: 1.3722519874572754\n",
      "JGrad: tensor([-0.1571]),  bGrad: tensor([6.3663, 4.0132])\n",
      "J: 3.4597373008728027,  b0: -1.0367169380187988, b1: 1.3822802305221558\n",
      "JGrad: tensor([0.0481]),  bGrad: tensor([5.9504, 3.3405])\n",
      "J: 3.495192766189575,  b0: -1.068338394165039, b1: 1.380046010017395\n",
      "JGrad: tensor([-0.3803]),  bGrad: tensor([1.1372, 0.8904])\n",
      "J: 3.53383469581604,  b0: -1.1000038385391235, b1: 1.374995231628418\n",
      "JGrad: tensor([-0.4598]),  bGrad: tensor([0.3453, 0.3679])\n",
      "J: 3.5766568183898926,  b0: -1.129727840423584, b1: 1.3691350221633911\n",
      "JGrad: tensor([-0.5794]),  bGrad: tensor([-0.8576, -0.1769])\n",
      "J: 3.625112533569336,  b0: -1.1545383930206299, b1: 1.3644131422042847\n",
      "JGrad: tensor([-0.6101]),  bGrad: tensor([-3.6392, -2.3925])\n",
      "J: 3.6790764331817627,  b0: -1.1673743724822998, b1: 1.3684746026992798\n",
      "JGrad: tensor([0.2699]),  bGrad: tensor([-0.6931, -2.2015])\n",
      ">>>\t epoch 3:: loss = 1.2818107604980469, validation loss = 1.2533966302871704\n",
      "J: 3.7233872413635254,  b0: -1.177227258682251, b1: 1.3798309564590454\n",
      "JGrad: tensor([0.2593]),  bGrad: tensor([-1.2892, -2.6771])\n",
      "J: 3.7590837478637695,  b0: -1.1827503442764282, b1: 1.3994052410125732\n",
      "JGrad: tensor([-0.4262]),  bGrad: tensor([-2.1126, -1.5767])\n",
      "J: 3.798827648162842,  b0: -1.1820929050445557, b1: 1.4226998090744019\n",
      "JGrad: tensor([-0.2508]),  bGrad: tensor([-1.4262, -1.4215])\n",
      "J: 3.839346408843994,  b0: -1.177636742591858, b1: 1.4488732814788818\n",
      "JGrad: tensor([-0.2461]),  bGrad: tensor([1.6989, 1.2595])\n",
      "J: 3.880520820617676,  b0: -1.1782279014587402, b1: 1.4681243896484375\n",
      "JGrad: tensor([-0.0099]),  bGrad: tensor([ 0.8818, -0.2167])\n",
      "J: 3.918153762817383,  b0: -1.1811953783035278, b1: 1.4864180088043213\n",
      "JGrad: tensor([-0.3287]),  bGrad: tensor([-1.5095, -1.0393])\n",
      "J: 3.9582149982452393,  b0: -1.179693579673767, b1: 1.5068199634552002\n",
      "JGrad: tensor([0.0844]),  bGrad: tensor([ 0.8589, -0.3432])\n",
      "J: 3.9930875301361084,  b0: -1.180739402770996, b1: 1.5266340970993042\n",
      "JGrad: tensor([-0.1566]),  bGrad: tensor([1.4673, 0.5851])\n",
      "J: 4.027666091918945,  b0: -1.1858410835266113, b1: 1.5424641370773315\n",
      "JGrad: tensor([-0.1776]),  bGrad: tensor([1.8809, 1.0120])\n",
      "J: 4.062384128570557,  b0: -1.1958256959915161, b1: 1.553036093711853\n",
      "JGrad: tensor([-0.0529]),  bGrad: tensor([2.1135, 0.8224])\n",
      "J: 4.094936847686768,  b0: -1.2109273672103882, b1: 1.5595225095748901\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([1.0641, 0.0419])\n",
      "J: 4.124533653259277,  b0: -1.227717638015747, b1: 1.5652574300765991\n",
      "JGrad: tensor([-0.0992]),  bGrad: tensor([2.2062, 1.3064])\n",
      "J: 4.153326034545898,  b0: -1.2493300437927246, b1: 1.5654253959655762\n",
      "JGrad: tensor([-0.2084]),  bGrad: tensor([0.3935, 0.0358])\n",
      ">>>\t epoch 4:: loss = 1.036010980606079, validation loss = 1.032915472984314\n",
      "J: 4.1834845542907715,  b0: -1.2701196670532227, b1: 1.5654388666152954\n",
      "JGrad: tensor([-0.0589]),  bGrad: tensor([1.2342, 0.3950])\n",
      "J: 4.212031364440918,  b0: -1.2926355600357056, b1: 1.5639015436172485\n",
      "JGrad: tensor([-0.0972]),  bGrad: tensor([-1.5423, -1.8127])\n",
      "J: 4.239871501922607,  b0: -1.308448076248169, b1: 1.569653868675232\n",
      "JGrad: tensor([-0.3930]),  bGrad: tensor([-2.8903, -2.2281])\n",
      "J: 4.272799015045166,  b0: -1.3140735626220703, b1: 1.5836355686187744\n",
      "JGrad: tensor([-0.1476]),  bGrad: tensor([-1.3080, -1.5173])\n",
      "J: 4.305624485015869,  b0: -1.315237045288086, b1: 1.6023130416870117\n",
      "JGrad: tensor([-0.1976]),  bGrad: tensor([-0.3730, -0.4386])\n",
      "J: 4.339362621307373,  b0: -1.3151605129241943, b1: 1.621023178100586\n",
      "JGrad: tensor([-0.4252]),  bGrad: tensor([-2.1100, -1.3231])\n",
      "J: 4.3783650398254395,  b0: -1.308651328086853, b1: 1.6432970762252808\n",
      "JGrad: tensor([-0.0756]),  bGrad: tensor([-0.8638, -1.0921])\n",
      "J: 4.4152984619140625,  b0: -1.30008864402771, b1: 1.6679115295410156\n",
      "JGrad: tensor([0.0023]),  bGrad: tensor([2.7445, 1.5781])\n",
      "J: 4.448774337768555,  b0: -1.3008273839950562, b1: 1.6837409734725952\n",
      "JGrad: tensor([0.0421]),  bGrad: tensor([ 0.4082, -0.4561])\n",
      "J: 4.478282451629639,  b0: -1.3027666807174683, b1: 1.6999768018722534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.1023]),  bGrad: tensor([1.7957, 0.5518])\n",
      "J: 4.502917766571045,  b0: -1.3101361989974976, b1: 1.7124183177947998\n",
      "JGrad: tensor([0.2590]),  bGrad: tensor([3.1324, 1.1437])\n",
      "J: 4.5197882652282715,  b0: -1.3265656232833862, b1: 1.7189198732376099\n",
      "JGrad: tensor([0.1367]),  bGrad: tensor([3.2135, 1.4280])\n",
      "J: 4.532197952270508,  b0: -1.3513963222503662, b1: 1.7188200950622559\n",
      "JGrad: tensor([-0.1407]),  bGrad: tensor([0.9647, 0.5508])\n",
      ">>>\t epoch 5:: loss = 0.8491638898849487, validation loss = 0.939270555973053\n",
      "J: 4.546440124511719,  b0: -1.3769423961639404, b1: 1.7164051532745361\n",
      "JGrad: tensor([-0.1192]),  bGrad: tensor([ 0.2330, -0.1349])\n",
      "J: 4.561903476715088,  b0: -1.4008517265319824, b1: 1.714788556098938\n",
      "JGrad: tensor([-0.3956]),  bGrad: tensor([-1.2562, -0.5641])\n",
      "J: 4.584341049194336,  b0: -1.4184967279434204, b1: 1.715739369392395\n",
      "JGrad: tensor([-0.3206]),  bGrad: tensor([-3.4193, -2.6630])\n",
      "J: 4.6115217208862305,  b0: -1.4234486818313599, b1: 1.727973461151123\n",
      "JGrad: tensor([0.1906]),  bGrad: tensor([-0.0412, -1.0421])\n",
      "J: 4.632002830505371,  b0: -1.4278063774108887, b1: 1.743530035018921\n",
      "JGrad: tensor([-0.1990]),  bGrad: tensor([0.6086, 0.4090])\n",
      "J: 4.654886245727539,  b0: -1.4337254762649536, b1: 1.7558603286743164\n",
      "JGrad: tensor([-0.1763]),  bGrad: tensor([-0.0851, -0.2995])\n",
      "J: 4.679478645324707,  b0: -1.4388140439987183, b1: 1.768343448638916\n",
      "JGrad: tensor([-0.2467]),  bGrad: tensor([1.2035, 1.0270])\n",
      "J: 4.707165718078613,  b0: -1.4473683834075928, b1: 1.7751381397247314\n",
      "JGrad: tensor([-0.3223]),  bGrad: tensor([-0.1146,  0.0594])\n",
      "J: 4.7393059730529785,  b0: -1.45474374294281, b1: 1.7810347080230713\n",
      "JGrad: tensor([-0.1138]),  bGrad: tensor([-1.7824, -1.8093])\n",
      "J: 4.770958423614502,  b0: -1.455498456954956, b1: 1.7943671941757202\n",
      "JGrad: tensor([-0.2128]),  bGrad: tensor([-1.4419, -1.2911])\n",
      "J: 4.804365158081055,  b0: -1.4513719081878662, b1: 1.812166452407837\n",
      "JGrad: tensor([-0.0900]),  bGrad: tensor([1.5743, 0.8809])\n",
      "J: 4.836658000946045,  b0: -1.4529167413711548, b1: 1.8243366479873657\n",
      "JGrad: tensor([0.0164]),  bGrad: tensor([ 0.3795, -0.3627])\n",
      "J: 4.865545749664307,  b0: -1.455596923828125, b1: 1.8369959592819214\n",
      "JGrad: tensor([0.0348]),  bGrad: tensor([ 0.1872, -0.3169])\n",
      ">>>\t epoch 6:: loss = 0.5415428280830383, validation loss = 0.8883378505706787\n",
      "J: 4.890922546386719,  b0: -1.4586609601974487, b1: 1.8499006032943726\n",
      "JGrad: tensor([-0.1625]),  bGrad: tensor([0.7055, 0.4734])\n",
      "J: 4.917626857757568,  b0: -1.4638471603393555, b1: 1.8594281673431396\n",
      "JGrad: tensor([-0.0137]),  bGrad: tensor([1.4599, 0.5790])\n",
      "J: 4.942134857177734,  b0: -1.4735519886016846, b1: 1.8653974533081055\n",
      "JGrad: tensor([0.2992]),  bGrad: tensor([3.9480, 1.8271])\n",
      "J: 4.957321643829346,  b0: -1.4957268238067627, b1: 1.862377405166626\n",
      "JGrad: tensor([0.0495]),  bGrad: tensor([-0.8832, -1.3894])\n",
      "J: 4.9699201583862305,  b0: -1.5127650499343872, b1: 1.8660625219345093\n",
      "JGrad: tensor([0.0323]),  bGrad: tensor([-0.6326, -1.2480])\n",
      "J: 4.980570316314697,  b0: -1.5260049104690552, b1: 1.8751782178878784\n",
      "JGrad: tensor([-0.1611]),  bGrad: tensor([ 0.2030, -0.0370])\n",
      "J: 4.99401330947876,  b0: -1.538700819015503, b1: 1.88360595703125\n",
      "JGrad: tensor([-0.3986]),  bGrad: tensor([-1.3162, -0.5262])\n",
      "J: 5.01554536819458,  b0: -1.5455825328826904, b1: 1.8937036991119385\n",
      "JGrad: tensor([-0.0252]),  bGrad: tensor([-0.5413, -0.8740])\n",
      "J: 5.035641193389893,  b0: -1.5499093532562256, b1: 1.906958818435669\n",
      "JGrad: tensor([0.0620]),  bGrad: tensor([ 0.8320, -0.0732])\n",
      "J: 5.0523505210876465,  b0: -1.556766152381897, b1: 1.919307827949524\n",
      "JGrad: tensor([-0.4691]),  bGrad: tensor([-2.9277, -1.7028])\n",
      "J: 5.0785722732543945,  b0: -1.5525891780853271, b1: 1.938538908958435\n",
      "JGrad: tensor([-0.3512]),  bGrad: tensor([-0.1991,  0.1989])\n",
      "J: 5.110617160797119,  b0: -1.548100233078003, b1: 1.9549970626831055\n",
      "JGrad: tensor([0.1747]),  bGrad: tensor([1.5066, 0.1868])\n",
      "J: 5.135395050048828,  b0: -1.5494205951690674, b1: 1.9689968824386597\n",
      "JGrad: tensor([-0.0338]),  bGrad: tensor([2.7662, 1.7658])\n",
      ">>>\t epoch 7:: loss = 1.00124990940094, validation loss = 0.8020763993263245\n",
      "J: 5.158639430999756,  b0: -1.5604835748672485, b1: 1.973111629486084\n",
      "JGrad: tensor([0.1050]),  bGrad: tensor([2.2749, 1.0591])\n",
      "J: 5.177117824554443,  b0: -1.5785958766937256, b1: 1.9717075824737549\n",
      "JGrad: tensor([-0.1168]),  bGrad: tensor([-0.0118, -0.2780])\n",
      "J: 5.196690082550049,  b0: -1.5949469804763794, b1: 1.9717892408370972\n",
      "JGrad: tensor([-0.1600]),  bGrad: tensor([-1.4912, -1.4508])\n",
      "J: 5.218318462371826,  b0: -1.6043365001678467, b1: 1.9789395332336426\n",
      "JGrad: tensor([-0.2301]),  bGrad: tensor([-3.5139, -2.8001])\n",
      "J: 5.2435302734375,  b0: -1.6001118421554565, b1: 1.9989374876022339\n",
      "JGrad: tensor([-0.1667]),  bGrad: tensor([-0.3712, -0.4709])\n",
      "J: 5.270453929901123,  b0: -1.594946026802063, b1: 2.019327163696289\n",
      "JGrad: tensor([0.0315]),  bGrad: tensor([2.4277, 1.4343])\n",
      "J: 5.294032096862793,  b0: -1.5990866422653198, b1: 2.030710220336914\n",
      "JGrad: tensor([-0.0262]),  bGrad: tensor([3.0139, 1.9306])\n",
      "J: 5.316022872924805,  b0: -1.6137174367904663, b1: 2.031508684158325\n",
      "JGrad: tensor([-0.0188]),  bGrad: tensor([1.5675, 0.7571])\n",
      "J: 5.336392879486084,  b0: -1.6326262950897217, b1: 2.0285067558288574\n",
      "JGrad: tensor([0.1311]),  bGrad: tensor([1.2762, 0.1544])\n",
      "J: 5.351498126983643,  b0: -1.654369592666626, b1: 2.0250275135040283\n",
      "JGrad: tensor([0.0538]),  bGrad: tensor([ 0.5455, -0.0573])\n",
      "J: 5.363796234130859,  b0: -1.6760365962982178, b1: 2.0221643447875977\n",
      "JGrad: tensor([-0.2648]),  bGrad: tensor([-3.1773, -2.3847])\n",
      "J: 5.381643772125244,  b0: -1.6838754415512085, b1: 2.031421184539795\n",
      "JGrad: tensor([-0.3522]),  bGrad: tensor([-2.8635, -1.8565])\n",
      "J: 5.406707763671875,  b0: -1.6804546117782593, b1: 2.0489745140075684\n",
      "JGrad: tensor([-0.5799]),  bGrad: tensor([-3.0553, -1.5089])\n",
      ">>>\t epoch 8:: loss = 0.7693352699279785, validation loss = 0.7047955989837646\n",
      "J: 5.4438347816467285,  b0: -1.66621994972229, b1: 2.0723142623901367\n",
      "JGrad: tensor([0.2001]),  bGrad: tensor([-0.8356, -1.6424])\n",
      "J: 5.472280979156494,  b0: -1.650283932685852, b1: 2.1015398502349854\n",
      "JGrad: tensor([-0.1423]),  bGrad: tensor([0.6994, 0.4828])\n",
      "J: 5.501632213592529,  b0: -1.6384526491165161, b1: 2.125549793243408\n",
      "JGrad: tensor([0.0168]),  bGrad: tensor([3.1539, 2.0509])\n",
      "J: 5.527747631072998,  b0: -1.6394295692443848, b1: 2.136887311935425\n",
      "JGrad: tensor([-0.1497]),  bGrad: tensor([1.1479, 0.9675])\n",
      "J: 5.555210590362549,  b0: -1.6445538997650146, b1: 2.142268419265747\n",
      "JGrad: tensor([0.0479]),  bGrad: tensor([3.1731, 1.8938])\n",
      "J: 5.578804016113281,  b0: -1.6608606576919556, b1: 2.13759446144104\n",
      "JGrad: tensor([-0.0048]),  bGrad: tensor([2.6242, 1.5480])\n",
      "J: 5.600265979766846,  b0: -1.685222864151001, b1: 2.1255838871002197\n",
      "JGrad: tensor([0.0964]),  bGrad: tensor([1.4358, 0.4460])\n",
      "J: 5.61714506149292,  b0: -1.7125396728515625, b1: 2.112468957901001\n",
      "JGrad: tensor([0.1760]),  bGrad: tensor([ 0.4744, -0.6088])\n",
      "J: 5.627769947052002,  b0: -1.7390021085739136, b1: 2.103708028793335\n",
      "JGrad: tensor([-0.2750]),  bGrad: tensor([-0.8995, -0.4444])\n",
      "J: 5.644590854644775,  b0: -1.7595585584640503, b1: 2.098055839538574\n",
      "JGrad: tensor([-0.2490]),  bGrad: tensor([-2.4777, -1.8299])\n",
      "J: 5.6663408279418945,  b0: -1.7688121795654297, b1: 2.1023101806640625\n",
      "JGrad: tensor([-0.3173]),  bGrad: tensor([-1.6829, -1.0147])\n",
      "J: 5.694328308105469,  b0: -1.7708568572998047, b1: 2.1113507747650146\n",
      "JGrad: tensor([-0.1725]),  bGrad: tensor([-0.9556, -0.7809])\n",
      "J: 5.724182605743408,  b0: -1.7691090106964111, b1: 2.123535394668579\n",
      "JGrad: tensor([-0.1671]),  bGrad: tensor([-0.6414, -0.4990])\n",
      ">>>\t epoch 9:: loss = 0.6194500923156738, validation loss = 0.6974460482597351\n",
      "J: 5.755597114562988,  b0: -1.7651057243347168, b1: 2.1371254920959473\n",
      "JGrad: tensor([0.0170]),  bGrad: tensor([-0.5030, -0.8887])\n",
      "J: 5.783543586730957,  b0: -1.7595778703689575, b1: 2.1540069580078125\n",
      "JGrad: tensor([-0.2193]),  bGrad: tensor([-0.7744, -0.4316])\n",
      "J: 5.814650058746338,  b0: -1.7516316175460815, b1: 2.171511650085449\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([ 0.2006, -0.2295])\n",
      "J: 5.842731952667236,  b0: -1.7452162504196167, b1: 2.188534736633301\n",
      "JGrad: tensor([0.0724]),  bGrad: tensor([0.9858, 0.1888])\n",
      "J: 5.86615514755249,  b0: -1.7432080507278442, b1: 2.2029311656951904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.0762]),  bGrad: tensor([ 0.2267, -0.4170])\n",
      "J: 5.885254383087158,  b0: -1.7422677278518677, b1: 2.2181408405303955\n",
      "JGrad: tensor([0.2069]),  bGrad: tensor([3.2347, 1.6500])\n",
      "J: 5.896858215332031,  b0: -1.7538750171661377, b1: 2.2231338024139404\n",
      "JGrad: tensor([0.0647]),  bGrad: tensor([1.5793, 0.6858])\n",
      "J: 5.905574321746826,  b0: -1.7704459428787231, b1: 2.224010467529297\n",
      "JGrad: tensor([-0.0472]),  bGrad: tensor([ 0.0846, -0.1078])\n",
      "J: 5.914748191833496,  b0: -1.7857515811920166, b1: 2.2253763675689697\n",
      "JGrad: tensor([0.0656]),  bGrad: tensor([-0.0544, -0.5132])\n",
      "J: 5.921228885650635,  b0: -1.7993732690811157, b1: 2.2293519973754883\n",
      "JGrad: tensor([0.2264]),  bGrad: tensor([ 0.3254, -0.6783])\n",
      "J: 5.920814037322998,  b0: -1.8129554986953735, b1: 2.2365798950195312\n",
      "JGrad: tensor([-0.1727]),  bGrad: tensor([-1.5141, -1.1619])\n",
      "J: 5.925230026245117,  b0: -1.8192781209945679, b1: 2.249347686767578\n",
      "JGrad: tensor([-0.1067]),  bGrad: tensor([-0.3305, -0.3392])\n",
      "J: 5.932190895080566,  b0: -1.8236908912658691, b1: 2.2627153396606445\n",
      "JGrad: tensor([0.0132]),  bGrad: tensor([0.6325, 0.2027])\n",
      ">>>\t epoch 10:: loss = 0.686046302318573, validation loss = 0.6320117712020874\n",
      "J: 5.938113212585449,  b0: -1.8301767110824585, b1: 2.2736966609954834\n",
      "JGrad: tensor([-0.0153]),  bGrad: tensor([-0.2438, -0.4440])\n",
      "J: 5.943893909454346,  b0: -1.8350707292556763, b1: 2.2860333919525146\n",
      "JGrad: tensor([-0.1312]),  bGrad: tensor([-0.0173,  0.0772])\n",
      "J: 5.952813148498535,  b0: -1.8394241333007812, b1: 2.296759843826294\n",
      "JGrad: tensor([-0.1122]),  bGrad: tensor([-0.2473, -0.1968])\n",
      "J: 5.964041709899902,  b0: -1.8423690795898438, b1: 2.3075315952301025\n",
      "JGrad: tensor([0.0042]),  bGrad: tensor([ 0.2294, -0.1121])\n",
      "J: 5.974067687988281,  b0: -1.8459511995315552, b1: 2.3178820610046387\n",
      "JGrad: tensor([-0.1030]),  bGrad: tensor([-0.0723, -0.0873])\n",
      "J: 5.986058712005615,  b0: -1.8488962650299072, b1: 2.327716827392578\n",
      "JGrad: tensor([-0.1038]),  bGrad: tensor([0.9049, 0.7354])\n",
      "J: 5.9998579025268555,  b0: -1.8552157878875732, b1: 2.3325188159942627\n",
      "JGrad: tensor([-0.3524]),  bGrad: tensor([-0.9605, -0.1329])\n",
      "J: 6.022353649139404,  b0: -1.8570245504379272, b1: 2.337597370147705\n",
      "JGrad: tensor([-0.1591]),  bGrad: tensor([0.5907, 0.6740])\n",
      "J: 6.047225475311279,  b0: -1.8610643148422241, b1: 2.3384182453155518\n",
      "JGrad: tensor([-0.0471]),  bGrad: tensor([ 0.1224, -0.0566])\n",
      "J: 6.071052074432373,  b0: -1.8652145862579346, b1: 2.339477300643921\n",
      "JGrad: tensor([-0.0282]),  bGrad: tensor([1.8407, 1.2770])\n",
      "J: 6.093392372131348,  b0: -1.8764947652816772, b1: 2.3332574367523193\n",
      "JGrad: tensor([-0.2865]),  bGrad: tensor([-0.1129,  0.4058])\n",
      "J: 6.1218156814575195,  b0: -1.8862215280532837, b1: 2.3253512382507324\n",
      "JGrad: tensor([-0.0710]),  bGrad: tensor([0.5986, 0.4288])\n",
      "J: 6.149552345275879,  b0: -1.8974764347076416, b1: 2.315783977508545\n",
      "JGrad: tensor([0.0995]),  bGrad: tensor([-0.5425, -1.0981])\n",
      ">>>\t epoch 11:: loss = 0.941992998123169, validation loss = 0.6233569979667664\n",
      "J: 6.1717000007629395,  b0: -1.9053959846496582, b1: 2.3133819103240967\n",
      "JGrad: tensor([-0.2146]),  bGrad: tensor([-1.8584, -1.3480])\n",
      "J: 6.197946548461914,  b0: -1.9048278331756592, b1: 2.3188741207122803\n",
      "JGrad: tensor([0.0323]),  bGrad: tensor([-1.0220, -1.2868])\n",
      "J: 6.220708847045898,  b0: -1.9000639915466309, b1: 2.331148147583008\n",
      "JGrad: tensor([-0.1543]),  bGrad: tensor([-0.8960, -0.6272])\n",
      "J: 6.245793342590332,  b0: -1.8920241594314575, b1: 2.345810651779175\n",
      "JGrad: tensor([0.0705]),  bGrad: tensor([ 0.4968, -0.0179])\n",
      "J: 6.2663679122924805,  b0: -1.8868433237075806, b1: 2.3591578006744385\n",
      "JGrad: tensor([0.0668]),  bGrad: tensor([ 0.0353, -0.5050])\n",
      "J: 6.282970905303955,  b0: -1.8823117017745972, b1: 2.3741135597229004\n",
      "JGrad: tensor([0.1751]),  bGrad: tensor([1.4246, 0.3559])\n",
      "J: 6.29275369644165,  b0: -1.8842251300811768, b1: 2.3855671882629395\n",
      "JGrad: tensor([0.1459]),  bGrad: tensor([1.0361, 0.1104])\n",
      "J: 6.297239303588867,  b0: -1.890329360961914, b1: 2.3952736854553223\n",
      "JGrad: tensor([-0.1074]),  bGrad: tensor([1.3338, 1.0949])\n",
      "J: 6.304498672485352,  b0: -1.9014854431152344, b1: 2.3976755142211914\n",
      "JGrad: tensor([-0.2387]),  bGrad: tensor([0.5009, 0.6933])\n",
      "J: 6.3181867599487305,  b0: -1.9136887788772583, b1: 2.3958089351654053\n",
      "JGrad: tensor([-0.1146]),  bGrad: tensor([-0.1492, -0.0676])\n",
      "J: 6.333984375,  b0: -1.9240742921829224, b1: 2.3945178985595703\n",
      "JGrad: tensor([0.0990]),  bGrad: tensor([1.2897, 0.5170])\n",
      "J: 6.345267295837402,  b0: -1.9389574527740479, b1: 2.3903231620788574\n",
      "JGrad: tensor([-0.0621]),  bGrad: tensor([-0.7023, -0.7099])\n",
      "J: 6.3573317527771,  b0: -1.94938325881958, b1: 2.3907082080841064\n",
      "JGrad: tensor([0.1355]),  bGrad: tensor([ 0.7585, -0.0277])\n",
      ">>>\t epoch 12:: loss = 0.8080103397369385, validation loss = 0.5909026861190796\n",
      "J: 6.3641133308410645,  b0: -1.962058424949646, b1: 2.391219139099121\n",
      "JGrad: tensor([-0.1200]),  bGrad: tensor([-0.8153, -0.7120])\n",
      "J: 6.373883247375488,  b0: -1.9699828624725342, b1: 2.395890235900879\n",
      "JGrad: tensor([-0.0095]),  bGrad: tensor([-0.8366, -0.9094])\n",
      "J: 6.382997035980225,  b0: -1.9735156297683716, b1: 2.4054946899414062\n",
      "JGrad: tensor([-0.0667]),  bGrad: tensor([-1.2893, -1.1971])\n",
      "J: 6.3932671546936035,  b0: -1.9711095094680786, b1: 2.4212608337402344\n",
      "JGrad: tensor([-0.1373]),  bGrad: tensor([-0.3565, -0.2059])\n",
      "J: 6.406750679016113,  b0: -1.9673852920532227, b1: 2.4367244243621826\n",
      "JGrad: tensor([-0.2726]),  bGrad: tensor([-0.6305, -0.0481])\n",
      "J: 6.427270889282227,  b0: -1.9612702131271362, b1: 2.4509758949279785\n",
      "JGrad: tensor([0.1586]),  bGrad: tensor([0.9783, 0.1632])\n",
      "J: 6.440901756286621,  b0: -1.9600343704223633, b1: 2.4628663063049316\n",
      "JGrad: tensor([-0.2895]),  bGrad: tensor([0.5670, 0.9436])\n",
      "J: 6.462100982666016,  b0: -1.9614086151123047, b1: 2.4679205417633057\n",
      "JGrad: tensor([-0.0631]),  bGrad: tensor([-0.6920, -0.6266])\n",
      "J: 6.48319149017334,  b0: -1.959600806236267, b1: 2.476259231567383\n",
      "JGrad: tensor([0.0651]),  bGrad: tensor([1.0149, 0.3615])\n",
      "J: 6.500215530395508,  b0: -1.962451696395874, b1: 2.4816019535064697\n",
      "JGrad: tensor([-0.0595]),  bGrad: tensor([1.5235, 1.0967])\n",
      "J: 6.517436981201172,  b0: -1.9717628955841064, b1: 2.4797754287719727\n",
      "JGrad: tensor([-0.1278]),  bGrad: tensor([0.0096, 0.0564])\n",
      "J: 6.536967754364014,  b0: -1.9802130460739136, b1: 2.477783441543579\n",
      "JGrad: tensor([0.0083]),  bGrad: tensor([0.7266, 0.3153])\n",
      "J: 6.554342269897461,  b0: -1.9910751581192017, b1: 2.47406268119812\n",
      "JGrad: tensor([0.1233]),  bGrad: tensor([2.1346, 1.0690])\n",
      ">>>\t epoch 13:: loss = 0.8620755672454834, validation loss = 0.5671191215515137\n",
      "J: 6.566152095794678,  b0: -2.010359764099121, b1: 2.4641785621643066\n",
      "JGrad: tensor([-0.0681]),  bGrad: tensor([-1.1661, -1.0317])\n",
      "J: 6.578958034515381,  b0: -2.0225517749786377, b1: 2.4615793228149414\n",
      "JGrad: tensor([0.0185]),  bGrad: tensor([0.8002, 0.3423])\n",
      "J: 6.589935779571533,  b0: -2.0371365547180176, b1: 2.4571316242218018\n",
      "JGrad: tensor([-0.0428]),  bGrad: tensor([-0.7899, -0.8950])\n",
      "J: 6.60120153427124,  b0: -2.0467541217803955, b1: 2.458625555038452\n",
      "JGrad: tensor([0.0100]),  bGrad: tensor([-0.8113, -1.1020])\n",
      "J: 6.611053466796875,  b0: -2.0517821311950684, b1: 2.466763496398926\n",
      "JGrad: tensor([-0.0345]),  bGrad: tensor([-2.3261, -2.2309])\n",
      "J: 6.6210479736328125,  b0: -2.045839786529541, b1: 2.4877772331237793\n",
      "JGrad: tensor([-0.0671]),  bGrad: tensor([-0.2853, -0.3314])\n",
      "J: 6.6322150230407715,  b0: -2.0391876697540283, b1: 2.5087890625\n",
      "JGrad: tensor([-0.0541]),  bGrad: tensor([-0.8535, -0.8501])\n",
      "J: 6.644032001495361,  b0: -2.029322624206543, b1: 2.532993793487549\n",
      "JGrad: tensor([-0.2425]),  bGrad: tensor([-0.6294, -0.1182])\n",
      "J: 6.662467002868652,  b0: -2.0175626277923584, b1: 2.555577516555786\n",
      "JGrad: tensor([-0.1445]),  bGrad: tensor([-0.0118,  0.1252])\n",
      "J: 6.683750629425049,  b0: -2.006892442703247, b1: 2.5751869678497314\n",
      "JGrad: tensor([-0.1732]),  bGrad: tensor([1.5637, 1.4353])\n",
      "J: 6.708532333374023,  b0: -2.004403591156006, b1: 2.5839195251464844\n",
      "JGrad: tensor([0.4129]),  bGrad: tensor([3.0596, 1.0370])\n",
      "J: 6.717495441436768,  b0: -2.0160787105560303, b1: 2.585331678390503\n",
      "JGrad: tensor([0.0075]),  bGrad: tensor([2.1159, 1.3075])\n",
      "J: 6.725343227386475,  b0: -2.0362095832824707, b1: 2.578449249267578\n",
      "JGrad: tensor([0.2777]),  bGrad: tensor([ 0.9760, -0.2797])\n",
      ">>>\t epoch 14:: loss = 0.8167243003845215, validation loss = 0.5562950968742371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 6.723440647125244,  b0: -2.0588200092315674, b1: 2.573986291885376\n",
      "JGrad: tensor([-0.0096]),  bGrad: tensor([0.9237, 0.5224])\n",
      "J: 6.722034931182861,  b0: -2.0834403038024902, b1: 2.5666825771331787\n",
      "JGrad: tensor([-0.1537]),  bGrad: tensor([-0.1344,  0.0496])\n",
      "J: 6.725757122039795,  b0: -2.105048656463623, b1: 2.5597779750823975\n",
      "JGrad: tensor([-0.1000]),  bGrad: tensor([-0.9575, -0.8059])\n",
      "J: 6.732369899749756,  b0: -2.1201443672180176, b1: 2.5586307048797607\n",
      "JGrad: tensor([-0.3569]),  bGrad: tensor([-1.9740, -0.8814])\n",
      "J: 6.749921798706055,  b0: -2.124664783477783, b1: 2.563164234161377\n",
      "JGrad: tensor([-0.3615]),  bGrad: tensor([-0.7542,  0.0397])\n",
      "J: 6.777442455291748,  b0: -2.1252682209014893, b1: 2.567005157470703\n",
      "JGrad: tensor([-0.3904]),  bGrad: tensor([-2.0658, -0.9846])\n",
      "J: 6.814825534820557,  b0: -2.1162893772125244, b1: 2.5767176151275635\n",
      "JGrad: tensor([-0.0371]),  bGrad: tensor([-0.2807, -0.3503])\n",
      "J: 6.849774360656738,  b0: -2.1068880558013916, b1: 2.587712526321411\n",
      "JGrad: tensor([-0.0491]),  bGrad: tensor([1.0921, 0.6843])\n",
      "J: 6.882917404174805,  b0: -2.1034677028656006, b1: 2.5932652950286865\n",
      "JGrad: tensor([-0.2103]),  bGrad: tensor([-0.9716, -0.5436])\n",
      "J: 6.919658660888672,  b0: -2.0958709716796875, b1: 2.601752281188965\n",
      "JGrad: tensor([-0.0903]),  bGrad: tensor([-0.5981, -0.5001])\n",
      "J: 6.95576810836792,  b0: -2.0862314701080322, b1: 2.612617254257202\n",
      "JGrad: tensor([-0.0045]),  bGrad: tensor([ 0.1948, -0.0896])\n",
      "J: 6.98850679397583,  b0: -2.0784406661987305, b1: 2.622999906539917\n",
      "JGrad: tensor([0.2273]),  bGrad: tensor([1.3422, 0.1865])\n",
      "J: 7.010534763336182,  b0: -2.0776941776275635, b1: 2.631167411804199\n",
      "JGrad: tensor([0.0710]),  bGrad: tensor([0.9826, 0.2634])\n",
      ">>>\t epoch 15:: loss = 0.7412542104721069, validation loss = 0.5712352991104126\n",
      "J: 7.028071880340576,  b0: -2.0816266536712646, b1: 2.6368353366851807\n",
      "JGrad: tensor([0.1421]),  bGrad: tensor([0.8708, 0.0130])\n",
      "J: 7.0391950607299805,  b0: -2.0892651081085205, b1: 2.641866683959961\n",
      "JGrad: tensor([-0.2246]),  bGrad: tensor([-0.0636,  0.3256])\n",
      "J: 7.056649684906006,  b0: -2.0958592891693115, b1: 2.64428973197937\n",
      "JGrad: tensor([0.0471]),  bGrad: tensor([1.4709, 0.7511])\n",
      "J: 7.070838451385498,  b0: -2.1087427139282227, b1: 2.6415810585021973\n",
      "JGrad: tensor([0.0209]),  bGrad: tensor([ 0.3754, -0.0313])\n",
      "J: 7.082948684692383,  b0: -2.122145175933838, b1: 2.639341115951538\n",
      "JGrad: tensor([0.0122]),  bGrad: tensor([-0.2393, -0.4641])\n",
      "J: 7.093470096588135,  b0: -2.1331052780151367, b1: 2.6403603553771973\n",
      "JGrad: tensor([-0.1749]),  bGrad: tensor([-0.6183, -0.3443])\n",
      "J: 7.10880184173584,  b0: -2.1400537490844727, b1: 2.6435413360595703\n",
      "JGrad: tensor([0.2559]),  bGrad: tensor([ 0.6005, -0.4505])\n",
      "J: 7.114052772521973,  b0: -2.1491858959198, b1: 2.6493773460388184\n",
      "JGrad: tensor([-0.0204]),  bGrad: tensor([-0.0222, -0.2092])\n",
      "J: 7.119475841522217,  b0: -2.157320976257324, b1: 2.656024694442749\n",
      "JGrad: tensor([0.0171]),  bGrad: tensor([0.8898, 0.3709])\n",
      "J: 7.123795509338379,  b0: -2.168922185897827, b1: 2.6595680713653564\n",
      "JGrad: tensor([-0.1279]),  bGrad: tensor([0.6215, 0.5840])\n",
      "J: 7.132000923156738,  b0: -2.1823740005493164, b1: 2.65889048576355\n",
      "JGrad: tensor([0.1769]),  bGrad: tensor([-0.8247, -1.3817])\n",
      "J: 7.133427143096924,  b0: -2.190537691116333, b1: 2.667450189590454\n",
      "JGrad: tensor([-0.0475]),  bGrad: tensor([-0.3809, -0.4728])\n",
      "J: 7.136321067810059,  b0: -2.1960654258728027, b1: 2.6783182621002197\n",
      "JGrad: tensor([-0.2044]),  bGrad: tensor([-2.0199, -1.3585])\n",
      ">>>\t epoch 16:: loss = 0.6221907138824463, validation loss = 0.5064467191696167\n",
      "J: 7.145855903625488,  b0: -2.1912903785705566, b1: 2.69714617729187\n",
      "JGrad: tensor([-0.2883]),  bGrad: tensor([0.0301, 0.5442])\n",
      "J: 7.164211273193359,  b0: -2.187126874923706, b1: 2.7105000019073486\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.9153, -0.9719])\n",
      "J: 7.180789947509766,  b0: -2.178931951522827, b1: 2.7290306091308594\n",
      "JGrad: tensor([-0.1304]),  bGrad: tensor([-0.0310,  0.0683])\n",
      "J: 7.20018196105957,  b0: -2.171386241912842, b1: 2.7452943325042725\n",
      "JGrad: tensor([-0.2325]),  bGrad: tensor([-0.2944,  0.1062])\n",
      "J: 7.225578308105469,  b0: -2.163142442703247, b1: 2.759256601333618\n",
      "JGrad: tensor([0.1891]),  bGrad: tensor([3.2508, 1.7427])\n",
      "J: 7.2420148849487305,  b0: -2.171539545059204, b1: 2.7601165771484375\n",
      "JGrad: tensor([-0.1095]),  bGrad: tensor([-1.0072, -0.7338])\n",
      "J: 7.260589599609375,  b0: -2.174210548400879, b1: 2.7658255100250244\n",
      "JGrad: tensor([0.1376]),  bGrad: tensor([1.0033, 0.1759])\n",
      "J: 7.272623538970947,  b0: -2.1815109252929688, b1: 2.7697913646698\n",
      "JGrad: tensor([-0.0340]),  bGrad: tensor([0.7935, 0.5339])\n",
      "J: 7.284651279449463,  b0: -2.1919729709625244, b1: 2.769761800765991\n",
      "JGrad: tensor([0.1343]),  bGrad: tensor([1.3635, 0.4498])\n",
      "J: 7.290871620178223,  b0: -2.2080743312835693, b1: 2.7666890621185303\n",
      "JGrad: tensor([-0.0310]),  bGrad: tensor([0.4709, 0.2511])\n",
      "J: 7.297554969787598,  b0: -2.2249104976654053, b1: 2.7622125148773193\n",
      "JGrad: tensor([-0.0216]),  bGrad: tensor([1.3076, 0.8949])\n",
      "J: 7.3043317794799805,  b0: -2.2465097904205322, b1: 2.7520925998687744\n",
      "JGrad: tensor([-0.1241]),  bGrad: tensor([0.3999, 0.3733])\n",
      "J: 7.314748287200928,  b0: -2.2679662704467773, b1: 2.7404189109802246\n",
      "JGrad: tensor([-0.1470]),  bGrad: tensor([-3.4366, -2.6594])\n",
      ">>>\t epoch 17:: loss = 0.7941156625747681, validation loss = 0.5020128488540649\n",
      "J: 7.329249382019043,  b0: -2.2703418731689453, b1: 2.7479939460754395\n",
      "JGrad: tensor([-0.0383]),  bGrad: tensor([ 0.0136, -0.1128])\n",
      "J: 7.3436689376831055,  b0: -2.272552013397217, b1: 2.7555949687957764\n",
      "JGrad: tensor([0.1845]),  bGrad: tensor([ 0.4523, -0.3465])\n",
      "J: 7.350227355957031,  b0: -2.2767739295959473, b1: 2.7648117542266846\n",
      "JGrad: tensor([-0.3143]),  bGrad: tensor([-1.5797, -0.7282])\n",
      "J: 7.36708927154541,  b0: -2.2727885246276855, b1: 2.778090476989746\n",
      "JGrad: tensor([0.0700]),  bGrad: tensor([-0.1872, -0.6427])\n",
      "J: 7.379851818084717,  b0: -2.2682676315307617, b1: 2.7944588661193848\n",
      "JGrad: tensor([-0.2001]),  bGrad: tensor([-0.4005, -0.0250])\n",
      "J: 7.398357391357422,  b0: -2.262204885482788, b1: 2.8093984127044678\n",
      "JGrad: tensor([-0.1164]),  bGrad: tensor([-0.8826, -0.6437])\n",
      "J: 7.419129371643066,  b0: -2.2523560523986816, b1: 2.8272910118103027\n",
      "JGrad: tensor([0.0608]),  bGrad: tensor([ 0.3778, -0.0369])\n",
      "J: 7.435730934143066,  b0: -2.2453508377075195, b1: 2.8436877727508545\n",
      "JGrad: tensor([-0.1420]),  bGrad: tensor([-0.3484, -0.1104])\n",
      "J: 7.4557013511657715,  b0: -2.2372934818267822, b1: 2.8592429161071777\n",
      "JGrad: tensor([-0.1043]),  bGrad: tensor([1.7733, 1.4217])\n",
      "J: 7.4773945808410645,  b0: -2.2388877868652344, b1: 2.8634328842163086\n",
      "JGrad: tensor([-0.0168]),  bGrad: tensor([2.2661, 1.6190])\n",
      "J: 7.497561454772949,  b0: -2.2516236305236816, b1: 2.8560359477996826\n",
      "JGrad: tensor([-0.0922]),  bGrad: tensor([0.4834, 0.3680])\n",
      "J: 7.519021511077881,  b0: -2.2655282020568848, b1: 2.8468198776245117\n",
      "JGrad: tensor([-0.1241]),  bGrad: tensor([-0.1064,  0.0192])\n",
      "J: 7.542782306671143,  b0: -2.2775392532348633, b1: 2.8383724689483643\n",
      "JGrad: tensor([-0.0039]),  bGrad: tensor([1.7026, 1.1192])\n",
      ">>>\t epoch 18:: loss = 0.5788166522979736, validation loss = 0.4706079065799713\n",
      "J: 7.564355850219727,  b0: -2.2968931198120117, b1: 2.823000192642212\n",
      "JGrad: tensor([-0.1461]),  bGrad: tensor([-0.7874, -0.4809])\n",
      "J: 7.589017868041992,  b0: -2.3103909492492676, b1: 2.8124778270721436\n",
      "JGrad: tensor([-0.1592]),  bGrad: tensor([-0.7813, -0.4754])\n",
      "J: 7.616938591003418,  b0: -2.3186302185058594, b1: 2.8062992095947266\n",
      "JGrad: tensor([0.0489]),  bGrad: tensor([-0.8807, -1.0609])\n",
      "J: 7.6403727531433105,  b0: -2.321617603302002, b1: 2.8081300258636475\n",
      "JGrad: tensor([-0.0144]),  bGrad: tensor([-2.3631, -2.1415])\n",
      "J: 7.662030220031738,  b0: -2.312396287918091, b1: 2.824662446975708\n",
      "JGrad: tensor([-0.0253]),  bGrad: tensor([-0.6657, -0.7415])\n",
      "J: 7.682476997375488,  b0: -2.3007185459136963, b1: 2.844731569290161\n",
      "JGrad: tensor([-0.0148]),  bGrad: tensor([ 0.0032, -0.1558])\n",
      "J: 7.701456546783447,  b0: -2.2902002334594727, b1: 2.8639233112335205\n",
      "JGrad: tensor([-0.0231]),  bGrad: tensor([0.3612, 0.1317])\n",
      "J: 7.719412326812744,  b0: -2.2825443744659424, b1: 2.880314826965332\n",
      "JGrad: tensor([0.3587]),  bGrad: tensor([2.3197, 0.6964])\n",
      "J: 7.722599029541016,  b0: -2.287417411804199, b1: 2.890211582183838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.2279]),  bGrad: tensor([1.0552, 0.0270])\n",
      "J: 7.717237949371338,  b0: -2.2971670627593994, b1: 2.8989498615264893\n",
      "JGrad: tensor([0.1733]),  bGrad: tensor([1.3153, 0.3502])\n",
      "J: 7.706139087677002,  b0: -2.312638759613037, b1: 2.9043655395507812\n",
      "JGrad: tensor([-0.0881]),  bGrad: tensor([1.3688, 1.0761])\n",
      "J: 7.699322700500488,  b0: -2.333545684814453, b1: 2.9016599655151367\n",
      "JGrad: tensor([-0.0359]),  bGrad: tensor([-0.5672, -0.6434])\n",
      "J: 7.694479465484619,  b0: -2.349508762359619, b1: 2.9037632942199707\n",
      "JGrad: tensor([-0.0296]),  bGrad: tensor([1.6183, 1.1345])\n",
      ">>>\t epoch 19:: loss = 0.281697154045105, validation loss = 0.46097174286842346\n",
      "J: 7.691187858581543,  b0: -2.372145414352417, b1: 2.8976409435272217\n",
      "JGrad: tensor([-0.2259]),  bGrad: tensor([-1.6973, -1.0108])\n",
      "J: 7.696455001831055,  b0: -2.3838629722595215, b1: 2.899275779724121\n",
      "JGrad: tensor([-0.0734]),  bGrad: tensor([-1.0344, -0.8709])\n",
      "J: 7.70388650894165,  b0: -2.3891348838806152, b1: 2.90691876411438\n",
      "JGrad: tensor([0.1263]),  bGrad: tensor([1.2260, 0.4178])\n",
      "J: 7.705965518951416,  b0: -2.4001657962799072, b1: 2.910845994949341\n",
      "JGrad: tensor([-0.1374]),  bGrad: tensor([-2.8397, -2.1574])\n",
      "J: 7.712874412536621,  b0: -2.3955602645874023, b1: 2.9296391010284424\n",
      "JGrad: tensor([-0.3738]),  bGrad: tensor([-1.2712, -0.3117])\n",
      "J: 7.73275089263916,  b0: -2.384906768798828, b1: 2.9487998485565186\n",
      "JGrad: tensor([0.0637]),  bGrad: tensor([0.8304, 0.2926])\n",
      "J: 7.748342990875244,  b0: -2.379556894302368, b1: 2.964001417160034\n",
      "JGrad: tensor([-0.0268]),  bGrad: tensor([0.5884, 0.3380])\n",
      "J: 7.763391971588135,  b0: -2.377753973007202, b1: 2.975304126739502\n",
      "JGrad: tensor([0.0392]),  bGrad: tensor([-0.4178, -0.6822])\n",
      "J: 7.775521278381348,  b0: -2.3739776611328125, b1: 2.990361213684082\n",
      "JGrad: tensor([-0.1783]),  bGrad: tensor([-1.0401, -0.5978])\n",
      "J: 7.793023109436035,  b0: -2.3652122020721436, b1: 3.0082106590270996\n",
      "JGrad: tensor([-0.0753]),  bGrad: tensor([0.9072, 0.7479])\n",
      "J: 7.81158971786499,  b0: -2.3619942665100098, b1: 3.0189456939697266\n",
      "JGrad: tensor([-0.0532]),  bGrad: tensor([1.5758, 1.1930])\n",
      "J: 7.830305099487305,  b0: -2.367238759994507, b1: 3.020066976547241\n",
      "JGrad: tensor([-0.2911]),  bGrad: tensor([0.8301, 1.1924])\n",
      "J: 7.857913970947266,  b0: -2.3762643337249756, b1: 3.0125298500061035\n",
      "JGrad: tensor([-0.0225]),  bGrad: tensor([1.0783, 0.7159])\n",
      ">>>\t epoch 20:: loss = 0.7284221053123474, validation loss = 0.4526398479938507\n",
      "J: 7.883648872375488,  b0: -2.3899898529052734, b1: 3.0005953311920166\n",
      "JGrad: tensor([-0.0896]),  bGrad: tensor([1.5593, 1.2459])\n",
      "J: 7.910184383392334,  b0: -2.410442590713501, b1: 2.980901002883911\n",
      "JGrad: tensor([0.0239]),  bGrad: tensor([-0.5644, -0.7493])\n",
      "J: 7.933228015899658,  b0: -2.425952196121216, b1: 2.968538999557495\n",
      "JGrad: tensor([-0.0664]),  bGrad: tensor([-0.3286, -0.3554])\n",
      "J: 7.956485271453857,  b0: -2.4382286071777344, b1: 2.9599525928497314\n",
      "JGrad: tensor([0.1058]),  bGrad: tensor([-2.1603, -2.2344])\n",
      "J: 7.973500728607178,  b0: -2.438023090362549, b1: 2.9683024883270264\n",
      "JGrad: tensor([-0.0677]),  bGrad: tensor([-0.0347, -0.0174])\n",
      "J: 7.991382122039795,  b0: -2.437656879425049, b1: 2.975959300994873\n",
      "JGrad: tensor([-0.0794]),  bGrad: tensor([-1.4279, -1.1709])\n",
      "J: 8.01048755645752,  b0: -2.4298691749572754, b1: 2.9912893772125244\n",
      "JGrad: tensor([-0.1534]),  bGrad: tensor([-0.0853,  0.1366])\n",
      "J: 8.033469200134277,  b0: -2.4223990440368652, b1: 3.004129409790039\n",
      "JGrad: tensor([-0.0706]),  bGrad: tensor([0.0789, 0.0384])\n",
      "J: 8.056851387023926,  b0: -2.4160757064819336, b1: 3.015432596206665\n",
      "JGrad: tensor([-0.0408]),  bGrad: tensor([0.6153, 0.3804])\n",
      "J: 8.079477310180664,  b0: -2.413607120513916, b1: 3.0228683948516846\n",
      "JGrad: tensor([0.1164]),  bGrad: tensor([ 0.5797, -0.0952])\n",
      "J: 8.095476150512695,  b0: -2.414433002471924, b1: 3.030266523361206\n",
      "JGrad: tensor([0.1476]),  bGrad: tensor([1.3113, 0.4477])\n",
      "J: 8.104310989379883,  b0: -2.422088861465454, b1: 3.033679485321045\n",
      "JGrad: tensor([-0.0802]),  bGrad: tensor([0.5738, 0.4469])\n",
      "J: 8.115318298339844,  b0: -2.4320228099823, b1: 3.033498525619507\n",
      "JGrad: tensor([-0.2147]),  bGrad: tensor([0.5431, 0.8200])\n",
      ">>>\t epoch 21:: loss = 0.2582639157772064, validation loss = 0.4255719482898712\n",
      "J: 8.133378982543945,  b0: -2.443854331970215, b1: 3.027348756790161\n",
      "JGrad: tensor([0.0169]),  bGrad: tensor([0.4103, 0.0868])\n",
      "J: 8.14902400970459,  b0: -2.4566993713378906, b1: 3.021167755126953\n",
      "JGrad: tensor([-0.1356]),  bGrad: tensor([-1.7482, -1.3082])\n",
      "J: 8.168290138244629,  b0: -2.458991765975952, b1: 3.025176525115967\n",
      "JGrad: tensor([0.0215]),  bGrad: tensor([0.4352, 0.0842])\n",
      "J: 8.184845924377441,  b0: -2.463371753692627, b1: 3.028174638748169\n",
      "JGrad: tensor([-0.1761]),  bGrad: tensor([-0.2400,  0.0390])\n",
      "J: 8.206491470336914,  b0: -2.466043710708618, b1: 3.0305917263031006\n",
      "JGrad: tensor([-0.0218]),  bGrad: tensor([-0.7936, -0.7619])\n",
      "J: 8.226846694946289,  b0: -2.4642200469970703, b1: 3.038376808166504\n",
      "JGrad: tensor([0.0886]),  bGrad: tensor([ 0.0798, -0.3828])\n",
      "J: 8.241804122924805,  b0: -2.4630019664764404, b1: 3.0482184886932373\n",
      "JGrad: tensor([0.1380]),  bGrad: tensor([1.2531, 0.4396])\n",
      "J: 8.249982833862305,  b0: -2.468609571456909, b1: 3.0538456439971924\n",
      "JGrad: tensor([-0.0819]),  bGrad: tensor([-0.1942, -0.1817])\n",
      "J: 8.26050853729248,  b0: -2.472625255584717, b1: 3.060264825820923\n",
      "JGrad: tensor([0.0480]),  bGrad: tensor([0.5579, 0.1454])\n",
      "J: 8.268148422241211,  b0: -2.479243040084839, b1: 3.0649752616882324\n",
      "JGrad: tensor([0.1740]),  bGrad: tensor([ 6.6821e-04, -7.0043e-01])\n",
      "J: 8.268316268920898,  b0: -2.4852147102355957, b1: 3.074422597885132\n",
      "JGrad: tensor([0.1200]),  bGrad: tensor([1.7666, 0.8753])\n",
      "J: 8.263830184936523,  b0: -2.500100612640381, b1: 3.0764272212982178\n",
      "JGrad: tensor([0.0382]),  bGrad: tensor([-0.1971, -0.4860])\n",
      "J: 8.258304595947266,  b0: -2.5124614238739014, b1: 3.081854820251465\n",
      "JGrad: tensor([-0.0906]),  bGrad: tensor([-0.5606, -0.3865])\n",
      ">>>\t epoch 22:: loss = 0.3989016115665436, validation loss = 0.41450461745262146\n",
      "J: 8.256839752197266,  b0: -2.5205767154693604, b1: 3.089632749557495\n",
      "JGrad: tensor([-0.0816]),  bGrad: tensor([-0.5703, -0.4331])\n",
      "J: 8.25869083404541,  b0: -2.524806261062622, b1: 3.0998830795288086\n",
      "JGrad: tensor([-0.0505]),  bGrad: tensor([-1.2734, -1.1049])\n",
      "J: 8.262325286865234,  b0: -2.5217154026031494, b1: 3.1173789501190186\n",
      "JGrad: tensor([-0.1736]),  bGrad: tensor([0.7495, 0.8541])\n",
      "J: 8.272370338439941,  b0: -2.5229978561401367, b1: 3.1267473697662354\n",
      "JGrad: tensor([-0.0831]),  bGrad: tensor([0.2410, 0.1848])\n",
      "J: 8.284673690795898,  b0: -2.525465250015259, b1: 3.1338088512420654\n",
      "JGrad: tensor([-0.0315]),  bGrad: tensor([0.1986, 0.0461])\n",
      "J: 8.297001838684082,  b0: -2.5287723541259766, b1: 3.1398303508758545\n",
      "JGrad: tensor([-0.1866]),  bGrad: tensor([0.1516, 0.3933])\n",
      "J: 8.315417289733887,  b0: -2.5325822830200195, b1: 3.14229679107666\n",
      "JGrad: tensor([0.0330]),  bGrad: tensor([ 0.3000, -0.0207])\n",
      "J: 8.330730438232422,  b0: -2.537659168243408, b1: 3.1446774005889893\n",
      "JGrad: tensor([-0.0721]),  bGrad: tensor([-1.1011, -0.9319])\n",
      "J: 8.347370147705078,  b0: -2.5362024307250977, b1: 3.1538617610931396\n",
      "JGrad: tensor([-0.1065]),  bGrad: tensor([0.6527, 0.5919])\n",
      "J: 8.36656379699707,  b0: -2.538470506668091, b1: 3.1576626300811768\n",
      "JGrad: tensor([-0.1546]),  bGrad: tensor([-0.3817, -0.1685])\n",
      "J: 8.389955520629883,  b0: -2.538417339324951, b1: 3.162367343902588\n",
      "JGrad: tensor([0.0346]),  bGrad: tensor([0.7439, 0.2831])\n",
      "J: 8.40968132019043,  b0: -2.5424656867980957, b1: 3.164459228515625\n",
      "JGrad: tensor([-0.0744]),  bGrad: tensor([0.2140, 0.1512])\n",
      "J: 8.430411338806152,  b0: -2.5472970008850098, b1: 3.165194511413574\n",
      "JGrad: tensor([-0.0271]),  bGrad: tensor([0.7269, 0.4456])\n",
      ">>>\t epoch 23:: loss = 0.36595526337623596, validation loss = 0.3970683217048645\n",
      "J: 8.450180053710938,  b0: -2.555668830871582, b1: 3.162461042404175\n",
      "JGrad: tensor([-0.0105]),  bGrad: tensor([ 0.1046, -0.1046])\n",
      "J: 8.468423843383789,  b0: -2.5637972354888916, b1: 3.160795211791992\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([0.4266, 0.1426])\n",
      "J: 8.484926223754883,  b0: -2.5734920501708984, b1: 3.1582019329071045\n",
      "JGrad: tensor([0.1645]),  bGrad: tensor([-0.2011, -0.8329])\n",
      "J: 8.49323844909668,  b0: -2.5811166763305664, b1: 3.162245512008667\n",
      "JGrad: tensor([-0.0530]),  bGrad: tensor([-1.4426, -1.2187])\n",
      "J: 8.502848625183105,  b0: -2.5799612998962402, b1: 3.1752235889434814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0808]),  bGrad: tensor([-1.1791, -0.9572])\n",
      "J: 8.514744758605957,  b0: -2.5723562240600586, b1: 3.1942553520202637\n",
      "JGrad: tensor([-0.1151]),  bGrad: tensor([-0.0757,  0.0262])\n",
      "J: 8.530076026916504,  b0: -2.5650763511657715, b1: 3.211215019226074\n",
      "JGrad: tensor([-0.0649]),  bGrad: tensor([-0.0316, -0.0977])\n",
      "J: 8.546503067016602,  b0: -2.558335542678833, b1: 3.227259635925293\n",
      "JGrad: tensor([0.1158]),  bGrad: tensor([ 0.0732, -0.4075])\n",
      "J: 8.556657791137695,  b0: -2.5526673793792725, b1: 3.2448666095733643\n",
      "JGrad: tensor([0.0671]),  bGrad: tensor([0.6005, 0.1819])\n",
      "J: 8.5631103515625,  b0: -2.5509252548217773, b1: 3.2593371868133545\n",
      "JGrad: tensor([0.2197]),  bGrad: tensor([2.0430, 0.9035])\n",
      "J: 8.560070991516113,  b0: -2.560809373855591, b1: 3.2653865814208984\n",
      "JGrad: tensor([0.4424]),  bGrad: tensor([3.0666, 1.0898])\n",
      "J: 8.539603233337402,  b0: -2.5867981910705566, b1: 3.262402296066284\n",
      "JGrad: tensor([-0.2264]),  bGrad: tensor([-0.0267,  0.3956])\n",
      "J: 8.530259132385254,  b0: -2.6100828647613525, b1: 3.256645917892456\n",
      "JGrad: tensor([0.0646]),  bGrad: tensor([1.3030, 0.6478])\n",
      ">>>\t epoch 24:: loss = 0.4155260920524597, validation loss = 0.38822805881500244\n",
      "J: 8.51923656463623,  b0: -2.6383543014526367, b1: 3.246429681777954\n",
      "JGrad: tensor([-0.1218]),  bGrad: tensor([0.6141, 0.5682])\n",
      "J: 8.514204978942871,  b0: -2.6672847270965576, b1: 3.232804536819458\n",
      "JGrad: tensor([-0.2808]),  bGrad: tensor([-3.4871, -2.3358])\n",
      "J: 8.520974159240723,  b0: -2.6737287044525146, b1: 3.2386727333068848\n",
      "JGrad: tensor([-0.1186]),  bGrad: tensor([-1.3868, -0.9718])\n",
      "J: 8.531853675842285,  b0: -2.671788215637207, b1: 3.251486301422119\n",
      "JGrad: tensor([-0.1884]),  bGrad: tensor([-2.9018, -2.0890])\n",
      "J: 8.549248695373535,  b0: -2.6538915634155273, b1: 3.279118061065674\n",
      "JGrad: tensor([-0.2081]),  bGrad: tensor([-0.8221, -0.3074])\n",
      "J: 8.573305130004883,  b0: -2.6331777572631836, b1: 3.306408405303955\n",
      "JGrad: tensor([-0.1670]),  bGrad: tensor([0.4172, 0.5557])\n",
      "J: 8.601720809936523,  b0: -2.616833209991455, b1: 3.326700448989868\n",
      "JGrad: tensor([-0.1111]),  bGrad: tensor([1.4555, 1.2475])\n",
      "J: 8.631824493408203,  b0: -2.610248565673828, b1: 3.3352980613708496\n",
      "JGrad: tensor([-0.0593]),  bGrad: tensor([0.1308, 0.0651])\n",
      "J: 8.661367416381836,  b0: -2.60504412651062, b1: 3.3425445556640625\n",
      "JGrad: tensor([-0.0946]),  bGrad: tensor([1.4311, 1.2325])\n",
      "J: 8.691835403442383,  b0: -2.608374834060669, b1: 3.3394973278045654\n",
      "JGrad: tensor([0.1535]),  bGrad: tensor([1.2870, 0.4936])\n",
      "J: 8.713054656982422,  b0: -2.618591785430908, b1: 3.332911729812622\n",
      "JGrad: tensor([0.1656]),  bGrad: tensor([1.5110, 0.6311])\n",
      "J: 8.72543716430664,  b0: -2.6362688541412354, b1: 3.322061777114868\n",
      "JGrad: tensor([0.0434]),  bGrad: tensor([1.6296, 0.9944])\n",
      "J: 8.734832763671875,  b0: -2.6613283157348633, b1: 3.3045408725738525\n",
      "JGrad: tensor([-0.1880]),  bGrad: tensor([0.6205, 0.7885])\n",
      ">>>\t epoch 25:: loss = 0.3574571907520294, validation loss = 0.3850363790988922\n",
      "J: 8.750959396362305,  b0: -2.6874051094055176, b1: 3.282602548599243\n",
      "JGrad: tensor([-0.0033]),  bGrad: tensor([ 0.0512, -0.1077])\n",
      "J: 8.76563549041748,  b0: -2.711204767227173, b1: 3.2636642456054688\n",
      "JGrad: tensor([-0.2320]),  bGrad: tensor([-2.9066, -1.9427])\n",
      "J: 8.788322448730469,  b0: -2.7162423133850098, b1: 3.261808156967163\n",
      "JGrad: tensor([-0.2796]),  bGrad: tensor([-1.6720, -0.7856])\n",
      "J: 8.820141792297363,  b0: -2.711388349533081, b1: 3.266268014907837\n",
      "JGrad: tensor([-0.0384]),  bGrad: tensor([-2.0994, -1.7885])\n",
      "J: 8.850397109985352,  b0: -2.695241928100586, b1: 3.2842133045196533\n",
      "JGrad: tensor([-0.0474]),  bGrad: tensor([-1.1943, -1.0157])\n",
      "J: 8.879616737365723,  b0: -2.673987627029419, b1: 3.308295249938965\n",
      "JGrad: tensor([0.2989]),  bGrad: tensor([ 0.6986, -0.3725])\n",
      "J: 8.893659591674805,  b0: -2.658759593963623, b1: 3.332913875579834\n",
      "JGrad: tensor([0.0906]),  bGrad: tensor([0.6702, 0.1698])\n",
      "J: 8.902603149414062,  b0: -2.6488094329833984, b1: 3.353780746459961\n",
      "JGrad: tensor([0.3090]),  bGrad: tensor([1.2326, 0.0069])\n",
      "J: 8.897994995117188,  b0: -2.646796703338623, b1: 3.37253999710083\n",
      "JGrad: tensor([0.1782]),  bGrad: tensor([2.4715, 1.3232])\n",
      "J: 8.886542320251465,  b0: -2.6589019298553467, b1: 3.3790507316589355\n",
      "JGrad: tensor([0.2475]),  bGrad: tensor([2.2061, 0.9840])\n",
      "J: 8.866093635559082,  b0: -2.682194471359253, b1: 3.377196788787842\n",
      "JGrad: tensor([-0.1733]),  bGrad: tensor([0.8133, 0.9020])\n",
      "J: 8.854781150817871,  b0: -2.7077672481536865, b1: 3.368446111679077\n",
      "JGrad: tensor([-0.0805]),  bGrad: tensor([0.1867, 0.1248])\n",
      "J: 8.847890853881836,  b0: -2.7318761348724365, b1: 3.3595752716064453\n",
      "JGrad: tensor([-0.1948]),  bGrad: tensor([-2.8712, -2.0167])\n",
      ">>>\t epoch 26:: loss = 0.5105193257331848, validation loss = 0.360803484916687\n",
      "J: 8.849693298339844,  b0: -2.7373597621917725, b1: 3.367429256439209\n",
      "JGrad: tensor([0.1612]),  bGrad: tensor([-0.6968, -1.1912])\n",
      "J: 8.844686508178711,  b0: -2.7383763790130615, b1: 3.3838436603546143\n",
      "JGrad: tensor([-0.0165]),  bGrad: tensor([1.1622, 0.7790])\n",
      "J: 8.84085464477539,  b0: -2.745846748352051, b1: 3.392515182495117\n",
      "JGrad: tensor([-0.1535]),  bGrad: tensor([-0.2702,  0.0093])\n",
      "J: 8.843735694885254,  b0: -2.7510547637939453, b1: 3.4002599716186523\n",
      "JGrad: tensor([-0.0759]),  bGrad: tensor([0.8931, 0.7347])\n",
      "J: 8.849470138549805,  b0: -2.7608001232147217, b1: 3.4014525413513184\n",
      "JGrad: tensor([-0.2801]),  bGrad: tensor([-2.2238, -1.2752])\n",
      "J: 8.866193771362305,  b0: -2.7569949626922607, b1: 3.4125685691833496\n",
      "JGrad: tensor([-0.2105]),  bGrad: tensor([0.1624, 0.4823])\n",
      "J: 8.889945030212402,  b0: -2.754483938217163, b1: 3.418783664703369\n",
      "JGrad: tensor([-0.2289]),  bGrad: tensor([0.2088, 0.5715])\n",
      "J: 8.920783042907715,  b0: -2.753404140472412, b1: 3.4198713302612305\n",
      "JGrad: tensor([-0.1166]),  bGrad: tensor([0.0512, 0.1444])\n",
      "J: 8.953396797180176,  b0: -2.7527217864990234, b1: 3.4197092056274414\n",
      "JGrad: tensor([-0.0767]),  bGrad: tensor([0.1570, 0.1169])\n",
      "J: 8.98597240447998,  b0: -2.753000020980835, b1: 3.4186370372772217\n",
      "JGrad: tensor([-0.2268]),  bGrad: tensor([-1.4606, -0.7901])\n",
      "J: 9.02469539642334,  b0: -2.7449357509613037, b1: 3.4239392280578613\n",
      "JGrad: tensor([-0.0634]),  bGrad: tensor([0.4241, 0.3150])\n",
      "J: 9.062233924865723,  b0: -2.740084648132324, b1: 3.4262161254882812\n",
      "JGrad: tensor([-0.0767]),  bGrad: tensor([1.5131, 1.1580])\n",
      "J: 9.099259376525879,  b0: -2.7443480491638184, b1: 3.419062614440918\n",
      "JGrad: tensor([0.0101]),  bGrad: tensor([-1.5225, -1.4558])\n",
      ">>>\t epoch 27:: loss = 0.31666624546051025, validation loss = 0.3623284101486206\n",
      "J: 9.132218360900879,  b0: -2.7394981384277344, b1: 3.424191474914551\n",
      "JGrad: tensor([0.2212]),  bGrad: tensor([1.3370, 0.3710])\n",
      "J: 9.152677536010742,  b0: -2.742765426635742, b1: 3.425863027572632\n",
      "JGrad: tensor([0.3042]),  bGrad: tensor([1.7419, 0.4509])\n",
      "J: 9.15841293334961,  b0: -2.7556533813476562, b1: 3.4237775802612305\n",
      "JGrad: tensor([0.1522]),  bGrad: tensor([ 0.5129, -0.1418])\n",
      "J: 9.157240867614746,  b0: -2.7702040672302246, b1: 3.423029661178589\n",
      "JGrad: tensor([-0.0287]),  bGrad: tensor([-0.5883, -0.6149])\n",
      "J: 9.15738296508789,  b0: -2.779949188232422, b1: 3.427269220352173\n",
      "JGrad: tensor([0.1872]),  bGrad: tensor([-0.2798, -0.9327])\n",
      "J: 9.149693489074707,  b0: -2.7871289253234863, b1: 3.4385459423065186\n",
      "JGrad: tensor([0.0093]),  bGrad: tensor([-0.6429, -0.7411])\n",
      "J: 9.142374038696289,  b0: -2.7899060249328613, b1: 3.454638719558716\n",
      "JGrad: tensor([0.0424]),  bGrad: tensor([0.7400, 0.3199])\n",
      "J: 9.133999824523926,  b0: -2.796666383743286, b1: 3.4665796756744385\n",
      "JGrad: tensor([-0.1712]),  bGrad: tensor([-0.1770,  0.1185])\n",
      "J: 9.133631706237793,  b0: -2.801740884780884, b1: 3.4763922691345215\n",
      "JGrad: tensor([-0.1671]),  bGrad: tensor([0.9068, 0.9416])\n",
      "J: 9.14030933380127,  b0: -2.8115453720092773, b1: 3.477663040161133\n",
      "JGrad: tensor([-0.1595]),  bGrad: tensor([-0.4030, -0.0886])\n",
      "J: 9.153023719787598,  b0: -2.818054676055908, b1: 3.4795212745666504\n",
      "JGrad: tensor([-0.1844]),  bGrad: tensor([-0.7251, -0.3327])\n",
      "J: 9.172221183776855,  b0: -2.819725275039673, b1: 3.4838786125183105\n",
      "JGrad: tensor([-0.0387]),  bGrad: tensor([-0.0163, -0.1033])\n",
      "J: 9.191157341003418,  b0: -2.821136951446533, b1: 3.4886410236358643\n",
      "JGrad: tensor([-0.0271]),  bGrad: tensor([-0.3197, -0.3423])\n",
      ">>>\t epoch 28:: loss = 0.28233304619789124, validation loss = 0.333710253238678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 9.209370613098145,  b0: -2.8205533027648926, b1: 3.495701789855957\n",
      "JGrad: tensor([0.0232]),  bGrad: tensor([0.5717, 0.1518])\n",
      "J: 9.224807739257812,  b0: -2.8233513832092285, b1: 3.5008366107940674\n",
      "JGrad: tensor([-0.0323]),  bGrad: tensor([-0.3734, -0.3950])\n",
      "J: 9.240091323852539,  b0: -2.8236989974975586, b1: 3.508668899536133\n",
      "JGrad: tensor([-0.0363]),  bGrad: tensor([0.3835, 0.2351])\n",
      "J: 9.25540828704834,  b0: -2.82624888420105, b1: 3.5138189792633057\n",
      "JGrad: tensor([0.0264]),  bGrad: tensor([-0.2539, -0.4576])\n",
      "J: 9.268095016479492,  b0: -2.827064275741577, b1: 3.522183418273926\n",
      "JGrad: tensor([-0.1140]),  bGrad: tensor([0.3787, 0.3691])\n",
      "J: 9.284369468688965,  b0: -2.83001446723938, b1: 3.526715040206909\n",
      "JGrad: tensor([-0.0291]),  bGrad: tensor([0.5235, 0.2627])\n",
      "J: 9.30027961730957,  b0: -2.835740804672241, b1: 3.528655529022217\n",
      "JGrad: tensor([-0.0570]),  bGrad: tensor([ 0.0566, -0.0044])\n",
      "J: 9.317047119140625,  b0: -2.8412346839904785, b1: 3.5304410457611084\n",
      "JGrad: tensor([-0.1725]),  bGrad: tensor([-0.1497,  0.1528])\n",
      "J: 9.339507102966309,  b0: -2.8453073501586914, b1: 3.530799627304077\n",
      "JGrad: tensor([0.0520]),  bGrad: tensor([-0.8993, -1.0317])\n",
      "J: 9.357532501220703,  b0: -2.8436849117279053, b1: 3.5395729541778564\n",
      "JGrad: tensor([-0.1428]),  bGrad: tensor([0.2037, 0.3252])\n",
      "J: 9.379878044128418,  b0: -2.8434231281280518, b1: 3.544813394546509\n",
      "JGrad: tensor([0.1631]),  bGrad: tensor([ 0.4732, -0.1460])\n",
      "J: 9.39302921295166,  b0: -2.845979928970337, b1: 3.550736904144287\n",
      "JGrad: tensor([0.1345]),  bGrad: tensor([0.8279, 0.1710])\n",
      "J: 9.399115562438965,  b0: -2.8531763553619385, b1: 3.5546693801879883\n",
      "JGrad: tensor([0.1313]),  bGrad: tensor([ 0.3178, -0.2907])\n",
      ">>>\t epoch 29:: loss = 0.3184185028076172, validation loss = 0.32104846835136414\n",
      "J: 9.398969650268555,  b0: -2.861544370651245, b1: 3.5606095790863037\n",
      "JGrad: tensor([-0.0413]),  bGrad: tensor([0.2032, 0.1095])\n",
      "J: 9.400612831115723,  b0: -2.8702917098999023, b1: 3.5650603771209717\n",
      "JGrad: tensor([-0.1861]),  bGrad: tensor([-0.5142, -0.1242])\n",
      "J: 9.410090446472168,  b0: -2.8751230239868164, b1: 3.570098876953125\n",
      "JGrad: tensor([-0.2119]),  bGrad: tensor([0.1022, 0.4178])\n",
      "J: 9.42773151397705,  b0: -2.8800857067108154, b1: 3.571181058883667\n",
      "JGrad: tensor([-0.0620]),  bGrad: tensor([0.1669, 0.1054])\n",
      "J: 9.446300506591797,  b0: -2.8855528831481934, b1: 3.571282386779785\n",
      "JGrad: tensor([-0.1053]),  bGrad: tensor([-0.0103,  0.0213])\n",
      "J: 9.467573165893555,  b0: -2.8904199600219727, b1: 3.571197032928467\n",
      "JGrad: tensor([-0.1340]),  bGrad: tensor([-0.7629, -0.4015])\n",
      "J: 9.49251937866211,  b0: -2.890249252319336, b1: 3.5744590759277344\n",
      "JGrad: tensor([0.0027]),  bGrad: tensor([ 0.0604, -0.1585])\n",
      "J: 9.51488971710205,  b0: -2.8904569149017334, b1: 3.5787196159362793\n",
      "JGrad: tensor([0.1277]),  bGrad: tensor([-0.0921, -0.6060])\n",
      "J: 9.529520988464355,  b0: -2.890092372894287, b1: 3.5876119136810303\n",
      "JGrad: tensor([0.2043]),  bGrad: tensor([ 0.3775, -0.4109])\n",
      "J: 9.533851623535156,  b0: -2.89202880859375, b1: 3.599057197570801\n",
      "JGrad: tensor([0.2808]),  bGrad: tensor([2.1574, 0.8632])\n",
      "J: 9.525604248046875,  b0: -2.906700372695923, b1: 3.60215163230896\n",
      "JGrad: tensor([-0.0391]),  bGrad: tensor([-0.0772, -0.1186])\n",
      "J: 9.519862174987793,  b0: -2.919461965560913, b1: 3.605933427810669\n",
      "JGrad: tensor([0.0981]),  bGrad: tensor([ 0.3623, -0.0967])\n",
      "J: 9.5104341506958,  b0: -2.9331424236297607, b1: 3.6101531982421875\n",
      "JGrad: tensor([0.0132]),  bGrad: tensor([-3.6341, -3.1815])\n",
      ">>>\t epoch 30:: loss = 0.5413285493850708, validation loss = 0.3126058280467987\n",
      "J: 9.501362800598145,  b0: -2.9236626625061035, b1: 3.640336275100708\n",
      "JGrad: tensor([-0.0851]),  bGrad: tensor([-0.0617,  0.0002])\n",
      "J: 9.4968900680542,  b0: -2.914748430252075, b1: 3.66754150390625\n",
      "JGrad: tensor([-0.0655]),  bGrad: tensor([1.8572, 1.4723])\n",
      "J: 9.495709419250488,  b0: -2.917841672897339, b1: 3.6797709465026855\n",
      "JGrad: tensor([0.0317]),  bGrad: tensor([1.5920, 0.9992])\n",
      "J: 9.493261337280273,  b0: -2.9301538467407227, b1: 3.6824748516082764\n",
      "JGrad: tensor([-0.2153]),  bGrad: tensor([-0.3633,  0.0861])\n",
      "J: 9.500448226928711,  b0: -2.9390735626220703, b1: 3.684194564819336\n",
      "JGrad: tensor([-0.1759]),  bGrad: tensor([0.3614, 0.5322])\n",
      "J: 9.514598846435547,  b0: -2.94928240776062, b1: 3.681306838989258\n",
      "JGrad: tensor([-0.1817]),  bGrad: tensor([-0.1826,  0.1407])\n",
      "J: 9.53527545928955,  b0: -2.9573867321014404, b1: 3.6775290966033936\n",
      "JGrad: tensor([-0.0788]),  bGrad: tensor([0.1066, 0.0846])\n",
      "J: 9.557353973388672,  b0: -2.9653334617614746, b1: 3.6734163761138916\n",
      "JGrad: tensor([-0.2932]),  bGrad: tensor([-1.2017, -0.4235])\n",
      "J: 9.59001350402832,  b0: -2.965250253677368, b1: 3.6732563972473145\n",
      "JGrad: tensor([-0.1481]),  bGrad: tensor([0.4915, 0.5830])\n",
      "J: 9.625909805297852,  b0: -2.9681403636932373, b1: 3.668224573135376\n",
      "JGrad: tensor([-0.0065]),  bGrad: tensor([-0.2612, -0.3379])\n",
      "J: 9.658550262451172,  b0: -2.9691672325134277, b1: 3.6665265560150146\n",
      "JGrad: tensor([0.0516]),  bGrad: tensor([-0.2861, -0.5623])\n",
      "J: 9.685707092285156,  b0: -2.9683613777160645, b1: 3.66972279548645\n",
      "JGrad: tensor([-0.1268]),  bGrad: tensor([-2.0477, -1.4812])\n",
      "J: 9.715743064880371,  b0: -2.9552555084228516, b1: 3.685037136077881\n",
      "JGrad: tensor([0.0856]),  bGrad: tensor([1.2281, 0.6261])\n",
      ">>>\t epoch 31:: loss = 0.3182618021965027, validation loss = 0.307451069355011\n",
      "J: 9.73904800415039,  b0: -2.9508824348449707, b1: 3.6935713291168213\n",
      "JGrad: tensor([0.1651]),  bGrad: tensor([1.2606, 0.4597])\n",
      "J: 9.752776145935059,  b0: -2.954576015472412, b1: 3.6973915100097656\n",
      "JGrad: tensor([0.2036]),  bGrad: tensor([ 0.5188, -0.2757])\n",
      "J: 9.756176948547363,  b0: -2.9610495567321777, b1: 3.7031590938568115\n",
      "JGrad: tensor([0.1957]),  bGrad: tensor([ 0.7453, -0.0756])\n",
      "J: 9.75062370300293,  b0: -2.9714066982269287, b1: 3.708996534347534\n",
      "JGrad: tensor([-0.1098]),  bGrad: tensor([-0.9821, -0.6870])\n",
      "J: 9.750459671020508,  b0: -2.9747700691223145, b1: 3.720061779022217\n",
      "JGrad: tensor([-0.2655]),  bGrad: tensor([0.0598, 0.5510])\n",
      "J: 9.762007713317871,  b0: -2.9781653881073, b1: 3.725369691848755\n",
      "JGrad: tensor([-0.1040]),  bGrad: tensor([-0.1348, -0.0272])\n",
      "J: 9.776998519897461,  b0: -2.9804041385650635, b1: 3.7303848266601562\n",
      "JGrad: tensor([-0.1440]),  bGrad: tensor([0.9498, 0.9081])\n",
      "J: 9.796858787536621,  b0: -2.9882144927978516, b1: 3.727200984954834\n",
      "JGrad: tensor([-0.1630]),  bGrad: tensor([0.0015, 0.2219])\n",
      "J: 9.82194709777832,  b0: -2.9952633380889893, b1: 3.722447395324707\n",
      "JGrad: tensor([0.2280]),  bGrad: tensor([ 0.7834, -0.1382])\n",
      "J: 9.834457397460938,  b0: -3.0064053535461426, b1: 3.7193377017974854\n",
      "JGrad: tensor([-0.1768]),  bGrad: tensor([-0.6900, -0.2368])\n",
      "J: 9.853536605834961,  b0: -3.0122201442718506, b1: 3.7185516357421875\n",
      "JGrad: tensor([-0.0656]),  bGrad: tensor([-0.5039, -0.3755])\n",
      "J: 9.87363338470459,  b0: -3.014370918273926, b1: 3.7210450172424316\n",
      "JGrad: tensor([0.0571]),  bGrad: tensor([-1.6455, -1.6644])\n",
      "J: 9.889217376708984,  b0: -3.0062179565429688, b1: 3.737457275390625\n",
      "JGrad: tensor([0.4964]),  bGrad: tensor([2.3002, 0.3536])\n",
      ">>>\t epoch 32:: loss = 0.29986369609832764, validation loss = 0.2851293981075287\n",
      "J: 9.881287574768066,  b0: -3.0129730701446533, b1: 3.7492330074310303\n",
      "JGrad: tensor([-0.0673]),  bGrad: tensor([0.6036, 0.5169])\n",
      "J: 9.877111434936523,  b0: -3.0227608680725098, b1: 3.7554311752319336\n",
      "JGrad: tensor([-0.0356]),  bGrad: tensor([0.9350, 0.6340])\n",
      "J: 9.874921798706055,  b0: -3.037315607070923, b1: 3.7555978298187256\n",
      "JGrad: tensor([-0.0418]),  bGrad: tensor([-1.2210, -1.0224])\n",
      "J: 9.874798774719238,  b0: -3.042926073074341, b1: 3.764486789703369\n",
      "JGrad: tensor([-0.0768]),  bGrad: tensor([-1.2681, -0.9505])\n",
      "J: 9.878091812133789,  b0: -3.0401878356933594, b1: 3.7806193828582764\n",
      "JGrad: tensor([-0.1881]),  bGrad: tensor([-2.0685, -1.3910])\n",
      "J: 9.889397621154785,  b0: -3.025028944015503, b1: 3.807018518447876\n",
      "JGrad: tensor([0.0292]),  bGrad: tensor([1.7703, 1.1315])\n",
      "J: 9.898292541503906,  b0: -3.0222527980804443, b1: 3.821108341217041\n",
      "JGrad: tensor([-0.1843]),  bGrad: tensor([0.4708, 0.6833])\n",
      "J: 9.914485931396484,  b0: -3.022643804550171, b1: 3.827955484390259\n",
      "JGrad: tensor([-0.1583]),  bGrad: tensor([0.3116, 0.4674])\n",
      "J: 9.936107635498047,  b0: -3.0249135494232178, b1: 3.8301219940185547\n",
      "JGrad: tensor([0.1256]),  bGrad: tensor([1.8274, 1.0086])\n",
      "J: 9.949997901916504,  b0: -3.0381953716278076, b1: 3.8234293460845947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.1016]),  bGrad: tensor([1.4594, 0.7174])\n",
      "J: 9.957986831665039,  b0: -3.059131145477295, b1: 3.8112473487854004\n",
      "JGrad: tensor([-0.0635]),  bGrad: tensor([0.5692, 0.4390])\n",
      "J: 9.96802043914795,  b0: -3.081503391265869, b1: 3.7964999675750732\n",
      "JGrad: tensor([-0.2173]),  bGrad: tensor([-1.3292, -0.6604])\n",
      "J: 9.986742973327637,  b0: -3.0934557914733887, b1: 3.788891315460205\n",
      "JGrad: tensor([-0.2452]),  bGrad: tensor([-1.7948, -0.9240])\n",
      ">>>\t epoch 33:: loss = 0.2675135135650635, validation loss = 0.3077027499675751\n",
      "J: 10.014524459838867,  b0: -3.093151569366455, b1: 3.7899866104125977\n",
      "JGrad: tensor([-0.1989]),  bGrad: tensor([-1.3431, -0.7185])\n",
      "J: 10.048408508300781,  b0: -3.0845985412597656, b1: 3.7971584796905518\n",
      "JGrad: tensor([0.0325]),  bGrad: tensor([0.6476, 0.2873])\n",
      "J: 10.077496528625488,  b0: -3.080887794494629, b1: 3.80114483833313\n",
      "JGrad: tensor([-0.1923]),  bGrad: tensor([-1.9166, -1.2083])\n",
      "J: 10.112279891967773,  b0: -3.0657286643981934, b1: 3.8151464462280273\n",
      "JGrad: tensor([0.2879]),  bGrad: tensor([1.1424, 0.0099])\n",
      "J: 10.130701065063477,  b0: -3.05912709236145, b1: 3.8276803493499756\n",
      "JGrad: tensor([0.2953]),  bGrad: tensor([1.2696, 0.0664])\n",
      "J: 10.134093284606934,  b0: -3.061023235321045, b1: 3.8384032249450684\n",
      "JGrad: tensor([0.1181]),  bGrad: tensor([-0.0615, -0.4762])\n",
      "J: 10.131878852844238,  b0: -3.062352180480957, b1: 3.8521857261657715\n",
      "JGrad: tensor([-0.0394]),  bGrad: tensor([0.7019, 0.5631])\n",
      "J: 10.131645202636719,  b0: -3.0678954124450684, b1: 3.8597254753112793\n",
      "JGrad: tensor([0.2206]),  bGrad: tensor([1.5815, 0.5685])\n",
      "J: 10.121573448181152,  b0: -3.0826773643493652, b1: 3.861588478088379\n",
      "JGrad: tensor([0.2373]),  bGrad: tensor([1.0906, 0.1160])\n",
      "J: 10.101903915405273,  b0: -3.1027495861053467, b1: 3.862260103225708\n",
      "JGrad: tensor([0.0694]),  bGrad: tensor([ 0.1531, -0.2575])\n",
      "J: 10.081071853637695,  b0: -3.1217901706695557, b1: 3.8651046752929688\n",
      "JGrad: tensor([-0.0053]),  bGrad: tensor([0.5280, 0.3195])\n",
      "J: 10.062535285949707,  b0: -3.142228603363037, b1: 3.8648860454559326\n",
      "JGrad: tensor([-0.1459]),  bGrad: tensor([-1.9949, -1.3986])\n",
      "J: 10.05238151550293,  b0: -3.148223876953125, b1: 3.8768584728240967\n",
      "JGrad: tensor([-0.2923]),  bGrad: tensor([-2.3002, -1.2327])\n",
      ">>>\t epoch 34:: loss = 0.24088872969150543, validation loss = 0.28340944647789\n",
      "J: 10.056351661682129,  b0: -3.1393518447875977, b1: 3.898355484008789\n",
      "JGrad: tensor([-0.2511]),  bGrad: tensor([-0.4653,  0.1428])\n",
      "J: 10.071170806884766,  b0: -3.1284687519073486, b1: 3.916485548019409\n",
      "JGrad: tensor([-0.2376]),  bGrad: tensor([0.0953, 0.5194])\n",
      "J: 10.095145225524902,  b0: -3.1192524433135986, b1: 3.928290843963623\n",
      "JGrad: tensor([-0.0677]),  bGrad: tensor([0.1818, 0.1763])\n",
      "J: 10.119784355163574,  b0: -3.1120779514312744, b1: 3.937390089035034\n",
      "JGrad: tensor([-0.0627]),  bGrad: tensor([1.3305, 1.0187])\n",
      "J: 10.144804954528809,  b0: -3.113903522491455, b1: 3.936683416366577\n",
      "JGrad: tensor([-0.1648]),  bGrad: tensor([2.0681, 1.8817])\n",
      "J: 10.17474365234375,  b0: -3.1284120082855225, b1: 3.919649839401245\n",
      "JGrad: tensor([-0.0266]),  bGrad: tensor([-0.3367, -0.3909])\n",
      "J: 10.202920913696289,  b0: -3.1393892765045166, b1: 3.907711982727051\n",
      "JGrad: tensor([0.0547]),  bGrad: tensor([ 0.3847, -0.0074])\n",
      "J: 10.225851058959961,  b0: -3.1516811847686768, b1: 3.897017478942871\n",
      "JGrad: tensor([-0.1297]),  bGrad: tensor([-1.6945, -1.1813])\n",
      "J: 10.25235652923584,  b0: -3.1521737575531006, b1: 3.897714138031006\n",
      "JGrad: tensor([-0.1813]),  bGrad: tensor([-0.4504, -0.0358])\n",
      "J: 10.28439998626709,  b0: -3.1498048305511475, b1: 3.898655414581299\n",
      "JGrad: tensor([-0.0194]),  bGrad: tensor([-0.3180, -0.3399])\n",
      "J: 10.314155578613281,  b0: -3.145681381225586, b1: 3.9024806022644043\n",
      "JGrad: tensor([0.1908]),  bGrad: tensor([-1.3936, -1.7893])\n",
      "J: 10.33232593536377,  b0: -3.133251428604126, b1: 3.9215598106384277\n",
      "JGrad: tensor([0.1962]),  bGrad: tensor([ 0.5987, -0.2206])\n",
      "J: 10.33981704711914,  b0: -3.125800371170044, b1: 3.9406847953796387\n",
      "JGrad: tensor([-0.0333]),  bGrad: tensor([0.8287, 0.6577])\n",
      ">>>\t epoch 35:: loss = 0.25307005643844604, validation loss = 0.3086945414543152\n",
      "J: 10.348075866699219,  b0: -3.1242828369140625, b1: 3.9521501064300537\n",
      "JGrad: tensor([0.0583]),  bGrad: tensor([1.7672, 1.1031])\n",
      "J: 10.352875709533691,  b0: -3.1339926719665527, b1: 3.95280385017395\n",
      "JGrad: tensor([0.2043]),  bGrad: tensor([2.2434, 1.1571])\n",
      "J: 10.347936630249023,  b0: -3.1567602157592773, b1: 3.9432532787323\n",
      "JGrad: tensor([0.1926]),  bGrad: tensor([1.5169, 0.5667])\n",
      "J: 10.334756851196289,  b0: -3.186748743057251, b1: 3.929678201675415\n",
      "JGrad: tensor([-0.0640]),  bGrad: tensor([-1.2166, -0.9422])\n",
      "J: 10.325787544250488,  b0: -3.206134557723999, b1: 3.9257233142852783\n",
      "JGrad: tensor([-0.1255]),  bGrad: tensor([-1.4459, -0.9931])\n",
      "J: 10.323410987854004,  b0: -3.2145280838012695, b1: 3.930880546569824\n",
      "JGrad: tensor([-0.0896]),  bGrad: tensor([-1.0076, -0.7209])\n",
      "J: 10.325346946716309,  b0: -3.215771436691284, b1: 3.9418587684631348\n",
      "JGrad: tensor([0.0449]),  bGrad: tensor([-0.3319, -0.5201])\n",
      "J: 10.325047492980957,  b0: -3.214808464050293, b1: 3.9563241004943848\n",
      "JGrad: tensor([-0.0969]),  bGrad: tensor([-0.8467, -0.5587])\n",
      "J: 10.329197883605957,  b0: -3.208620309829712, b1: 3.9742746353149414\n",
      "JGrad: tensor([-0.2410]),  bGrad: tensor([-1.1456, -0.4187])\n",
      "J: 10.343917846679688,  b0: -3.1958441734313965, b1: 3.9941396713256836\n",
      "JGrad: tensor([-0.1622]),  bGrad: tensor([-1.7770, -1.2325])\n",
      "J: 10.364574432373047,  b0: -3.1731793880462646, b1: 4.022874355316162\n",
      "JGrad: tensor([-0.0907]),  bGrad: tensor([1.4020, 1.2249])\n",
      "J: 10.3873291015625,  b0: -3.161590099334717, b1: 4.037939071655273\n",
      "JGrad: tensor([0.0582]),  bGrad: tensor([1.3435, 0.8594])\n",
      "J: 10.405170440673828,  b0: -3.159606695175171, b1: 4.043929576873779\n",
      "JGrad: tensor([0.0067]),  bGrad: tensor([2.1306, 1.5877])\n",
      ">>>\t epoch 36:: loss = 0.29734301567077637, validation loss = 0.32022473216056824\n",
      "J: 10.420944213867188,  b0: -3.171211004257202, b1: 4.035336971282959\n",
      "JGrad: tensor([-0.0430]),  bGrad: tensor([1.7548, 1.4208])\n",
      "J: 10.43713092803955,  b0: -3.1926748752593994, b1: 4.015110969543457\n",
      "JGrad: tensor([0.0166]),  bGrad: tensor([0.9585, 0.5873])\n",
      "J: 10.450957298278809,  b0: -3.2180347442626953, b1: 3.991718053817749\n",
      "JGrad: tensor([-0.0431]),  bGrad: tensor([0.0627, 0.0216])\n",
      "J: 10.465399742126465,  b0: -3.241283893585205, b1: 3.9704463481903076\n",
      "JGrad: tensor([-0.0572]),  bGrad: tensor([-0.0208, -0.0085])\n",
      "J: 10.481046676635742,  b0: -3.2621047496795654, b1: 3.9513509273529053\n",
      "JGrad: tensor([-0.1160]),  bGrad: tensor([-1.1494, -0.7593])\n",
      "J: 10.500484466552734,  b0: -3.2736053466796875, b1: 3.940861225128174\n",
      "JGrad: tensor([-0.0929]),  bGrad: tensor([-2.0000, -1.5324])\n",
      "J: 10.522279739379883,  b0: -3.2713425159454346, b1: 3.944955348968506\n",
      "JGrad: tensor([-0.1595]),  bGrad: tensor([-1.9747, -1.3571])\n",
      "J: 10.549266815185547,  b0: -3.2568700313568115, b1: 3.960608959197998\n",
      "JGrad: tensor([-0.1384]),  bGrad: tensor([-1.3746, -0.8916])\n",
      "J: 10.579964637756348,  b0: -3.235180377960205, b1: 3.9825730323791504\n",
      "JGrad: tensor([0.1407]),  bGrad: tensor([-0.9974, -1.2488])\n",
      "J: 10.601113319396973,  b0: -3.209354877471924, b1: 4.01335334777832\n",
      "JGrad: tensor([0.3613]),  bGrad: tensor([ 0.0967, -1.0324])\n",
      "J: 10.60344409942627,  b0: -3.186692237854004, b1: 4.050171852111816\n",
      "JGrad: tensor([0.2657]),  bGrad: tensor([2.1262, 0.9317])\n",
      "J: 10.59329891204834,  b0: -3.17972731590271, b1: 4.07509708404541\n",
      "JGrad: tensor([0.1853]),  bGrad: tensor([2.3191, 1.3123])\n",
      "J: 10.57562255859375,  b0: -3.188072919845581, b1: 4.085939407348633\n",
      "JGrad: tensor([0.1935]),  bGrad: tensor([2.0374, 1.0874])\n",
      ">>>\t epoch 37:: loss = 0.4181753098964691, validation loss = 0.32291409373283386\n",
      "J: 10.550788879394531,  b0: -3.208397626876831, b1: 4.08610200881958\n",
      "JGrad: tensor([0.0637]),  bGrad: tensor([2.3954, 1.6541])\n",
      "J: 10.525471687316895,  b0: -3.2417070865631104, b1: 4.071671485900879\n",
      "JGrad: tensor([-0.0641]),  bGrad: tensor([1.1825, 0.9773])\n",
      "J: 10.505621910095215,  b0: -3.2791359424591064, b1: 4.0500640869140625\n",
      "JGrad: tensor([-0.0107]),  bGrad: tensor([-0.2577, -0.3230])\n",
      "J: 10.48823070526123,  b0: -3.3112425804138184, b1: 4.033444881439209\n",
      "JGrad: tensor([-0.0566]),  bGrad: tensor([-1.3976, -1.1194])\n",
      "J: 10.475184440612793,  b0: -3.3313486576080322, b1: 4.028367042541504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0277]),  bGrad: tensor([-1.6484, -1.4070])\n",
      "J: 10.464712142944336,  b0: -3.3390657901763916, b1: 4.036209583282471\n",
      "JGrad: tensor([-0.2984]),  bGrad: tensor([-2.4405, -1.3625])\n",
      "J: 10.469125747680664,  b0: -3.3306639194488525, b1: 4.055274486541748\n",
      "JGrad: tensor([-0.1643]),  bGrad: tensor([-0.8371, -0.3913])\n",
      "J: 10.48071575164795,  b0: -3.3178303241729736, b1: 4.0759053230285645\n",
      "JGrad: tensor([-0.2543]),  bGrad: tensor([-2.0960, -1.2156])\n",
      "J: 10.502923011779785,  b0: -3.293120861053467, b1: 4.105195045471191\n",
      "JGrad: tensor([-0.2697]),  bGrad: tensor([-1.6816, -0.8120])\n",
      "J: 10.535384178161621,  b0: -3.2603209018707275, b1: 4.138741493225098\n",
      "JGrad: tensor([-0.0970]),  bGrad: tensor([1.4466, 1.2902])\n",
      "J: 10.569125175476074,  b0: -3.239884853363037, b1: 4.157535552978516\n",
      "JGrad: tensor([0.1767]),  bGrad: tensor([1.7425, 0.8712])\n",
      "J: 10.591314315795898,  b0: -3.2324440479278564, b1: 4.1667656898498535\n",
      "JGrad: tensor([0.1738]),  bGrad: tensor([1.9803, 1.0728])\n",
      "J: 10.603229522705078,  b0: -3.2381842136383057, b1: 4.165600299835205\n",
      "JGrad: tensor([0.0663]),  bGrad: tensor([3.0889, 2.2008])\n",
      ">>>\t epoch 38:: loss = 0.5601707696914673, validation loss = 0.29868200421333313\n",
      "J: 10.61088752746582,  b0: -3.2626562118530273, b1: 4.145188331604004\n",
      "JGrad: tensor([-0.1839]),  bGrad: tensor([0.3156, 0.6452])\n",
      "J: 10.626323699951172,  b0: -3.28668475151062, b1: 4.121118545532227\n",
      "JGrad: tensor([-0.1140]),  bGrad: tensor([0.7680, 0.7377])\n",
      "J: 10.645529747009277,  b0: -3.3131468296051025, b1: 4.092937469482422\n",
      "JGrad: tensor([-0.1883]),  bGrad: tensor([-1.5436, -0.9097])\n",
      "J: 10.671581268310547,  b0: -3.3272860050201416, b1: 4.075584888458252\n",
      "JGrad: tensor([-0.1300]),  bGrad: tensor([-0.3761, -0.0927])\n",
      "J: 10.701096534729004,  b0: -3.3376657962799072, b1: 4.060766696929932\n",
      "JGrad: tensor([-0.1237]),  bGrad: tensor([-1.4255, -0.9624])\n",
      "J: 10.73344898223877,  b0: -3.3380587100982666, b1: 4.055926322937012\n",
      "JGrad: tensor([-0.1405]),  bGrad: tensor([-2.0468, -1.4562])\n",
      "J: 10.769139289855957,  b0: -3.3255701065063477, b1: 4.064424514770508\n",
      "JGrad: tensor([-0.0936]),  bGrad: tensor([-2.3290, -1.7822])\n",
      "J: 10.805662155151367,  b0: -3.2997548580169678, b1: 4.087757587432861\n",
      "JGrad: tensor([0.2690]),  bGrad: tensor([-0.0838, -0.8953])\n",
      "J: 10.825963973999023,  b0: -3.275965929031372, b1: 4.1166582107543945\n",
      "JGrad: tensor([0.2176]),  bGrad: tensor([ 0.6161, -0.1933])\n",
      "J: 10.834085464477539,  b0: -3.258402109146118, b1: 4.144406318664551\n",
      "JGrad: tensor([0.1803]),  bGrad: tensor([1.6421, 0.7601])\n",
      "J: 10.832985877990723,  b0: -3.2529075145721436, b1: 4.162685394287109\n",
      "JGrad: tensor([0.0832]),  bGrad: tensor([1.6527, 1.0492])\n",
      "J: 10.828108787536621,  b0: -3.2583396434783936, b1: 4.1698737144470215\n",
      "JGrad: tensor([0.1972]),  bGrad: tensor([2.8174, 1.6519])\n",
      "J: 10.814508438110352,  b0: -3.280858278274536, b1: 4.161766529083252\n",
      "JGrad: tensor([0.2524]),  bGrad: tensor([2.1536, 0.9978])\n",
      ">>>\t epoch 39:: loss = 0.4721893072128296, validation loss = 0.2166847288608551\n",
      "J: 10.79049015045166,  b0: -3.3145761489868164, b1: 4.145666122436523\n",
      "JGrad: tensor([0.1272]),  bGrad: tensor([1.1867, 0.4287])\n",
      "J: 10.762913703918457,  b0: -3.3523666858673096, b1: 4.127374172210693\n",
      "JGrad: tensor([-0.0380]),  bGrad: tensor([-0.6371, -0.5629])\n",
      "J: 10.739843368530273,  b0: -3.3824219703674316, b1: 4.115871429443359\n",
      "JGrad: tensor([-0.2456]),  bGrad: tensor([-0.7715, -0.1206])\n",
      "J: 10.730576515197754,  b0: -3.4046590328216553, b1: 4.106573581695557\n",
      "JGrad: tensor([-0.1423]),  bGrad: tensor([-1.8609, -1.2809])\n",
      "J: 10.728890419006348,  b0: -3.4129974842071533, b1: 4.109540939331055\n",
      "JGrad: tensor([-0.1208]),  bGrad: tensor([-1.5347, -1.0917])\n",
      "J: 10.73302936553955,  b0: -3.4108808040618896, b1: 4.121870994567871\n",
      "JGrad: tensor([-0.2596]),  bGrad: tensor([-3.0931, -2.0151])\n",
      "J: 10.748906135559082,  b0: -3.3896567821502686, b1: 4.150718688964844\n",
      "JGrad: tensor([0.0280]),  bGrad: tensor([-2.3666, -2.1427])\n",
      "J: 10.7618989944458,  b0: -3.355818033218384, b1: 4.195445537567139\n",
      "JGrad: tensor([-0.3872]),  bGrad: tensor([-1.6878, -0.5533])\n",
      "J: 10.791654586791992,  b0: -3.3148388862609863, b1: 4.240609645843506\n",
      "JGrad: tensor([-0.1433]),  bGrad: tensor([0.9228, 1.0083])\n",
      "J: 10.825157165527344,  b0: -3.2836883068084717, b1: 4.272388935089111\n",
      "JGrad: tensor([0.0859]),  bGrad: tensor([1.4335, 0.8494])\n",
      "J: 10.851320266723633,  b0: -3.2645976543426514, b1: 4.293521881103516\n",
      "JGrad: tensor([0.2669]),  bGrad: tensor([3.5197, 2.0218])\n",
      "J: 10.862363815307617,  b0: -3.2693731784820557, b1: 4.294723987579346\n",
      "JGrad: tensor([0.0527]),  bGrad: tensor([2.7756, 1.9672])\n",
      "J: 10.869848251342773,  b0: -3.290870428085327, b1: 4.278558731079102\n",
      "JGrad: tensor([0.1524]),  bGrad: tensor([3.5441, 2.3277])\n",
      ">>>\t epoch 40:: loss = 0.7676976919174194, validation loss = 0.30490076541900635\n",
      "J: 10.869443893432617,  b0: -3.331998586654663, b1: 4.243740558624268\n",
      "JGrad: tensor([0.1020]),  bGrad: tensor([1.9569, 1.2391])\n",
      "J: 10.864294052124023,  b0: -3.3810629844665527, b1: 4.20159387588501\n",
      "JGrad: tensor([-0.2522]),  bGrad: tensor([-0.5915,  0.0201])\n",
      "J: 10.871489524841309,  b0: -3.4216160774230957, b1: 4.1634392738342285\n",
      "JGrad: tensor([-0.0842]),  bGrad: tensor([-0.8286, -0.5968])\n",
      "J: 10.881924629211426,  b0: -3.453026056289673, b1: 4.1342902183532715\n",
      "JGrad: tensor([-0.1941]),  bGrad: tensor([-2.3042, -1.5240])\n",
      "J: 10.900430679321289,  b0: -3.4670376777648926, b1: 4.121401786804199\n",
      "JGrad: tensor([-0.1769]),  bGrad: tensor([-3.2037, -2.3081])\n",
      "J: 10.925400733947754,  b0: -3.45989990234375, b1: 4.12994384765625\n",
      "JGrad: tensor([-0.2754]),  bGrad: tensor([-2.9234, -1.8429])\n",
      "J: 10.96078109741211,  b0: -3.4355626106262207, b1: 4.153634071350098\n",
      "JGrad: tensor([-0.2235]),  bGrad: tensor([-2.3517, -1.5064])\n",
      "J: 11.003108024597168,  b0: -3.399282455444336, b1: 4.18801736831665\n",
      "JGrad: tensor([0.0120]),  bGrad: tensor([-0.8100, -0.8319])\n",
      "J: 11.040685653686523,  b0: -3.3616340160369873, b1: 4.226208686828613\n",
      "JGrad: tensor([0.1011]),  bGrad: tensor([1.8105, 1.1263])\n",
      "J: 11.069782257080078,  b0: -3.3388571739196777, b1: 4.250795841217041\n",
      "JGrad: tensor([0.1188]),  bGrad: tensor([1.7027, 0.9515])\n",
      "J: 11.090398788452148,  b0: -3.328795909881592, b1: 4.264662265777588\n",
      "JGrad: tensor([0.0697]),  bGrad: tensor([1.0003, 0.5480])\n",
      "J: 11.105690956115723,  b0: -3.325868844985962, b1: 4.272386074066162\n",
      "JGrad: tensor([0.1763]),  bGrad: tensor([2.2884, 1.2803])\n",
      "J: 11.111149787902832,  b0: -3.337256669998169, b1: 4.268199443817139\n",
      "JGrad: tensor([0.0197]),  bGrad: tensor([1.3577, 1.0042])\n",
      ">>>\t epoch 41:: loss = 0.23316575586795807, validation loss = 0.29777100682258606\n",
      "J: 11.115140914916992,  b0: -3.355830192565918, b1: 4.255693435668945\n",
      "JGrad: tensor([0.2272]),  bGrad: tensor([2.0512, 0.9855])\n",
      "J: 11.108013153076172,  b0: -3.385096788406372, b1: 4.2358574867248535\n",
      "JGrad: tensor([0.1616]),  bGrad: tensor([1.0795, 0.3819])\n",
      "J: 11.093968391418457,  b0: -3.4180705547332764, b1: 4.214658737182617\n",
      "JGrad: tensor([0.0537]),  bGrad: tensor([-1.0255, -1.1188])\n",
      "J: 11.078778266906738,  b0: -3.441479444503784, b1: 4.205326557159424\n",
      "JGrad: tensor([-0.1884]),  bGrad: tensor([-0.7217, -0.2316])\n",
      "J: 11.074007034301758,  b0: -3.458137273788452, b1: 4.198938369750977\n",
      "JGrad: tensor([-0.1249]),  bGrad: tensor([-1.2191, -0.8018])\n",
      "J: 11.075617790222168,  b0: -3.465649366378784, b1: 4.200183868408203\n",
      "JGrad: tensor([-0.2092]),  bGrad: tensor([-2.1845, -1.3986])\n",
      "J: 11.08696174621582,  b0: -3.4589998722076416, b1: 4.213505268096924\n",
      "JGrad: tensor([-0.1092]),  bGrad: tensor([-0.9234, -0.5795])\n",
      "J: 11.102351188659668,  b0: -3.4473400115966797, b1: 4.230565071105957\n",
      "JGrad: tensor([-0.0149]),  bGrad: tensor([-0.4082, -0.4148])\n",
      "J: 11.116924285888672,  b0: -3.4343245029449463, b1: 4.249560356140137\n",
      "JGrad: tensor([-0.1349]),  bGrad: tensor([-1.6841, -1.1379])\n",
      "J: 11.13645076751709,  b0: -3.4122583866119385, b1: 4.276602268218994\n",
      "JGrad: tensor([0.2942]),  bGrad: tensor([2.5831, 1.2211])\n",
      "J: 11.140061378479004,  b0: -3.40828537940979, b1: 4.29026460647583\n",
      "JGrad: tensor([0.0233]),  bGrad: tensor([1.1123, 0.7821])\n",
      "J: 11.142210006713867,  b0: -3.4115371704101562, b1: 4.29572868347168\n",
      "JGrad: tensor([0.1456]),  bGrad: tensor([2.6479, 1.6612])\n",
      "J: 11.137232780456543,  b0: -3.43068528175354, b1: 4.286132335662842\n",
      "JGrad: tensor([-0.1079]),  bGrad: tensor([0.0519, 0.2381])\n",
      ">>>\t epoch 42:: loss = 0.23422689735889435, validation loss = 0.2177925854921341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 11.1378755569458,  b0: -3.4482579231262207, b1: 4.27540397644043\n",
      "JGrad: tensor([-0.1148]),  bGrad: tensor([-0.5714, -0.3474])\n",
      "J: 11.143914222717285,  b0: -3.4605801105499268, b1: 4.2687788009643555\n",
      "JGrad: tensor([-0.1907]),  bGrad: tensor([-0.8131, -0.2911])\n",
      "J: 11.158417701721191,  b0: -3.4666812419891357, b1: 4.265359878540039\n",
      "JGrad: tensor([-0.0025]),  bGrad: tensor([-1.6957, -1.5203])\n",
      "J: 11.171605110168457,  b0: -3.4617483615875244, b1: 4.275594234466553\n",
      "JGrad: tensor([0.0187]),  bGrad: tensor([-0.5097, -0.5973])\n",
      "J: 11.182596206665039,  b0: -3.4541678428649902, b1: 4.290046215057373\n",
      "JGrad: tensor([-0.1433]),  bGrad: tensor([-0.6704, -0.2918])\n",
      "J: 11.199329376220703,  b0: -3.443209409713745, b1: 4.30562686920166\n",
      "JGrad: tensor([0.0854]),  bGrad: tensor([0.5351, 0.1863])\n",
      "J: 11.210325241088867,  b0: -3.436635971069336, b1: 4.318029403686523\n",
      "JGrad: tensor([-0.0382]),  bGrad: tensor([0.7315, 0.6225])\n",
      "J: 11.22205924987793,  b0: -3.4352288246154785, b1: 4.323729991912842\n",
      "JGrad: tensor([0.1199]),  bGrad: tensor([2.1537, 1.3381])\n",
      "J: 11.226892471313477,  b0: -3.4472436904907227, b1: 4.317102909088135\n",
      "JGrad: tensor([0.1269]),  bGrad: tensor([1.6599, 0.9193])\n",
      "J: 11.225171089172363,  b0: -3.4682908058166504, b1: 4.3030571937561035\n",
      "JGrad: tensor([-0.1396]),  bGrad: tensor([-0.6199, -0.2639])\n",
      "J: 11.230308532714844,  b0: -3.483426570892334, b1: 4.292724132537842\n",
      "JGrad: tensor([-0.0134]),  bGrad: tensor([-0.9624, -0.8710])\n",
      "J: 11.235579490661621,  b0: -3.491114854812622, b1: 4.291086196899414\n",
      "JGrad: tensor([-0.0938]),  bGrad: tensor([-1.9962, -1.5242])\n",
      "J: 11.244831085205078,  b0: -3.4857077598571777, b1: 4.3030171394348145\n",
      "JGrad: tensor([-0.0736]),  bGrad: tensor([-1.3473, -1.0289])\n",
      ">>>\t epoch 43:: loss = 0.15947070717811584, validation loss = 0.199066624045372\n",
      "J: 11.256705284118652,  b0: -3.472519636154175, b1: 4.322807788848877\n",
      "JGrad: tensor([-0.1769]),  bGrad: tensor([-0.3854,  0.0656])\n",
      "J: 11.275897979736328,  b0: -3.45825457572937, b1: 4.340062141418457\n",
      "JGrad: tensor([0.0026]),  bGrad: tensor([1.5010, 1.0883])\n",
      "J: 11.293068885803223,  b0: -3.4546940326690674, b1: 4.34600830078125\n",
      "JGrad: tensor([0.2093]),  bGrad: tensor([0.7999, 0.0227])\n",
      "J: 11.29844856262207,  b0: -3.4564366340637207, b1: 4.351165771484375\n",
      "JGrad: tensor([0.1116]),  bGrad: tensor([2.5160, 1.6621])\n",
      "J: 11.297918319702148,  b0: -3.4735467433929443, b1: 4.341166019439697\n",
      "JGrad: tensor([0.2114]),  bGrad: tensor([1.4034, 0.5455])\n",
      "J: 11.28725814819336,  b0: -3.4976232051849365, b1: 4.327350616455078\n",
      "JGrad: tensor([-0.0860]),  bGrad: tensor([-1.0874, -0.7731])\n",
      "J: 11.28179931640625,  b0: -3.5125815868377686, b1: 4.321727275848389\n",
      "JGrad: tensor([0.0624]),  bGrad: tensor([-0.8830, -1.0050])\n",
      "J: 11.273870468139648,  b0: -3.52059006690979, b1: 4.325530052185059\n",
      "JGrad: tensor([-0.0310]),  bGrad: tensor([-0.0966, -0.1077])\n",
      "J: 11.268224716186523,  b0: -3.527207374572754, b1: 4.329906940460205\n",
      "JGrad: tensor([-0.2195]),  bGrad: tensor([-0.8548, -0.2682])\n",
      "J: 11.273748397827148,  b0: -3.527867317199707, b1: 4.336221694946289\n",
      "JGrad: tensor([-0.1690]),  bGrad: tensor([-1.8232, -1.1799])\n",
      "J: 11.286890983581543,  b0: -3.5171589851379395, b1: 4.352334976196289\n",
      "JGrad: tensor([-0.0484]),  bGrad: tensor([-0.5010, -0.4185])\n",
      "J: 11.301072120666504,  b0: -3.5044023990631104, b1: 4.370554447174072\n",
      "JGrad: tensor([-0.3671]),  bGrad: tensor([-0.4426,  0.4827])\n",
      "J: 11.331523895263672,  b0: -3.490159749984741, b1: 4.382692337036133\n",
      "JGrad: tensor([0.0115]),  bGrad: tensor([1.3951, 1.0259])\n",
      ">>>\t epoch 44:: loss = 0.1287042200565338, validation loss = 0.2235502302646637\n",
      "J: 11.358405113220215,  b0: -3.48600697517395, b1: 4.384530067443848\n",
      "JGrad: tensor([0.0532]),  bGrad: tensor([1.7878, 1.2166])\n",
      "J: 11.38005256652832,  b0: -3.4933767318725586, b1: 4.375408172607422\n",
      "JGrad: tensor([0.0920]),  bGrad: tensor([1.8897, 1.2188])\n",
      "J: 11.395099639892578,  b0: -3.5117411613464355, b1: 4.356407165527344\n",
      "JGrad: tensor([0.1864]),  bGrad: tensor([-2.1013, -2.2743])\n",
      "J: 11.399618148803711,  b0: -3.515218496322632, b1: 4.359435558319092\n",
      "JGrad: tensor([0.2125]),  bGrad: tensor([ 0.7201, -0.0845])\n",
      "J: 11.393392562866211,  b0: -3.522822618484497, b1: 4.362910747528076\n",
      "JGrad: tensor([-0.0942]),  bGrad: tensor([-0.9200, -0.6558])\n",
      "J: 11.392350196838379,  b0: -3.523953437805176, b1: 4.3718390464782715\n",
      "JGrad: tensor([-0.1846]),  bGrad: tensor([-1.1463, -0.5279])\n",
      "J: 11.400362968444824,  b0: -3.51784348487854, b1: 4.384553909301758\n",
      "JGrad: tensor([-0.2381]),  bGrad: tensor([-0.8213, -0.1100])\n",
      "J: 11.419108390808105,  b0: -3.507228374481201, b1: 4.396984100341797\n",
      "JGrad: tensor([0.1655]),  bGrad: tensor([2.4864, 1.4647])\n",
      "J: 11.427964210510254,  b0: -3.5131404399871826, b1: 4.395196914672852\n",
      "JGrad: tensor([0.0946]),  bGrad: tensor([0.7094, 0.2932])\n",
      "J: 11.431349754333496,  b0: -3.522878646850586, b1: 4.390988349914551\n",
      "JGrad: tensor([0.0256]),  bGrad: tensor([1.3084, 0.9476])\n",
      "J: 11.433155059814453,  b0: -3.539787530899048, b1: 4.378798484802246\n",
      "JGrad: tensor([-0.0464]),  bGrad: tensor([-0.9902, -0.8134])\n",
      "J: 11.43703842163086,  b0: -3.5488507747650146, b1: 4.375036239624023\n",
      "JGrad: tensor([-0.2436]),  bGrad: tensor([-1.7301, -0.9072])\n",
      "J: 11.452373504638672,  b0: -3.5462357997894287, b1: 4.379698276519775\n",
      "JGrad: tensor([0.0792]),  bGrad: tensor([-0.5714, -0.8037])\n",
      ">>>\t epoch 45:: loss = 0.32457655668258667, validation loss = 0.1992845982313156\n",
      "J: 11.462333679199219,  b0: -3.5403192043304443, b1: 4.391031742095947\n",
      "JGrad: tensor([-0.1358]),  bGrad: tensor([-0.3884, -0.0362])\n",
      "J: 11.477913856506348,  b0: -3.5325655937194824, b1: 4.401565074920654\n",
      "JGrad: tensor([0.0699]),  bGrad: tensor([0.7302, 0.3576])\n",
      "J: 11.488545417785645,  b0: -3.530139923095703, b1: 4.407873153686523\n",
      "JGrad: tensor([0.1551]),  bGrad: tensor([ 0.4344, -0.0853])\n",
      "J: 11.490558624267578,  b0: -3.530669689178467, b1: 4.414316177368164\n",
      "JGrad: tensor([0.0765]),  bGrad: tensor([1.5975, 1.0559])\n",
      "J: 11.488637924194336,  b0: -3.541131019592285, b1: 4.410709381103516\n",
      "JGrad: tensor([0.0253]),  bGrad: tensor([-0.1739, -0.2224])\n",
      "J: 11.485668182373047,  b0: -3.5494682788848877, b1: 4.4094438552856445\n",
      "JGrad: tensor([-0.0638]),  bGrad: tensor([-0.4736, -0.2900])\n",
      "J: 11.486114501953125,  b0: -3.554013252258301, b1: 4.410892009735107\n",
      "JGrad: tensor([-0.1193]),  bGrad: tensor([-0.6376, -0.2791])\n",
      "J: 11.492353439331055,  b0: -3.554110050201416, b1: 4.4146904945373535\n",
      "JGrad: tensor([0.0599]),  bGrad: tensor([-2.2676, -2.0852])\n",
      "J: 11.495038986206055,  b0: -3.53999662399292, b1: 4.436683177947998\n",
      "JGrad: tensor([-0.0530]),  bGrad: tensor([-0.6098, -0.3827])\n",
      "J: 11.500060081481934,  b0: -3.5234599113464355, b1: 4.459909915924072\n",
      "JGrad: tensor([0.1330]),  bGrad: tensor([1.6859, 0.9347])\n",
      "J: 11.498054504394531,  b0: -3.5191447734832764, b1: 4.472479820251465\n",
      "JGrad: tensor([0.0910]),  bGrad: tensor([1.5539, 0.9354])\n",
      "J: 11.491776466369629,  b0: -3.525000810623169, b1: 4.475446701049805\n",
      "JGrad: tensor([0.1856]),  bGrad: tensor([2.9061, 1.7925])\n",
      "J: 11.477007865905762,  b0: -3.5484254360198975, b1: 4.462138652801514\n",
      "JGrad: tensor([-0.2242]),  bGrad: tensor([2.3364, 2.3537])\n",
      ">>>\t epoch 46:: loss = 0.43519720435142517, validation loss = 0.21593298017978668\n",
      "J: 11.474730491638184,  b0: -3.584069013595581, b1: 4.4293107986450195\n",
      "JGrad: tensor([-0.0631]),  bGrad: tensor([-0.4147, -0.3026])\n",
      "J: 11.47578239440918,  b0: -3.6135895252227783, b1: 4.402424335479736\n",
      "JGrad: tensor([-0.0587]),  bGrad: tensor([-1.1480, -0.9047])\n",
      "J: 11.479619026184082,  b0: -3.632993221282959, b1: 4.386260509490967\n",
      "JGrad: tensor([-0.2250]),  bGrad: tensor([-2.1799, -1.3375])\n",
      "J: 11.49414348602295,  b0: -3.6368203163146973, b1: 4.38360595703125\n",
      "JGrad: tensor([-0.3211]),  bGrad: tensor([-2.5605, -1.4596])\n",
      "J: 11.522969245910645,  b0: -3.62428879737854, b1: 4.394179344177246\n",
      "JGrad: tensor([-0.0504]),  bGrad: tensor([-1.1207, -0.9184])\n",
      "J: 11.551419258117676,  b0: -3.6060104370117188, b1: 4.411856651306152\n",
      "JGrad: tensor([-0.1593]),  bGrad: tensor([-2.7216, -1.9252])\n",
      "J: 11.584871292114258,  b0: -3.5726447105407715, b1: 4.444798469543457\n",
      "JGrad: tensor([0.1358]),  bGrad: tensor([ 0.4123, -0.0674])\n",
      "J: 11.608308792114258,  b0: -3.5451550483703613, b1: 4.475077152252197\n",
      "JGrad: tensor([0.1746]),  bGrad: tensor([2.8862, 1.7631])\n",
      "J: 11.620811462402344,  b0: -3.538423776626587, b1: 4.486663818359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.0266]),  bGrad: tensor([1.2462, 0.8623])\n",
      "J: 11.630764961242676,  b0: -3.5401158332824707, b1: 4.489452838897705\n",
      "JGrad: tensor([0.3763]),  bGrad: tensor([2.0569, 0.5947])\n",
      "J: 11.621200561523438,  b0: -3.5544254779815674, b1: 4.486689567565918\n",
      "JGrad: tensor([0.1607]),  bGrad: tensor([2.6003, 1.5723])\n",
      "J: 11.604686737060547,  b0: -3.5834195613861084, b1: 4.470271587371826\n",
      "JGrad: tensor([-0.0262]),  bGrad: tensor([0.3504, 0.3402])\n",
      "J: 11.591096878051758,  b0: -3.6117186546325684, b1: 4.452462673187256\n",
      "JGrad: tensor([0.0067]),  bGrad: tensor([-0.1332, -0.2707])\n",
      ">>>\t epoch 47:: loss = 0.13198940455913544, validation loss = 0.2596363127231598\n",
      "J: 11.578524589538574,  b0: -3.6363868713378906, b1: 4.438821792602539\n",
      "JGrad: tensor([-0.1726]),  bGrad: tensor([-1.1627, -0.6517])\n",
      "J: 11.575716972351074,  b0: -3.651365041732788, b1: 4.432326793670654\n",
      "JGrad: tensor([-0.1049]),  bGrad: tensor([-1.3875, -0.9947])\n",
      "J: 11.578363418579102,  b0: -3.656212568283081, b1: 4.43532133102417\n",
      "JGrad: tensor([-0.2013]),  bGrad: tensor([-1.5408, -0.8806])\n",
      "J: 11.590679168701172,  b0: -3.650984287261963, b1: 4.445847511291504\n",
      "JGrad: tensor([-0.1369]),  bGrad: tensor([-1.8987, -1.3040])\n",
      "J: 11.608530044555664,  b0: -3.6344666481018066, b1: 4.466908931732178\n",
      "JGrad: tensor([-0.1979]),  bGrad: tensor([-1.6177, -0.9271])\n",
      "J: 11.634369850158691,  b0: -3.6095356941223145, b1: 4.494114398956299\n",
      "JGrad: tensor([-0.1683]),  bGrad: tensor([0.0471, 0.4032])\n",
      "J: 11.665945053100586,  b0: -3.587367057800293, b1: 4.515033721923828\n",
      "JGrad: tensor([0.0613]),  bGrad: tensor([1.8839, 1.2742])\n",
      "J: 11.691361427307129,  b0: -3.579153299331665, b1: 4.522518634796143\n",
      "JGrad: tensor([0.2550]),  bGrad: tensor([2.7312, 1.4204])\n",
      "J: 11.70162296295166,  b0: -3.5887465476989746, b1: 4.516621112823486\n",
      "JGrad: tensor([0.2751]),  bGrad: tensor([2.4113, 1.1521])\n",
      "J: 11.697269439697266,  b0: -3.6123316287994385, b1: 4.50106954574585\n",
      "JGrad: tensor([0.0573]),  bGrad: tensor([ 0.1573, -0.0580])\n",
      "J: 11.690516471862793,  b0: -3.6345584392547607, b1: 4.487574100494385\n",
      "JGrad: tensor([-0.1260]),  bGrad: tensor([-0.0765,  0.1859])\n",
      "J: 11.69066333770752,  b0: -3.654108762741089, b1: 4.473758697509766\n",
      "JGrad: tensor([-0.0442]),  bGrad: tensor([-1.2410, -1.0507])\n",
      "J: 11.692985534667969,  b0: -3.6639907360076904, b1: 4.470686912536621\n",
      "JGrad: tensor([-0.1326]),  bGrad: tensor([-1.2410, -0.7420])\n",
      ">>>\t epoch 48:: loss = 0.1921142041683197, validation loss = 0.25058430433273315\n",
      "J: 11.70164680480957,  b0: -3.6651644706726074, b1: 4.474536895751953\n",
      "JGrad: tensor([0.0896]),  bGrad: tensor([-0.7854, -1.0324])\n",
      "J: 11.705008506774902,  b0: -3.6613292694091797, b1: 4.487209320068359\n",
      "JGrad: tensor([-0.1599]),  bGrad: tensor([-1.7483, -1.1522])\n",
      "J: 11.71596622467041,  b0: -3.6469898223876953, b1: 4.508889198303223\n",
      "JGrad: tensor([-0.1769]),  bGrad: tensor([-1.1155, -0.5363])\n",
      "J: 11.73460578918457,  b0: -3.6271259784698486, b1: 4.533203601837158\n",
      "JGrad: tensor([0.0302]),  bGrad: tensor([ 0.0572, -0.0575])\n",
      "J: 11.749900817871094,  b0: -3.609586477279663, b1: 4.555624008178711\n",
      "JGrad: tensor([0.0941]),  bGrad: tensor([1.1753, 0.6348])\n",
      "J: 11.758999824523926,  b0: -3.601128101348877, b1: 4.570141315460205\n",
      "JGrad: tensor([0.0804]),  bGrad: tensor([2.1469, 1.4336])\n",
      "J: 11.763195037841797,  b0: -3.60690975189209, b1: 4.570388317108154\n",
      "JGrad: tensor([0.1069]),  bGrad: tensor([2.3301, 1.5157])\n",
      "J: 11.761651992797852,  b0: -3.626620054244995, b1: 4.557079315185547\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([1.4626, 1.1185])\n",
      "J: 11.760186195373535,  b0: -3.6534738540649414, b1: 4.535116195678711\n",
      "JGrad: tensor([-0.1552]),  bGrad: tensor([-1.1783, -0.6236])\n",
      "J: 11.766603469848633,  b0: -3.6703100204467773, b1: 4.5209059715271\n",
      "JGrad: tensor([0.0473]),  bGrad: tensor([-2.1789, -1.9673])\n",
      "J: 11.770024299621582,  b0: -3.6718809604644775, b1: 4.525681972503662\n",
      "JGrad: tensor([-0.0368]),  bGrad: tensor([-0.1007, -0.0786])\n",
      "J: 11.774944305419922,  b0: -3.67266845703125, b1: 4.530686378479004\n",
      "JGrad: tensor([-0.1262]),  bGrad: tensor([-0.8987, -0.4761])\n",
      "J: 11.785685539245605,  b0: -3.667771100997925, b1: 4.539445877075195\n",
      "JGrad: tensor([-0.1420]),  bGrad: tensor([0.3281, 0.5822])\n",
      ">>>\t epoch 49:: loss = 0.11459629237651825, validation loss = 0.19549056887626648\n",
      "J: 11.802459716796875,  b0: -3.665408134460449, b1: 4.5421319007873535\n",
      "JGrad: tensor([-0.0951]),  bGrad: tensor([-0.9680, -0.6223])\n",
      "J: 11.82232666015625,  b0: -3.657231092453003, b1: 4.550117492675781\n",
      "JGrad: tensor([-0.0058]),  bGrad: tensor([-0.5079, -0.4207])\n",
      "J: 11.840516090393066,  b0: -3.6466877460479736, b1: 4.561077117919922\n",
      "JGrad: tensor([0.0735]),  bGrad: tensor([ 0.1791, -0.0678])\n",
      "J: 11.853216171264648,  b0: -3.638310194015503, b1: 4.571558952331543\n",
      "JGrad: tensor([0.1632]),  bGrad: tensor([2.3340, 1.3529])\n",
      "J: 11.856460571289062,  b0: -3.6453757286071777, b1: 4.568869113922119\n",
      "JGrad: tensor([0.0948]),  bGrad: tensor([0.8463, 0.4091])\n",
      "J: 11.85462474822998,  b0: -3.6570358276367188, b1: 4.562777519226074\n",
      "JGrad: tensor([0.1921]),  bGrad: tensor([0.7731, 0.1020])\n",
      "J: 11.8433256149292,  b0: -3.6723806858062744, b1: 4.5563740730285645\n",
      "JGrad: tensor([-0.0514]),  bGrad: tensor([1.7511, 1.4515])\n",
      "J: 11.835731506347656,  b0: -3.6971538066864014, b1: 4.537596702575684\n",
      "JGrad: tensor([-0.2220]),  bGrad: tensor([-2.5798, -1.6534])\n",
      "J: 11.840056419372559,  b0: -3.7032837867736816, b1: 4.535528659820557\n",
      "JGrad: tensor([-0.0842]),  bGrad: tensor([-0.3388, -0.1649])\n",
      "J: 11.848188400268555,  b0: -3.70668625831604, b1: 4.535143852233887\n",
      "JGrad: tensor([-0.1669]),  bGrad: tensor([-1.7398, -1.1206])\n",
      "J: 11.863905906677246,  b0: -3.6988625526428223, b1: 4.544845104217529\n",
      "JGrad: tensor([-0.2403]),  bGrad: tensor([-1.6382, -0.8184])\n",
      "J: 11.890129089355469,  b0: -3.681572675704956, b1: 4.560922622680664\n",
      "JGrad: tensor([-0.1019]),  bGrad: tensor([-0.3749, -0.1314])\n",
      "J: 11.918876647949219,  b0: -3.6636481285095215, b1: 4.576587200164795\n",
      "JGrad: tensor([0.1749]),  bGrad: tensor([1.8560, 1.0084])\n",
      ">>>\t epoch 50:: loss = 0.31587356328964233, validation loss = 0.19762195646762848\n",
      "J: 11.935949325561523,  b0: -3.6591410636901855, b1: 4.581630229949951\n",
      "JGrad: tensor([0.0671]),  bGrad: tensor([0.6748, 0.3566])\n",
      "J: 11.947949409484863,  b0: -3.6593093872070312, b1: 4.582967758178711\n",
      "JGrad: tensor([0.1942]),  bGrad: tensor([1.5068, 0.6665])\n",
      "J: 11.948965072631836,  b0: -3.66890287399292, b1: 4.578176021575928\n",
      "JGrad: tensor([0.1228]),  bGrad: tensor([ 0.0840, -0.2819])\n",
      "J: 11.94368839263916,  b0: -3.678072929382324, b1: 4.5763983726501465\n",
      "JGrad: tensor([0.0563]),  bGrad: tensor([-0.0983, -0.2575])\n",
      "J: 11.93609619140625,  b0: -3.6857173442840576, b1: 4.577117919921875\n",
      "JGrad: tensor([0.1748]),  bGrad: tensor([-0.5350, -0.9467])\n",
      "J: 11.92043685913086,  b0: -3.6892411708831787, b1: 4.586302280426025\n",
      "JGrad: tensor([0.2021]),  bGrad: tensor([1.1426, 0.3416])\n",
      "J: 11.89614486694336,  b0: -3.699599027633667, b1: 4.591493129730225\n",
      "JGrad: tensor([-0.1026]),  bGrad: tensor([0.2793, 0.4381])\n",
      "J: 11.879447937011719,  b0: -3.710688352584839, b1: 4.592211723327637\n",
      "JGrad: tensor([-0.0703]),  bGrad: tensor([0.4715, 0.4898])\n",
      "J: 11.867962837219238,  b0: -3.723649263381958, b1: 4.588430881500244\n",
      "JGrad: tensor([-0.1221]),  bGrad: tensor([-1.4602, -0.9403])\n",
      "J: 11.863795280456543,  b0: -3.726114511489868, b1: 4.593530178070068\n",
      "JGrad: tensor([-0.0973]),  bGrad: tensor([-0.7058, -0.3932])\n",
      "J: 11.864970207214355,  b0: -3.723883628845215, b1: 4.601682662963867\n",
      "JGrad: tensor([-0.2764]),  bGrad: tensor([-1.0075, -0.1646])\n",
      "J: 11.880006790161133,  b0: -3.7155168056488037, b1: 4.610518455505371\n",
      "JGrad: tensor([-0.2620]),  bGrad: tensor([-0.5032,  0.1772])\n",
      "J: 11.90677261352539,  b0: -3.704801321029663, b1: 4.616871356964111\n",
      "JGrad: tensor([-0.0860]),  bGrad: tensor([-0.4343, -0.1982])\n",
      ">>>\t epoch 51:: loss = 0.3346271216869354, validation loss = 0.1894940882921219\n",
      "J: 11.935232162475586,  b0: -3.6924023628234863, b1: 4.624393939971924\n",
      "JGrad: tensor([0.1045]),  bGrad: tensor([1.6077, 0.9832])\n",
      "J: 11.955574989318848,  b0: -3.691408395767212, b1: 4.622237682342529\n",
      "JGrad: tensor([0.0756]),  bGrad: tensor([0.3464, 0.0728])\n",
      "J: 11.97006893157959,  b0: -3.6927056312561035, b1: 4.619633674621582\n",
      "JGrad: tensor([0.0649]),  bGrad: tensor([1.5894, 1.0854])\n",
      "J: 11.979833602905273,  b0: -3.7039318084716797, b1: 4.607423782348633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0191]),  bGrad: tensor([-0.7339, -0.5849])\n",
      "J: 11.98960018157959,  b0: -3.709395408630371, b1: 4.601747989654541\n",
      "JGrad: tensor([0.1620]),  bGrad: tensor([ 0.3232, -0.2018])\n",
      "J: 11.990168571472168,  b0: -3.7163665294647217, b1: 4.5984721183776855\n",
      "JGrad: tensor([-0.1329]),  bGrad: tensor([-0.4956, -0.1355])\n",
      "J: 11.997431755065918,  b0: -3.719501256942749, b1: 4.596756458282471\n",
      "JGrad: tensor([-0.1143]),  bGrad: tensor([-1.2349, -0.7982])\n",
      "J: 12.009783744812012,  b0: -3.714484214782715, b1: 4.6024909019470215\n",
      "JGrad: tensor([0.2863]),  bGrad: tensor([-0.1499, -0.9156])\n",
      "J: 12.00634479522705,  b0: -3.7090113162994385, b1: 4.616006374359131\n",
      "JGrad: tensor([0.1416]),  bGrad: tensor([-0.4521, -0.7846])\n",
      "J: 11.996052742004395,  b0: -3.7012057304382324, b1: 4.6353373527526855\n",
      "JGrad: tensor([0.0163]),  bGrad: tensor([0.1727, 0.0713])\n",
      "J: 11.985950469970703,  b0: -3.6952733993530273, b1: 4.652101039886475\n",
      "JGrad: tensor([0.0018]),  bGrad: tensor([0.9369, 0.6950])\n",
      "J: 11.976757049560547,  b0: -3.695899724960327, b1: 4.660844326019287\n",
      "JGrad: tensor([0.0537]),  bGrad: tensor([1.0024, 0.5942])\n",
      "J: 11.965739250183105,  b0: -3.702854633331299, b1: 4.663282871246338\n",
      "JGrad: tensor([-0.0451]),  bGrad: tensor([1.1992, 1.0185])\n",
      ">>>\t epoch 52:: loss = 0.1226065382361412, validation loss = 0.1966666281223297\n",
      "J: 11.958112716674805,  b0: -3.7167649269104004, b1: 4.656158924102783\n",
      "JGrad: tensor([-0.2740]),  bGrad: tensor([0.3371, 0.8999])\n",
      "J: 11.965216636657715,  b0: -3.7314484119415283, b1: 4.641509056091309\n",
      "JGrad: tensor([-0.0969]),  bGrad: tensor([-0.5477, -0.2700])\n",
      "J: 11.976554870605469,  b0: -3.741175651550293, b1: 4.6307854652404785\n",
      "JGrad: tensor([-0.2765]),  bGrad: tensor([-1.4479, -0.5402])\n",
      "J: 12.000839233398438,  b0: -3.740678071975708, b1: 4.62608003616333\n",
      "JGrad: tensor([-0.0720]),  bGrad: tensor([0.3029, 0.3505])\n",
      "J: 12.026388168334961,  b0: -3.7421674728393555, b1: 4.618624687194824\n",
      "JGrad: tensor([-0.1977]),  bGrad: tensor([-1.3228, -0.6597])\n",
      "J: 12.059462547302246,  b0: -3.735044002532959, b1: 4.6179680824279785\n",
      "JGrad: tensor([0.0631]),  bGrad: tensor([-0.1674, -0.3385])\n",
      "J: 12.086036682128906,  b0: -3.7275540828704834, b1: 4.620487689971924\n",
      "JGrad: tensor([0.1630]),  bGrad: tensor([-0.4378, -0.8316])\n",
      "J: 12.101638793945312,  b0: -3.7180001735687256, b1: 4.6304030418396\n",
      "JGrad: tensor([0.1755]),  bGrad: tensor([0.5950, 0.0015])\n",
      "J: 12.106719970703125,  b0: -3.713212251663208, b1: 4.639321327209473\n",
      "JGrad: tensor([0.1519]),  bGrad: tensor([0.8785, 0.2889])\n",
      "J: 12.103531837463379,  b0: -3.71454119682312, b1: 4.6446943283081055\n",
      "JGrad: tensor([0.1645]),  bGrad: tensor([-0.0151, -0.4565])\n",
      "J: 12.092254638671875,  b0: -3.7156412601470947, b1: 4.653743267059326\n",
      "JGrad: tensor([0.0742]),  bGrad: tensor([0.6893, 0.3286])\n",
      "J: 12.078301429748535,  b0: -3.721066474914551, b1: 4.658862113952637\n",
      "JGrad: tensor([0.1407]),  bGrad: tensor([0.9982, 0.4015])\n",
      "J: 12.0585355758667,  b0: -3.732377052307129, b1: 4.659764289855957\n",
      "JGrad: tensor([0.0100]),  bGrad: tensor([1.2159, 0.9303])\n",
      ">>>\t epoch 53:: loss = 0.2151816189289093, validation loss = 0.19028133153915405\n",
      "J: 12.040214538574219,  b0: -3.750389575958252, b1: 4.651981353759766\n",
      "JGrad: tensor([-0.1961]),  bGrad: tensor([-0.3672,  0.1295])\n",
      "J: 12.033771514892578,  b0: -3.764249801635742, b1: 4.643772125244141\n",
      "JGrad: tensor([-0.2664]),  bGrad: tensor([-0.7767,  0.0101])\n",
      "J: 12.041609764099121,  b0: -3.771723508834839, b1: 4.6362833976745605\n",
      "JGrad: tensor([-0.0975]),  bGrad: tensor([-0.7242, -0.4093])\n",
      "J: 12.05366039276123,  b0: -3.773780345916748, b1: 4.633329391479492\n",
      "JGrad: tensor([0.0336]),  bGrad: tensor([-0.2598, -0.3873])\n",
      "J: 12.062795639038086,  b0: -3.773954391479492, b1: 4.634260654449463\n",
      "JGrad: tensor([-0.0496]),  bGrad: tensor([-1.8040, -1.4095])\n",
      "J: 12.073569297790527,  b0: -3.762458562850952, b1: 4.648159980773926\n",
      "JGrad: tensor([-0.1139]),  bGrad: tensor([-0.1205,  0.1181])\n",
      "J: 12.089118957519531,  b0: -3.7513227462768555, b1: 4.659585952758789\n",
      "JGrad: tensor([-0.1023]),  bGrad: tensor([0.5129, 0.5891])\n",
      "J: 12.108377456665039,  b0: -3.7446107864379883, b1: 4.664408206939697\n",
      "JGrad: tensor([-0.0343]),  bGrad: tensor([-0.3110, -0.1863])\n",
      "J: 12.127493858337402,  b0: -3.7365498542785645, b1: 4.670483112335205\n",
      "JGrad: tensor([0.0827]),  bGrad: tensor([0.3444, 0.0439])\n",
      "J: 12.140456199645996,  b0: -3.7315213680267334, b1: 4.675548076629639\n",
      "JGrad: tensor([0.1092]),  bGrad: tensor([ 0.3699, -0.0050])\n",
      "J: 12.146504402160645,  b0: -3.7293920516967773, b1: 4.680157661437988\n",
      "JGrad: tensor([0.1522]),  bGrad: tensor([1.0075, 0.3891])\n",
      "J: 12.144107818603516,  b0: -3.7340166568756104, b1: 4.6806840896606445\n",
      "JGrad: tensor([0.1353]),  bGrad: tensor([0.8535, 0.3055])\n",
      "J: 12.134973526000977,  b0: -3.743727445602417, b1: 4.678309440612793\n",
      "JGrad: tensor([0.1181]),  bGrad: tensor([1.1883, 0.6258])\n",
      ">>>\t epoch 54:: loss = 0.28417763113975525, validation loss = 0.18160636723041534\n",
      "J: 12.120654106140137,  b0: -3.760195255279541, b1: 4.67033052444458\n",
      "JGrad: tensor([-0.1441]),  bGrad: tensor([-0.1131,  0.2006])\n",
      "J: 12.115196228027344,  b0: -3.774294853210449, b1: 4.66126823425293\n",
      "JGrad: tensor([-0.1677]),  bGrad: tensor([-0.5538, -0.0780])\n",
      "J: 12.118941307067871,  b0: -3.783388614654541, b1: 4.653833866119385\n",
      "JGrad: tensor([-0.2142]),  bGrad: tensor([-0.3030,  0.2103])\n",
      "J: 12.1333646774292,  b0: -3.7896058559417725, b1: 4.645168304443359\n",
      "JGrad: tensor([-0.0871]),  bGrad: tensor([-1.4843, -1.0518])\n",
      "J: 12.150856971740723,  b0: -3.7855255603790283, b1: 4.647214412689209\n",
      "JGrad: tensor([-0.1599]),  bGrad: tensor([-2.0744, -1.3650])\n",
      "J: 12.17486572265625,  b0: -3.7683441638946533, b1: 4.661823749542236\n",
      "JGrad: tensor([0.1718]),  bGrad: tensor([ 0.2913, -0.2563])\n",
      "J: 12.187601089477539,  b0: -3.754765510559082, b1: 4.677384376525879\n",
      "JGrad: tensor([0.1077]),  bGrad: tensor([1.2411, 0.6926])\n",
      "J: 12.193501472473145,  b0: -3.7506353855133057, b1: 4.684908866882324\n",
      "JGrad: tensor([0.0585]),  bGrad: tensor([0.8874, 0.5431])\n",
      "J: 12.195788383483887,  b0: -3.7527074813842773, b1: 4.686594009399414\n",
      "JGrad: tensor([0.1458]),  bGrad: tensor([0.8345, 0.2618])\n",
      "J: 12.190295219421387,  b0: -3.760023593902588, b1: 4.68565559387207\n",
      "JGrad: tensor([0.1379]),  bGrad: tensor([ 0.2210, -0.2074])\n",
      "J: 12.178203582763672,  b0: -3.768059015274048, b1: 4.686758518218994\n",
      "JGrad: tensor([0.1101]),  bGrad: tensor([-0.5569, -0.7692])\n",
      "J: 12.161605834960938,  b0: -3.771653413772583, b1: 4.694979667663574\n",
      "JGrad: tensor([-0.1314]),  bGrad: tensor([0.0763, 0.3251])\n",
      "J: 12.153475761413574,  b0: -3.775391101837158, b1: 4.6993279457092285\n",
      "JGrad: tensor([-0.1981]),  bGrad: tensor([-1.6450, -0.9176])\n",
      ">>>\t epoch 55:: loss = 0.18777041137218475, validation loss = 0.18203262984752655\n",
      "J: 12.156434059143066,  b0: -3.7679827213287354, b1: 4.7118754386901855\n",
      "JGrad: tensor([0.0174]),  bGrad: tensor([1.3167, 0.9842])\n",
      "J: 12.158194541931152,  b0: -3.76993727684021, b1: 4.713909149169922\n",
      "JGrad: tensor([0.1954]),  bGrad: tensor([1.1354, 0.3683])\n",
      "J: 12.149632453918457,  b0: -3.779137134552002, b1: 4.712272644042969\n",
      "JGrad: tensor([-0.0842]),  bGrad: tensor([1.1654, 1.0839])\n",
      "J: 12.1462984085083,  b0: -3.795060157775879, b1: 4.700592994689941\n",
      "JGrad: tensor([-0.1474]),  bGrad: tensor([-0.6475, -0.1969])\n",
      "J: 12.150957107543945,  b0: -3.80515456199646, b1: 4.691927433013916\n",
      "JGrad: tensor([0.0433]),  bGrad: tensor([-0.3856, -0.5125])\n",
      "J: 12.152899742126465,  b0: -3.811715602874756, b1: 4.688957214355469\n",
      "JGrad: tensor([-0.0076]),  bGrad: tensor([-1.2118, -1.0328])\n",
      "J: 12.155047416687012,  b0: -3.809662342071533, b1: 4.69602632522583\n",
      "JGrad: tensor([-0.1713]),  bGrad: tensor([-1.3036, -0.6973])\n",
      "J: 12.165905952453613,  b0: -3.799248456954956, b1: 4.708973407745361\n",
      "JGrad: tensor([-0.1871]),  bGrad: tensor([-0.5160,  0.0076])\n",
      "J: 12.185423851013184,  b0: -3.7864747047424316, b1: 4.720565319061279\n",
      "JGrad: tensor([-0.0100]),  bGrad: tensor([0.4520, 0.3332])\n",
      "J: 12.203529357910156,  b0: -3.7779433727264404, b1: 4.727855682373047\n",
      "JGrad: tensor([0.0913]),  bGrad: tensor([-0.0595, -0.3050])\n",
      "J: 12.215069770812988,  b0: -3.7698655128479004, b1: 4.73730993270874\n",
      "JGrad: tensor([0.0810]),  bGrad: tensor([0.7871, 0.3984])\n",
      "J: 12.221235275268555,  b0: -3.7677793502807617, b1: 4.74205207824707\n",
      "JGrad: tensor([-0.0741]),  bGrad: tensor([0.9924, 0.8998])\n",
      "J: 12.230664253234863,  b0: -3.772447109222412, b1: 4.737795829772949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.1029]),  bGrad: tensor([1.8763, 1.7147])\n",
      ">>>\t epoch 56:: loss = 0.33618149161338806, validation loss = 0.1792566329240799\n",
      "J: 12.244538307189941,  b0: -3.7890172004699707, b1: 4.7177510261535645\n",
      "JGrad: tensor([0.1022]),  bGrad: tensor([1.0611, 0.5484])\n",
      "J: 12.251686096191406,  b0: -3.8109371662139893, b1: 4.694506645202637\n",
      "JGrad: tensor([0.0465]),  bGrad: tensor([0.2731, 0.0271])\n",
      "J: 12.25568675994873,  b0: -3.832486867904663, b1: 4.673309803009033\n",
      "JGrad: tensor([-0.1087]),  bGrad: tensor([-1.4429, -1.0076])\n",
      "J: 12.264986991882324,  b0: -3.842355489730835, b1: 4.6637797355651855\n",
      "JGrad: tensor([-0.0922]),  bGrad: tensor([-1.6950, -1.2509])\n",
      "J: 12.278197288513184,  b0: -3.840045213699341, b1: 4.667055130004883\n",
      "JGrad: tensor([-0.1623]),  bGrad: tensor([-0.9886, -0.5161])\n",
      "J: 12.298604965209961,  b0: -3.831434726715088, b1: 4.674898147583008\n",
      "JGrad: tensor([-0.0353]),  bGrad: tensor([-1.0612, -0.9069])\n",
      "J: 12.318842887878418,  b0: -3.8166680335998535, b1: 4.690557956695557\n",
      "JGrad: tensor([0.2348]),  bGrad: tensor([ 0.3472, -0.3619])\n",
      "J: 12.324721336364746,  b0: -3.8056626319885254, b1: 4.7080979347229\n",
      "JGrad: tensor([0.0684]),  bGrad: tensor([-0.0674, -0.2659])\n",
      "J: 12.326424598693848,  b0: -3.795301675796509, b1: 4.726423263549805\n",
      "JGrad: tensor([-0.0577]),  bGrad: tensor([-0.3261, -0.1282])\n",
      "J: 12.33099365234375,  b0: -3.7838075160980225, b1: 4.7441511154174805\n",
      "JGrad: tensor([0.0062]),  bGrad: tensor([0.7565, 0.5671])\n",
      "J: 12.334785461425781,  b0: -3.778472423553467, b1: 4.754721641540527\n",
      "JGrad: tensor([0.1393]),  bGrad: tensor([1.9292, 1.1277])\n",
      "J: 12.330865859985352,  b0: -3.7864599227905273, b1: 4.753506183624268\n",
      "JGrad: tensor([0.1427]),  bGrad: tensor([0.7009, 0.1639])\n",
      "J: 12.319819450378418,  b0: -3.7983031272888184, b1: 4.750850677490234\n",
      "JGrad: tensor([-0.0261]),  bGrad: tensor([0.4177, 0.3850])\n",
      ">>>\t epoch 57:: loss = 0.11803826689720154, validation loss = 0.17787756025791168\n",
      "J: 12.31124496459961,  b0: -3.811743974685669, b1: 4.744790554046631\n",
      "JGrad: tensor([0.0913]),  bGrad: tensor([0.8144, 0.4003])\n",
      "J: 12.298702239990234,  b0: -3.829258918762207, b1: 4.735513687133789\n",
      "JGrad: tensor([-0.0184]),  bGrad: tensor([-0.1716, -0.1794])\n",
      "J: 12.288374900817871,  b0: -3.8438966274261475, b1: 4.7288689613342285\n",
      "JGrad: tensor([0.0392]),  bGrad: tensor([-1.5184, -1.4263])\n",
      "J: 12.276998519897461,  b0: -3.8469738960266113, b1: 4.7364983558654785\n",
      "JGrad: tensor([-0.0999]),  bGrad: tensor([-0.6834, -0.3663])\n",
      "J: 12.272035598754883,  b0: -3.8451976776123047, b1: 4.746868133544922\n",
      "JGrad: tensor([-0.1322]),  bGrad: tensor([-0.2679,  0.0598])\n",
      "J: 12.274564743041992,  b0: -3.841813564300537, b1: 4.755638599395752\n",
      "JGrad: tensor([-0.1528]),  bGrad: tensor([-0.3480,  0.0552])\n",
      "J: 12.284929275512695,  b0: -3.8364453315734863, b1: 4.7630109786987305\n",
      "JGrad: tensor([-0.1346]),  bGrad: tensor([-0.6847, -0.2783])\n",
      "J: 12.301390647888184,  b0: -3.827042579650879, b1: 4.7723164558410645\n",
      "JGrad: tensor([-0.1967]),  bGrad: tensor([-1.0496, -0.4207])\n",
      "J: 12.326623916625977,  b0: -3.811570167541504, b1: 4.784728527069092\n",
      "JGrad: tensor([0.0318]),  bGrad: tensor([1.4413, 1.0374])\n",
      "J: 12.347670555114746,  b0: -3.807264566421509, b1: 4.785961151123047\n",
      "JGrad: tensor([0.0846]),  bGrad: tensor([ 0.2741, -0.0295])\n",
      "J: 12.362139701843262,  b0: -3.8052175045013428, b1: 4.787354946136475\n",
      "JGrad: tensor([0.0761]),  bGrad: tensor([0.6035, 0.2710])\n",
      "J: 12.371132850646973,  b0: -3.8074090480804443, b1: 4.786009311676025\n",
      "JGrad: tensor([0.1170]),  bGrad: tensor([0.8899, 0.3807])\n",
      "J: 12.373016357421875,  b0: -3.815336227416992, b1: 4.781140327453613\n",
      "JGrad: tensor([0.1516]),  bGrad: tensor([1.2812, 0.6074])\n",
      ">>>\t epoch 58:: loss = 0.26116496324539185, validation loss = 0.17709539830684662\n",
      "J: 12.366657257080078,  b0: -3.8310468196868896, b1: 4.7709174156188965\n",
      "JGrad: tensor([-0.0119]),  bGrad: tensor([-0.3733, -0.3073])\n",
      "J: 12.36155891418457,  b0: -3.842698335647583, b1: 4.764665126800537\n",
      "JGrad: tensor([-0.1296]),  bGrad: tensor([-0.1876,  0.1152])\n",
      "J: 12.36386775970459,  b0: -3.8519365787506104, b1: 4.757923603057861\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([-0.4225, -0.4350])\n",
      "J: 12.36589527130127,  b0: -3.8574230670928955, b1: 4.756043434143066\n",
      "JGrad: tensor([-0.1320]),  bGrad: tensor([0.3261, 0.5353])\n",
      "J: 12.374755859375,  b0: -3.864555597305298, b1: 4.749188423156738\n",
      "JGrad: tensor([-0.2746]),  bGrad: tensor([-1.6106, -0.6736])\n",
      "J: 12.397343635559082,  b0: -3.8601584434509277, b1: 4.749515056610107\n",
      "JGrad: tensor([-0.1505]),  bGrad: tensor([-0.8963, -0.4141])\n",
      "J: 12.42569351196289,  b0: -3.8501760959625244, b1: 4.753807544708252\n",
      "JGrad: tensor([0.1896]),  bGrad: tensor([-0.2521, -0.7419])\n",
      "J: 12.441112518310547,  b0: -3.8394882678985596, b1: 4.764840126037598\n",
      "JGrad: tensor([0.1116]),  bGrad: tensor([ 0.2384, -0.1336])\n",
      "J: 12.449048042297363,  b0: -3.831465482711792, b1: 4.776070594787598\n",
      "JGrad: tensor([0.0957]),  bGrad: tensor([ 0.2733, -0.0435])\n",
      "J: 12.451089859008789,  b0: -3.826079845428467, b1: 4.786608695983887\n",
      "JGrad: tensor([0.1320]),  bGrad: tensor([0.6329, 0.1491])\n",
      "J: 12.445884704589844,  b0: -3.8254969120025635, b1: 4.7946577072143555\n",
      "JGrad: tensor([0.0189]),  bGrad: tensor([0.7891, 0.5595])\n",
      "J: 12.440183639526367,  b0: -3.830296277999878, b1: 4.796482563018799\n",
      "JGrad: tensor([0.0614]),  bGrad: tensor([1.2227, 0.7972])\n",
      "J: 12.431768417358398,  b0: -3.8428690433502197, b1: 4.790395259857178\n",
      "JGrad: tensor([0.0697]),  bGrad: tensor([0.8397, 0.4721])\n",
      ">>>\t epoch 59:: loss = 0.1664283573627472, validation loss = 0.17876377701759338\n",
      "J: 12.420458793640137,  b0: -3.859863042831421, b1: 4.780330657958984\n",
      "JGrad: tensor([-0.2046]),  bGrad: tensor([-0.4821,  0.0703])\n",
      "J: 12.421226501464844,  b0: -3.8719122409820557, b1: 4.7705817222595215\n",
      "JGrad: tensor([0.0450]),  bGrad: tensor([-0.0697, -0.2405])\n",
      "J: 12.419507026672363,  b0: -3.8822953701019287, b1: 4.764138221740723\n",
      "JGrad: tensor([-0.1032]),  bGrad: tensor([-0.3866, -0.1372])\n",
      "J: 12.423487663269043,  b0: -3.8890302181243896, b1: 4.759669303894043\n",
      "JGrad: tensor([-0.1514]),  bGrad: tensor([-1.1574, -0.6165])\n",
      "J: 12.435185432434082,  b0: -3.887253761291504, b1: 4.7616472244262695\n",
      "JGrad: tensor([-0.0584]),  bGrad: tensor([-1.1385, -0.8414])\n",
      "J: 12.44885540008545,  b0: -3.877939224243164, b1: 4.771623134613037\n",
      "JGrad: tensor([-0.1235]),  bGrad: tensor([-1.5268, -0.9913])\n",
      "J: 12.467790603637695,  b0: -3.859210968017578, b1: 4.790257453918457\n",
      "JGrad: tensor([0.1100]),  bGrad: tensor([0.5488, 0.1091])\n",
      "J: 12.478935241699219,  b0: -3.8460638523101807, b1: 4.8059797286987305\n",
      "JGrad: tensor([0.1066]),  bGrad: tensor([0.7544, 0.3090])\n",
      "J: 12.483243942260742,  b0: -3.8393430709838867, b1: 4.817126274108887\n",
      "JGrad: tensor([0.1320]),  bGrad: tensor([1.2592, 0.6457])\n",
      "J: 12.48002815246582,  b0: -3.8418400287628174, b1: 4.820859909057617\n",
      "JGrad: tensor([0.0318]),  bGrad: tensor([ 0.1126, -0.0080])\n",
      "J: 12.475419998168945,  b0: -3.8448543548583984, b1: 4.824301242828369\n",
      "JGrad: tensor([0.0450]),  bGrad: tensor([0.8327, 0.5215])\n",
      "J: 12.468847274780273,  b0: -3.8532299995422363, b1: 4.822300910949707\n",
      "JGrad: tensor([0.1504]),  bGrad: tensor([-0.0449, -0.4439])\n",
      "J: 12.454829216003418,  b0: -3.8604695796966553, b1: 4.824843406677246\n",
      "JGrad: tensor([0.0060]),  bGrad: tensor([0.1903, 0.1017])\n",
      ">>>\t epoch 60:: loss = 0.23794573545455933, validation loss = 0.17615747451782227\n",
      "J: 12.441875457763672,  b0: -3.8682870864868164, b1: 4.826138019561768\n",
      "JGrad: tensor([-0.2166]),  bGrad: tensor([-0.8130, -0.1644])\n",
      "J: 12.44189167022705,  b0: -3.8697867393493652, b1: 4.828915596008301\n",
      "JGrad: tensor([-0.3073]),  bGrad: tensor([-0.3479,  0.4429])\n",
      "J: 12.458440780639648,  b0: -3.868764638900757, b1: 4.8270721435546875\n",
      "JGrad: tensor([-0.0416]),  bGrad: tensor([-0.4306, -0.2710])\n",
      "J: 12.4755859375,  b0: -3.8649044036865234, b1: 4.828072547912598\n",
      "JGrad: tensor([0.1062]),  bGrad: tensor([1.2977, 0.7477])\n",
      "J: 12.485304832458496,  b0: -3.8702900409698486, b1: 4.821627616882324\n",
      "JGrad: tensor([0.0809]),  bGrad: tensor([-0.2362, -0.4320])\n",
      "J: 12.489694595336914,  b0: -3.8735272884368896, b1: 4.820070743560791\n",
      "JGrad: tensor([0.1063]),  bGrad: tensor([0.9196, 0.4443])\n",
      "J: 12.487914085388184,  b0: -3.882730484008789, b1: 4.814296722412109\n",
      "JGrad: tensor([0.0439]),  bGrad: tensor([-0.6597, -0.7258])\n",
      "J: 12.483942031860352,  b0: -3.886505365371704, b1: 4.81624174118042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.1164]),  bGrad: tensor([0.1271, 0.3302])\n",
      "J: 12.486655235290527,  b0: -3.8907766342163086, b1: 4.814741134643555\n",
      "JGrad: tensor([-0.1089]),  bGrad: tensor([-1.8001, -1.2761])\n",
      "J: 12.494983673095703,  b0: -3.882295608520508, b1: 4.825955390930176\n",
      "JGrad: tensor([0.1777]),  bGrad: tensor([ 0.0553, -0.4700])\n",
      "J: 12.492874145507812,  b0: -3.875035047531128, b1: 4.840685844421387\n",
      "JGrad: tensor([0.0951]),  bGrad: tensor([1.4892, 0.9268])\n",
      "J: 12.48582935333252,  b0: -3.878704786300659, b1: 4.844812393188477\n",
      "JGrad: tensor([0.1610]),  bGrad: tensor([ 0.3823, -0.1252])\n",
      "J: 12.470775604248047,  b0: -3.884631872177124, b1: 4.849764347076416\n",
      "JGrad: tensor([-0.1403]),  bGrad: tensor([1.0316, 1.1292])\n",
      ">>>\t epoch 61:: loss = 0.20559990406036377, validation loss = 0.1817384660243988\n",
      "J: 12.464818954467773,  b0: -3.8970465660095215, b1: 4.843084335327148\n",
      "JGrad: tensor([0.0294]),  bGrad: tensor([0.6100, 0.3288])\n",
      "J: 12.457860946655273,  b0: -3.9124162197113037, b1: 4.833822250366211\n",
      "JGrad: tensor([-0.1861]),  bGrad: tensor([-0.9335, -0.3283])\n",
      "J: 12.461685180664062,  b0: -3.9198436737060547, b1: 4.82872200012207\n",
      "JGrad: tensor([-0.1076]),  bGrad: tensor([-1.3260, -0.8831])\n",
      "J: 12.470964431762695,  b0: -3.9174184799194336, b1: 4.832855224609375\n",
      "JGrad: tensor([-0.1676]),  bGrad: tensor([-1.1612, -0.5782])\n",
      "J: 12.488404273986816,  b0: -3.907254219055176, b1: 4.8422932624816895\n",
      "JGrad: tensor([-0.0537]),  bGrad: tensor([0.0761, 0.1239])\n",
      "J: 12.507027626037598,  b0: -3.8986215591430664, b1: 4.8495683670043945\n",
      "JGrad: tensor([-0.1459]),  bGrad: tensor([-0.3247,  0.0503])\n",
      "J: 12.531716346740723,  b0: -3.8886096477508545, b1: 4.855624198913574\n",
      "JGrad: tensor([-0.0391]),  bGrad: tensor([0.0222, 0.0907])\n",
      "J: 12.55607795715332,  b0: -3.8797435760498047, b1: 4.860179901123047\n",
      "JGrad: tensor([0.1024]),  bGrad: tensor([1.0331, 0.5445])\n",
      "J: 12.5724515914917,  b0: -3.8788836002349854, b1: 4.858881950378418\n",
      "JGrad: tensor([0.1052]),  bGrad: tensor([0.7632, 0.3157])\n",
      "J: 12.581475257873535,  b0: -3.8833746910095215, b1: 4.854578971862793\n",
      "JGrad: tensor([0.1165]),  bGrad: tensor([0.5749, 0.1323])\n",
      "J: 12.583260536193848,  b0: -3.8913888931274414, b1: 4.849388122558594\n",
      "JGrad: tensor([0.0280]),  bGrad: tensor([0.4570, 0.2672])\n",
      "J: 12.583344459533691,  b0: -3.9017655849456787, b1: 4.842055320739746\n",
      "JGrad: tensor([0.1478]),  bGrad: tensor([ 0.5281, -0.0042])\n",
      "J: 12.575366020202637,  b0: -3.914763927459717, b1: 4.835491180419922\n",
      "JGrad: tensor([-0.1227]),  bGrad: tensor([0.1172, 0.3540])\n",
      ">>>\t epoch 62:: loss = 0.16939373314380646, validation loss = 0.19702032208442688\n",
      "J: 12.574870109558105,  b0: -3.927284002304077, b1: 4.826053142547607\n",
      "JGrad: tensor([-0.1297]),  bGrad: tensor([-0.9220, -0.4589])\n",
      "J: 12.581496238708496,  b0: -3.9321727752685547, b1: 4.822126865386963\n",
      "JGrad: tensor([-0.1358]),  bGrad: tensor([-0.7024, -0.2803])\n",
      "J: 12.594870567321777,  b0: -3.931708335876465, b1: 4.821386337280273\n",
      "JGrad: tensor([-0.1757]),  bGrad: tensor([-1.3876, -0.7535])\n",
      "J: 12.616496086120605,  b0: -3.921673536300659, b1: 4.828239440917969\n",
      "JGrad: tensor([0.1880]),  bGrad: tensor([ 0.0778, -0.4690])\n",
      "J: 12.625700950622559,  b0: -3.9131736755371094, b1: 4.8390960693359375\n",
      "JGrad: tensor([0.1288]),  bGrad: tensor([ 0.1478, -0.2461])\n",
      "J: 12.626955032348633,  b0: -3.906543016433716, b1: 4.851335525512695\n",
      "JGrad: tensor([0.0411]),  bGrad: tensor([0.4807, 0.2544])\n",
      "J: 12.625838279724121,  b0: -3.9039108753204346, b1: 4.8598151206970215\n",
      "JGrad: tensor([0.0255]),  bGrad: tensor([1.3086, 0.9372])\n",
      "J: 12.623435974121094,  b0: -3.910635471343994, b1: 4.858070373535156\n",
      "JGrad: tensor([0.1038]),  bGrad: tensor([ 0.3473, -0.0185])\n",
      "J: 12.615592956542969,  b0: -3.9191081523895264, b1: 4.856683731079102\n",
      "JGrad: tensor([0.1321]),  bGrad: tensor([ 0.0590, -0.3571])\n",
      "J: 12.601296424865723,  b0: -3.9271509647369385, b1: 4.859013557434082\n",
      "JGrad: tensor([-0.0646]),  bGrad: tensor([-0.0958,  0.0031])\n",
      "J: 12.591957092285156,  b0: -3.9337284564971924, b1: 4.861081123352051\n",
      "JGrad: tensor([-0.1145]),  bGrad: tensor([-0.6360, -0.2978])\n",
      "J: 12.589826583862305,  b0: -3.9352176189422607, b1: 4.865932941436768\n",
      "JGrad: tensor([-0.0553]),  bGrad: tensor([-0.9821, -0.7179])\n",
      "J: 12.590940475463867,  b0: -3.9297070503234863, b1: 4.877511978149414\n",
      "JGrad: tensor([-0.4784]),  bGrad: tensor([-3.1406, -1.4073])\n",
      ">>>\t epoch 63:: loss = 0.23933711647987366, validation loss = 0.18862205743789673\n",
      "J: 12.618047714233398,  b0: -3.902928590774536, b1: 4.902045249938965\n",
      "JGrad: tensor([0.1114]),  bGrad: tensor([1.5192, 0.8901])\n",
      "J: 12.63637638092041,  b0: -3.8893918991088867, b1: 4.915196418762207\n",
      "JGrad: tensor([0.0615]),  bGrad: tensor([0.6350, 0.2863])\n",
      "J: 12.64952278137207,  b0: -3.881617546081543, b1: 4.924166202545166\n",
      "JGrad: tensor([0.1881]),  bGrad: tensor([2.1302, 1.1206])\n",
      "J: 12.65107250213623,  b0: -3.889432191848755, b1: 4.920984268188477\n",
      "JGrad: tensor([0.1507]),  bGrad: tensor([1.2605, 0.5353])\n",
      "J: 12.644229888916016,  b0: -3.90522837638855, b1: 4.912739276885986\n",
      "JGrad: tensor([0.1137]),  bGrad: tensor([1.2083, 0.6326])\n",
      "J: 12.63184642791748,  b0: -3.927849769592285, b1: 4.898955345153809\n",
      "JGrad: tensor([0.0411]),  bGrad: tensor([1.2971, 0.9133])\n",
      "J: 12.618444442749023,  b0: -3.9572324752807617, b1: 4.877364635467529\n",
      "JGrad: tensor([-0.2162]),  bGrad: tensor([-1.1848, -0.4742])\n",
      "J: 12.618218421936035,  b0: -3.975442886352539, b1: 4.862691402435303\n",
      "JGrad: tensor([-0.2844]),  bGrad: tensor([-0.3586,  0.3837])\n",
      "J: 12.633559226989746,  b0: -3.989349365234375, b1: 4.845611572265625\n",
      "JGrad: tensor([0.0111]),  bGrad: tensor([ 0.0385, -0.0844])\n",
      "J: 12.646770477294922,  b0: -4.002144813537598, b1: 4.8310770988464355\n",
      "JGrad: tensor([-0.1897]),  bGrad: tensor([-2.3885, -1.5813])\n",
      "J: 12.669036865234375,  b0: -3.99702525138855, b1: 4.833929538726807\n",
      "JGrad: tensor([-0.2493]),  bGrad: tensor([-1.2007, -0.4602])\n",
      "J: 12.702689170837402,  b0: -3.984060764312744, b1: 4.8411335945129395\n",
      "JGrad: tensor([-0.2163]),  bGrad: tensor([-1.5561, -0.8004])\n",
      "J: 12.744783401489258,  b0: -3.9615674018859863, b1: 4.855683326721191\n",
      "JGrad: tensor([0.1344]),  bGrad: tensor([-0.1455, -0.5304])\n",
      ">>>\t epoch 64:: loss = 0.16805797815322876, validation loss = 0.18439246714115143\n",
      "J: 12.775336265563965,  b0: -3.9402921199798584, b1: 4.874134063720703\n",
      "JGrad: tensor([0.1002]),  bGrad: tensor([-0.7236, -0.9070])\n",
      "J: 12.797372817993164,  b0: -3.9160892963409424, b1: 4.899888038635254\n",
      "JGrad: tensor([0.2352]),  bGrad: tensor([0.8611, 0.0557])\n",
      "J: 12.804338455200195,  b0: -3.900298595428467, b1: 4.922524929046631\n",
      "JGrad: tensor([-0.0486]),  bGrad: tensor([0.7846, 0.7168])\n",
      "J: 12.813271522521973,  b0: -3.891552448272705, b1: 4.935669898986816\n",
      "JGrad: tensor([0.1820]),  bGrad: tensor([1.5167, 0.6958])\n",
      "J: 12.811354637145996,  b0: -3.8942625522613525, b1: 4.94047737121582\n",
      "JGrad: tensor([0.2320]),  bGrad: tensor([2.5776, 1.3496])\n",
      "J: 12.796942710876465,  b0: -3.9146435260772705, b1: 4.931179046630859\n",
      "JGrad: tensor([0.1357]),  bGrad: tensor([0.7299, 0.1962])\n",
      "J: 12.776540756225586,  b0: -3.9380838871002197, b1: 4.920821189880371\n",
      "JGrad: tensor([0.0628]),  bGrad: tensor([ 0.1709, -0.0384])\n",
      "J: 12.754727363586426,  b0: -3.9603898525238037, b1: 4.911879062652588\n",
      "JGrad: tensor([0.0631]),  bGrad: tensor([0.2558, 0.0094])\n",
      "J: 12.731624603271484,  b0: -3.982267379760742, b1: 4.90372896194458\n",
      "JGrad: tensor([-0.2082]),  bGrad: tensor([0.7023, 1.0108])\n",
      "J: 12.72224235534668,  b0: -4.006875038146973, b1: 4.886166095733643\n",
      "JGrad: tensor([-0.1546]),  bGrad: tensor([-1.3141, -0.7483])\n",
      "J: 12.722265243530273,  b0: -4.019846439361572, b1: 4.877928733825684\n",
      "JGrad: tensor([-0.1890]),  bGrad: tensor([-1.4565, -0.7717])\n",
      "J: 12.732637405395508,  b0: -4.021347522735596, b1: 4.878326892852783\n",
      "JGrad: tensor([-0.1645]),  bGrad: tensor([-0.4553, -0.0106])\n",
      "J: 12.750986099243164,  b0: -4.019517421722412, b1: 4.878792762756348\n",
      "JGrad: tensor([-0.1069]),  bGrad: tensor([-0.7699, -0.4661])\n",
      ">>>\t epoch 65:: loss = 0.24762658774852753, validation loss = 0.22399798035621643\n",
      "J: 12.773370742797852,  b0: -4.012484073638916, b1: 4.883939743041992\n",
      "JGrad: tensor([0.0184]),  bGrad: tensor([-1.6918, -1.5223])\n",
      "J: 12.792524337768555,  b0: -3.9943277835845947, b1: 4.903986930847168\n",
      "JGrad: tensor([-0.1626]),  bGrad: tensor([0.1380, 0.4669])\n",
      "J: 12.81868839263916,  b0: -3.978938102722168, b1: 4.917308807373047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.2345]),  bGrad: tensor([ 0.0592, -0.6154])\n",
      "J: 12.829360008239746,  b0: -3.9654901027679443, b1: 4.935545921325684\n",
      "JGrad: tensor([0.0622]),  bGrad: tensor([0.3587, 0.1017])\n",
      "J: 12.83555793762207,  b0: -3.9558913707733154, b1: 4.95094108581543\n",
      "JGrad: tensor([0.1171]),  bGrad: tensor([1.1938, 0.6330])\n",
      "J: 12.834708213806152,  b0: -3.955620765686035, b1: 4.958375453948975\n",
      "JGrad: tensor([0.0388]),  bGrad: tensor([0.3641, 0.1745])\n",
      "J: 12.831809043884277,  b0: -3.9579319953918457, b1: 4.9632978439331055\n",
      "JGrad: tensor([0.0803]),  bGrad: tensor([0.6864, 0.3266])\n",
      "J: 12.824779510498047,  b0: -3.9648332595825195, b1: 4.964409351348877\n",
      "JGrad: tensor([0.1159]),  bGrad: tensor([0.7793, 0.3050])\n",
      "J: 12.812068939208984,  b0: -3.9765236377716064, b1: 4.962305068969727\n",
      "JGrad: tensor([0.1111]),  bGrad: tensor([0.6704, 0.2213])\n",
      "J: 12.794507026672363,  b0: -3.991765260696411, b1: 4.958154678344727\n",
      "JGrad: tensor([-0.0371]),  bGrad: tensor([0.4704, 0.4079])\n",
      "J: 12.780731201171875,  b0: -4.008803367614746, b1: 4.950257301330566\n",
      "JGrad: tensor([-0.2202]),  bGrad: tensor([-1.9512, -1.0965])\n",
      "J: 12.780468940734863,  b0: -4.010406970977783, b1: 4.954329490661621\n",
      "JGrad: tensor([-0.2473]),  bGrad: tensor([-0.7303, -0.0294])\n",
      "J: 12.793845176696777,  b0: -4.006712913513184, b1: 4.958297252655029\n",
      "JGrad: tensor([-0.1410]),  bGrad: tensor([-1.6371, -1.0099])\n",
      ">>>\t epoch 66:: loss = 0.21354779601097107, validation loss = 0.1690022051334381\n",
      "J: 12.813652992248535,  b0: -3.9918744564056396, b1: 4.972171783447266\n",
      "JGrad: tensor([-0.0805]),  bGrad: tensor([-0.3053, -0.1037])\n",
      "J: 12.835928916931152,  b0: -3.9763593673706055, b1: 4.985727787017822\n",
      "JGrad: tensor([0.0192]),  bGrad: tensor([0.9200, 0.6548])\n",
      "J: 12.854935646057129,  b0: -3.9688680171966553, b1: 4.991245269775391\n",
      "JGrad: tensor([0.1368]),  bGrad: tensor([1.3641, 0.7115])\n",
      "J: 12.864502906799316,  b0: -3.971733331680298, b1: 4.988941669464111\n",
      "JGrad: tensor([0.0691]),  bGrad: tensor([1.3097, 0.8412])\n",
      "J: 12.869305610656738,  b0: -3.983538866043091, b1: 4.978268146514893\n",
      "JGrad: tensor([-0.0339]),  bGrad: tensor([0.1941, 0.2273])\n",
      "J: 12.87550163269043,  b0: -3.9955410957336426, b1: 4.966328144073486\n",
      "JGrad: tensor([0.0647]),  bGrad: tensor([0.8434, 0.4825])\n",
      "J: 12.8775053024292,  b0: -4.012299060821533, b1: 4.9506354331970215\n",
      "JGrad: tensor([-0.2281]),  bGrad: tensor([-1.6708, -0.8459])\n",
      "J: 12.891913414001465,  b0: -4.015593528747559, b1: 4.9451704025268555\n",
      "JGrad: tensor([-0.1030]),  bGrad: tensor([-1.0687, -0.6725])\n",
      "J: 12.910584449768066,  b0: -4.011020183563232, b1: 4.947139263153076\n",
      "JGrad: tensor([0.1067]),  bGrad: tensor([ 0.1291, -0.2246])\n",
      "J: 12.921493530273438,  b0: -4.007812023162842, b1: 4.9512152671813965\n",
      "JGrad: tensor([0.1771]),  bGrad: tensor([ 0.2508, -0.3076])\n",
      "J: 12.921509742736816,  b0: -4.006694793701172, b1: 4.958042621612549\n",
      "JGrad: tensor([0.0464]),  bGrad: tensor([-0.8803, -0.8764])\n",
      "J: 12.918952941894531,  b0: -3.999464273452759, b1: 4.973182201385498\n",
      "JGrad: tensor([0.1523]),  bGrad: tensor([0.8253, 0.2489])\n",
      "J: 12.908218383789062,  b0: -3.9987916946411133, b1: 4.984261989593506\n",
      "JGrad: tensor([0.2312]),  bGrad: tensor([1.2418, 0.3719])\n",
      ">>>\t epoch 67:: loss = 0.2733662724494934, validation loss = 0.1682177484035492\n",
      "J: 12.885765075683594,  b0: -4.006972789764404, b1: 4.990418910980225\n",
      "JGrad: tensor([0.0578]),  bGrad: tensor([1.0320, 0.6643])\n",
      "J: 12.862336158752441,  b0: -4.02164363861084, b1: 4.989131927490234\n",
      "JGrad: tensor([-0.1804]),  bGrad: tensor([-0.7513, -0.2231])\n",
      "J: 12.85124397277832,  b0: -4.029534339904785, b1: 4.990268707275391\n",
      "JGrad: tensor([-0.2633]),  bGrad: tensor([-1.8741, -0.9260])\n",
      "J: 12.855842590332031,  b0: -4.023366451263428, b1: 5.0008225440979\n",
      "JGrad: tensor([-0.2276]),  bGrad: tensor([-0.7615, -0.0935])\n",
      "J: 12.872570991516113,  b0: -4.012418270111084, b1: 5.011291980743408\n",
      "JGrad: tensor([-0.0881]),  bGrad: tensor([0.1765, 0.2950])\n",
      "J: 12.8925142288208,  b0: -4.00380802154541, b1: 5.017680644989014\n",
      "JGrad: tensor([0.0898]),  bGrad: tensor([0.7926, 0.3747])\n",
      "J: 12.905499458312988,  b0: -4.001676082611084, b1: 5.01956844329834\n",
      "JGrad: tensor([0.0865]),  bGrad: tensor([0.9737, 0.5311])\n",
      "J: 12.912400245666504,  b0: -4.006665229797363, b1: 5.0157856941223145\n",
      "JGrad: tensor([0.0632]),  bGrad: tensor([0.5708, 0.2809])\n",
      "J: 12.915109634399414,  b0: -4.015212059020996, b1: 5.009476661682129\n",
      "JGrad: tensor([0.0717]),  bGrad: tensor([0.8568, 0.4746])\n",
      "J: 12.913569450378418,  b0: -4.028995513916016, b1: 4.998889446258545\n",
      "JGrad: tensor([-0.0204]),  bGrad: tensor([0.2523, 0.2014])\n",
      "J: 12.913314819335938,  b0: -4.0432047843933105, b1: 4.987268924713135\n",
      "JGrad: tensor([-0.1582]),  bGrad: tensor([-1.2033, -0.6545])\n",
      "J: 12.921878814697266,  b0: -4.047438621520996, b1: 4.983579635620117\n",
      "JGrad: tensor([-0.1146]),  bGrad: tensor([-0.7499, -0.3901])\n",
      "J: 12.935959815979004,  b0: -4.045914173126221, b1: 4.984297752380371\n",
      "JGrad: tensor([0.0847]),  bGrad: tensor([ 0.3320, -0.0215])\n",
      ">>>\t epoch 68:: loss = 0.36616772413253784, validation loss = 0.18267473578453064\n",
      "J: 12.943928718566895,  b0: -4.046905994415283, b1: 4.985167503356934\n",
      "JGrad: tensor([-0.0421]),  bGrad: tensor([-0.9061, -0.7167])\n",
      "J: 12.953448295593262,  b0: -4.041342258453369, b1: 4.993383407592773\n",
      "JGrad: tensor([-0.2482]),  bGrad: tensor([-1.6446, -0.7695])\n",
      "J: 12.975820541381836,  b0: -4.02462100982666, b1: 5.008762836456299\n",
      "JGrad: tensor([0.2259]),  bGrad: tensor([1.3971, 0.5136])\n",
      "J: 12.983383178710938,  b0: -4.019524097442627, b1: 5.0172810554504395\n",
      "JGrad: tensor([0.0072]),  bGrad: tensor([0.1697, 0.0861])\n",
      "J: 12.989792823791504,  b0: -4.016142845153809, b1: 5.024060249328613\n",
      "JGrad: tensor([0.0959]),  bGrad: tensor([0.6559, 0.2603])\n",
      "J: 12.990224838256836,  b0: -4.017776966094971, b1: 5.027459144592285\n",
      "JGrad: tensor([0.1234]),  bGrad: tensor([0.8092, 0.3143])\n",
      "J: 12.98373794555664,  b0: -4.0250244140625, b1: 5.027250289916992\n",
      "JGrad: tensor([0.1119]),  bGrad: tensor([0.7813, 0.3198])\n",
      "J: 12.971659660339355,  b0: -4.037131309509277, b1: 5.023732662200928\n",
      "JGrad: tensor([0.0738]),  bGrad: tensor([0.6709, 0.3168])\n",
      "J: 12.956666946411133,  b0: -4.052829265594482, b1: 5.017262935638428\n",
      "JGrad: tensor([-0.0907]),  bGrad: tensor([-0.5587, -0.2715])\n",
      "J: 12.948225975036621,  b0: -4.062971591949463, b1: 5.0142669677734375\n",
      "JGrad: tensor([-0.0715]),  bGrad: tensor([-0.1074,  0.0373])\n",
      "J: 12.944618225097656,  b0: -4.071338653564453, b1: 5.011178970336914\n",
      "JGrad: tensor([-0.2338]),  bGrad: tensor([-0.7251, -0.0846])\n",
      "J: 12.954424858093262,  b0: -4.073679447174072, b1: 5.009280681610107\n",
      "JGrad: tensor([-0.1191]),  bGrad: tensor([-0.9190, -0.5112])\n",
      "J: 12.969904899597168,  b0: -4.069201469421387, b1: 5.012914657592773\n",
      "JGrad: tensor([-0.2217]),  bGrad: tensor([0.0939, 0.5739])\n",
      ">>>\t epoch 69:: loss = 0.20371760427951813, validation loss = 0.1812930703163147\n",
      "J: 12.996207237243652,  b0: -4.065841197967529, b1: 5.010185241699219\n",
      "JGrad: tensor([-0.1902]),  bGrad: tensor([-1.8346, -1.0803])\n",
      "J: 13.03049087524414,  b0: -4.04966926574707, b1: 5.019024848937988\n",
      "JGrad: tensor([0.0288]),  bGrad: tensor([0.1860, 0.0381])\n",
      "J: 13.059764862060547,  b0: -4.036437034606934, b1: 5.026588439941406\n",
      "JGrad: tensor([0.0856]),  bGrad: tensor([0.3279, 0.0236])\n",
      "J: 13.081341743469238,  b0: -4.026872634887695, b1: 5.0331549644470215\n",
      "JGrad: tensor([0.0684]),  bGrad: tensor([ 0.0910, -0.1223])\n",
      "J: 13.096946716308594,  b0: -4.018911361694336, b1: 5.040351390838623\n",
      "JGrad: tensor([0.0662]),  bGrad: tensor([0.3324, 0.0766])\n",
      "J: 13.107294082641602,  b0: -4.01413106918335, b1: 5.046030521392822\n",
      "JGrad: tensor([0.0685]),  bGrad: tensor([0.2899, 0.0326])\n",
      "J: 13.112774848937988,  b0: -4.011911869049072, b1: 5.050803184509277\n",
      "JGrad: tensor([0.1110]),  bGrad: tensor([1.3174, 0.7473])\n",
      "J: 13.111490249633789,  b0: -4.0193963050842285, b1: 5.047250747680664\n",
      "JGrad: tensor([0.0173]),  bGrad: tensor([1.1428, 0.8389])\n",
      "J: 13.109360694885254,  b0: -4.034362316131592, b1: 5.035240173339844\n",
      "JGrad: tensor([0.1126]),  bGrad: tensor([ 0.2042, -0.1557])\n",
      "J: 13.101125717163086,  b0: -4.049314498901367, b1: 5.026058673858643\n",
      "JGrad: tensor([0.3834]),  bGrad: tensor([3.1719, 1.5015])\n",
      "J: 13.072280883789062,  b0: -4.085498332977295, b1: 5.00203800201416\n",
      "JGrad: tensor([-0.2175]),  bGrad: tensor([-0.7033, -0.0798])\n",
      "J: 13.058494567871094,  b0: -4.113030910491943, b1: 4.981240272521973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.1115]),  bGrad: tensor([-0.4676, -0.1406])\n",
      "J: 13.05232048034668,  b0: -4.134466648101807, b1: 4.963985443115234\n",
      "JGrad: tensor([-0.1275]),  bGrad: tensor([-1.7720, -1.2294])\n",
      ">>>\t epoch 70:: loss = 0.22305937111377716, validation loss = 0.29843732714653015\n",
      "J: 13.053897857666016,  b0: -4.14101505279541, b1: 4.961389064788818\n",
      "JGrad: tensor([-0.2496]),  bGrad: tensor([-2.4364, -1.4605])\n",
      "J: 13.069276809692383,  b0: -4.129420280456543, b1: 4.974390506744385\n",
      "JGrad: tensor([-0.3867]),  bGrad: tensor([-2.1741, -0.9067])\n",
      "J: 13.104644775390625,  b0: -4.103419780731201, b1: 4.995614051818848\n",
      "JGrad: tensor([-0.0352]),  bGrad: tensor([-1.1700, -0.9218])\n",
      "J: 13.13846492767334,  b0: -4.071628570556641, b1: 5.024396896362305\n",
      "JGrad: tensor([0.1387]),  bGrad: tensor([0.6082, 0.0902])\n",
      "J: 13.161166191101074,  b0: -4.047358512878418, b1: 5.049374580383301\n",
      "JGrad: tensor([0.0700]),  bGrad: tensor([-0.5881, -0.6796])\n",
      "J: 13.177701950073242,  b0: -4.021279811859131, b1: 5.079010009765625\n",
      "JGrad: tensor([0.1211]),  bGrad: tensor([0.8125, 0.2889])\n",
      "J: 13.185820579528809,  b0: -4.0036301612854, b1: 5.102662563323975\n",
      "JGrad: tensor([0.0425]),  bGrad: tensor([2.1882, 1.5619])\n",
      "J: 13.190753936767578,  b0: -4.003458499908447, b1: 5.10750675201416\n",
      "JGrad: tensor([0.3296]),  bGrad: tensor([3.4158, 1.7780])\n",
      "J: 13.176783561706543,  b0: -4.0277018547058105, b1: 5.093212604522705\n",
      "JGrad: tensor([0.1259]),  bGrad: tensor([0.7965, 0.2693])\n",
      "J: 13.157170295715332,  b0: -4.055224895477295, b1: 5.077512264251709\n",
      "JGrad: tensor([0.1420]),  bGrad: tensor([0.9557, 0.3777])\n",
      "J: 13.131577491760254,  b0: -4.08683967590332, b1: 5.05940580368042\n",
      "JGrad: tensor([0.0896]),  bGrad: tensor([0.4499, 0.0811])\n",
      "J: 13.10351848602295,  b0: -4.118533134460449, b1: 5.0422444343566895\n",
      "JGrad: tensor([0.0680]),  bGrad: tensor([-0.1110, -0.3347])\n",
      "J: 13.074442863464355,  b0: -4.1462860107421875, b1: 5.030307769775391\n",
      "JGrad: tensor([-0.1260]),  bGrad: tensor([-1.2762, -0.7706])\n",
      ">>>\t epoch 71:: loss = 0.2479771077632904, validation loss = 0.2706688940525055\n",
      "J: 13.055315017700195,  b0: -4.1621270179748535, b1: 5.027669906616211\n",
      "JGrad: tensor([-0.2315]),  bGrad: tensor([-1.9232, -1.0469])\n",
      "J: 13.051060676574707,  b0: -4.162610054016113, b1: 5.036308765411377\n",
      "JGrad: tensor([-0.2793]),  bGrad: tensor([-2.0276, -1.0198])\n",
      "J: 13.06283950805664,  b0: -4.148547649383545, b1: 5.054809093475342\n",
      "JGrad: tensor([-0.1480]),  bGrad: tensor([0.0310, 0.3477])\n",
      "J: 13.081714630126953,  b0: -4.13610315322876, b1: 5.067811489105225\n",
      "JGrad: tensor([-0.2157]),  bGrad: tensor([-0.7946, -0.1744])\n",
      "J: 13.110745429992676,  b0: -4.119207859039307, b1: 5.081360816955566\n",
      "JGrad: tensor([-0.0975]),  bGrad: tensor([-0.4184, -0.1453])\n",
      "J: 13.142338752746582,  b0: -4.100992202758789, b1: 5.095097064971924\n",
      "JGrad: tensor([-0.2132]),  bGrad: tensor([-1.0254, -0.3596])\n",
      "J: 13.1826753616333,  b0: -4.077242374420166, b1: 5.111262321472168\n",
      "JGrad: tensor([0.2320]),  bGrad: tensor([1.1525, 0.3011])\n",
      "J: 13.206000328063965,  b0: -4.064125061035156, b1: 5.122642517089844\n",
      "JGrad: tensor([0.0434]),  bGrad: tensor([-0.0381, -0.1670])\n",
      "J: 13.22458267211914,  b0: -4.052036285400391, b1: 5.13465690612793\n",
      "JGrad: tensor([0.0405]),  bGrad: tensor([1.3821, 0.9406])\n",
      "J: 13.239054679870605,  b0: -4.0510735511779785, b1: 5.135531902313232\n",
      "JGrad: tensor([0.1348]),  bGrad: tensor([1.6525, 0.8997])\n",
      "J: 13.24454402923584,  b0: -4.062061786651611, b1: 5.12681245803833\n",
      "JGrad: tensor([0.1915]),  bGrad: tensor([1.6075, 0.7699])\n",
      "J: 13.238767623901367,  b0: -4.083476543426514, b1: 5.110825061798096\n",
      "JGrad: tensor([0.0511]),  bGrad: tensor([ 0.1827, -0.0043])\n",
      "J: 13.230705261230469,  b0: -4.104076385498047, b1: 5.096469879150391\n",
      "JGrad: tensor([0.1863]),  bGrad: tensor([ 0.5512, -0.0581])\n",
      ">>>\t epoch 72:: loss = 0.24694931507110596, validation loss = 0.1737232208251953\n",
      "J: 13.213018417358398,  b0: -4.126587867736816, b1: 5.0841546058654785\n",
      "JGrad: tensor([-0.1187]),  bGrad: tensor([-0.4568, -0.1398])\n",
      "J: 13.203742980957031,  b0: -4.143579483032227, b1: 5.074542999267578\n",
      "JGrad: tensor([0.0327]),  bGrad: tensor([-0.8309, -0.8322])\n",
      "J: 13.193556785583496,  b0: -4.152904987335205, b1: 5.074710369110107\n",
      "JGrad: tensor([-0.0945]),  bGrad: tensor([-0.2776, -0.0437])\n",
      "J: 13.189682960510254,  b0: -4.159306526184082, b1: 5.075325012207031\n",
      "JGrad: tensor([-0.1604]),  bGrad: tensor([-1.0902, -0.5444])\n",
      "J: 13.19519329071045,  b0: -4.15722131729126, b1: 5.081655502319336\n",
      "JGrad: tensor([-0.1039]),  bGrad: tensor([-1.5838, -1.1006])\n",
      "J: 13.205986976623535,  b0: -4.143945693969727, b1: 5.09902811050415\n",
      "JGrad: tensor([-0.1214]),  bGrad: tensor([-1.0880, -0.6755])\n",
      "J: 13.22252082824707,  b0: -4.1241607666015625, b1: 5.121838569641113\n",
      "JGrad: tensor([0.0154]),  bGrad: tensor([0.4196, 0.2769])\n",
      "J: 13.236547470092773,  b0: -4.1093645095825195, b1: 5.139442443847656\n",
      "JGrad: tensor([0.1938]),  bGrad: tensor([ 0.5601, -0.0902])\n",
      "J: 13.238282203674316,  b0: -4.100077152252197, b1: 5.1562581062316895\n",
      "JGrad: tensor([0.0994]),  bGrad: tensor([0.7677, 0.3331])\n",
      "J: 13.234254837036133,  b0: -4.097251892089844, b1: 5.16786003112793\n",
      "JGrad: tensor([0.0738]),  bGrad: tensor([0.8132, 0.4324])\n",
      "J: 13.22647476196289,  b0: -4.100577354431152, b1: 5.1737060546875\n",
      "JGrad: tensor([-0.0294]),  bGrad: tensor([0.8748, 0.7443])\n",
      "J: 13.221122741699219,  b0: -4.109889507293701, b1: 5.171043872833252\n",
      "JGrad: tensor([0.0319]),  bGrad: tensor([0.6213, 0.3686])\n",
      "J: 13.214506149291992,  b0: -4.12276554107666, b1: 5.164719104766846\n",
      "JGrad: tensor([-0.2535]),  bGrad: tensor([0.8116, 1.2153])\n",
      ">>>\t epoch 73:: loss = 0.1977122277021408, validation loss = 0.16551946103572845\n",
      "J: 13.222830772399902,  b0: -4.140228271484375, b1: 5.146088123321533\n",
      "JGrad: tensor([-0.1530]),  bGrad: tensor([0.0739, 0.3850])\n",
      "J: 13.238940238952637,  b0: -4.156492710113525, b1: 5.125206470489502\n",
      "JGrad: tensor([-0.3212]),  bGrad: tensor([0.2798, 0.9732])\n",
      "J: 13.271464347839355,  b0: -4.173168182373047, b1: 5.096044540405273\n",
      "JGrad: tensor([-0.0972]),  bGrad: tensor([-0.6113, -0.3139])\n",
      "J: 13.306221961975098,  b0: -4.183756351470947, b1: 5.073127269744873\n",
      "JGrad: tensor([-0.1657]),  bGrad: tensor([-0.5566, -0.1009])\n",
      "J: 13.34682559967041,  b0: -4.189256191253662, b1: 5.053562164306641\n",
      "JGrad: tensor([-0.0340]),  bGrad: tensor([-1.1765, -0.9421])\n",
      "J: 13.385309219360352,  b0: -4.18567419052124, b1: 5.0460076332092285\n",
      "JGrad: tensor([-0.1745]),  bGrad: tensor([-1.8989, -1.1966])\n",
      "J: 13.429767608642578,  b0: -4.168690204620361, b1: 5.051974773406982\n",
      "JGrad: tensor([0.2140]),  bGrad: tensor([-0.7684, -1.2096])\n",
      "J: 13.457723617553711,  b0: -4.147823333740234, b1: 5.070237636566162\n",
      "JGrad: tensor([0.1087]),  bGrad: tensor([ 0.1476, -0.1961])\n",
      "J: 13.476777076721191,  b0: -4.130099296569824, b1: 5.088779449462891\n",
      "JGrad: tensor([0.1148]),  bGrad: tensor([ 0.2190, -0.1622])\n",
      "J: 13.487467765808105,  b0: -4.115725517272949, b1: 5.107212066650391\n",
      "JGrad: tensor([0.1942]),  bGrad: tensor([-0.6066, -1.0540])\n",
      "J: 13.4861478805542,  b0: -4.098371982574463, b1: 5.135048866271973\n",
      "JGrad: tensor([0.0556]),  bGrad: tensor([1.1959, 0.7893])\n",
      "J: 13.481825828552246,  b0: -4.09144401550293, b1: 5.151679515838623\n",
      "JGrad: tensor([0.2358]),  bGrad: tensor([1.3637, 0.4481])\n",
      "J: 13.464658737182617,  b0: -4.095122337341309, b1: 5.161868572235107\n",
      "JGrad: tensor([0.2306]),  bGrad: tensor([1.8447, 0.8215])\n",
      ">>>\t epoch 74:: loss = 0.31864067912101746, validation loss = 0.1921888291835785\n",
      "J: 13.436237335205078,  b0: -4.111832141876221, b1: 5.162261962890625\n",
      "JGrad: tensor([0.1373]),  bGrad: tensor([0.8614, 0.3093])\n",
      "J: 13.40291976928711,  b0: -4.133139610290527, b1: 5.159308433532715\n",
      "JGrad: tensor([0.0879]),  bGrad: tensor([ 0.2909, -0.0189])\n",
      "J: 13.367961883544922,  b0: -4.154447555541992, b1: 5.156850337982178\n",
      "JGrad: tensor([0.0817]),  bGrad: tensor([-0.2049, -0.3992])\n",
      "J: 13.33187198638916,  b0: -4.172147750854492, b1: 5.15891170501709\n",
      "JGrad: tensor([-0.1877]),  bGrad: tensor([-0.9352, -0.3544])\n",
      "J: 13.309978485107422,  b0: -4.181273937225342, b1: 5.164566516876221\n",
      "JGrad: tensor([-0.2839]),  bGrad: tensor([-0.5903,  0.1740])\n",
      "J: 13.306282043457031,  b0: -4.185190677642822, b1: 5.167793273925781\n",
      "JGrad: tensor([-0.0250]),  bGrad: tensor([-0.5080, -0.4169])\n",
      "J: 13.304362297058105,  b0: -4.185013294219971, b1: 5.175172805786133\n",
      "JGrad: tensor([-0.2232]),  bGrad: tensor([-1.2749, -0.5283])\n",
      "J: 13.315204620361328,  b0: -4.175555229187012, b1: 5.187491416931152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.1155]),  bGrad: tensor([0.9785, 1.0144])\n",
      "J: 13.331475257873535,  b0: -4.174179553985596, b1: 5.187685489654541\n",
      "JGrad: tensor([-0.2121]),  bGrad: tensor([-0.8138, -0.1779])\n",
      "J: 13.358060836791992,  b0: -4.166999816894531, b1: 5.189772605895996\n",
      "JGrad: tensor([0.0545]),  bGrad: tensor([0.4418, 0.1914])\n",
      "J: 13.37893009185791,  b0: -4.163761138916016, b1: 5.18959379196167\n",
      "JGrad: tensor([0.1100]),  bGrad: tensor([1.8264, 1.1490])\n",
      "J: 13.391518592834473,  b0: -4.174182891845703, b1: 5.177082538604736\n",
      "JGrad: tensor([0.0587]),  bGrad: tensor([0.2474, 0.0067])\n",
      "J: 13.399543762207031,  b0: -4.185377597808838, b1: 5.165740966796875\n",
      "JGrad: tensor([-0.0113]),  bGrad: tensor([-0.3102, -0.2627])\n",
      ">>>\t epoch 75:: loss = 0.16704992949962616, validation loss = 0.17432008683681488\n",
      "J: 13.407407760620117,  b0: -4.193192481994629, b1: 5.158353805541992\n",
      "JGrad: tensor([-0.0715]),  bGrad: tensor([-1.1727, -0.8436])\n",
      "J: 13.418533325195312,  b0: -4.191650867462158, b1: 5.160787105560303\n",
      "JGrad: tensor([-0.1946]),  bGrad: tensor([-0.8384, -0.2386])\n",
      "J: 13.439544677734375,  b0: -4.184127330780029, b1: 5.165549278259277\n",
      "JGrad: tensor([-0.0142]),  bGrad: tensor([-0.2992, -0.2453])\n",
      "J: 13.459274291992188,  b0: -4.175159931182861, b1: 5.172483444213867\n",
      "JGrad: tensor([0.0358]),  bGrad: tensor([-0.4920, -0.5229])\n",
      "J: 13.475015640258789,  b0: -4.163477897644043, b1: 5.184369087219238\n",
      "JGrad: tensor([0.0381]),  bGrad: tensor([0.1917, 0.0322])\n",
      "J: 13.48703384399414,  b0: -4.154361248016357, b1: 5.194726943969727\n",
      "JGrad: tensor([0.1610]),  bGrad: tensor([1.8498, 1.0301])\n",
      "J: 13.488728523254395,  b0: -4.159718990325928, b1: 5.19292688369751\n",
      "JGrad: tensor([0.1962]),  bGrad: tensor([1.3376, 0.5471])\n",
      "J: 13.479137420654297,  b0: -4.174345016479492, b1: 5.185397148132324\n",
      "JGrad: tensor([0.1665]),  bGrad: tensor([ 0.5197, -0.0543])\n",
      "J: 13.46107292175293,  b0: -4.191329002380371, b1: 5.179201602935791\n",
      "JGrad: tensor([0.1005]),  bGrad: tensor([ 0.3084, -0.0448])\n",
      "J: 13.439108848571777,  b0: -4.208889961242676, b1: 5.174106121063232\n",
      "JGrad: tensor([-0.0946]),  bGrad: tensor([-0.0786,  0.1133])\n",
      "J: 13.424694061279297,  b0: -4.224129676818848, b1: 5.168290138244629\n",
      "JGrad: tensor([-0.1874]),  bGrad: tensor([-0.1466,  0.2919])\n",
      "J: 13.422347068786621,  b0: -4.236778736114502, b1: 5.159889221191406\n",
      "JGrad: tensor([-0.0673]),  bGrad: tensor([-1.3290, -0.9828])\n",
      "J: 13.424053192138672,  b0: -4.2383928298950195, b1: 5.162976264953613\n",
      "JGrad: tensor([0.0453]),  bGrad: tensor([-1.0693, -1.0774])\n",
      ">>>\t epoch 76:: loss = 0.3451595902442932, validation loss = 0.19997693598270416\n",
      "J: 13.423017501831055,  b0: -4.231982707977295, b1: 5.177422523498535\n",
      "JGrad: tensor([-0.1068]),  bGrad: tensor([-0.4911, -0.2040])\n",
      "J: 13.428153038024902,  b0: -4.222595691680908, b1: 5.1926445960998535\n",
      "JGrad: tensor([-0.1720]),  bGrad: tensor([-1.0646, -0.4880])\n",
      "J: 13.442546844482422,  b0: -4.206307888031006, b1: 5.211644172668457\n",
      "JGrad: tensor([-0.1756]),  bGrad: tensor([-0.4210,  0.0375])\n",
      "J: 13.465476989746094,  b0: -4.188536643981934, b1: 5.228350639343262\n",
      "JGrad: tensor([0.0610]),  bGrad: tensor([0.6237, 0.3220])\n",
      "J: 13.482659339904785,  b0: -4.177129745483398, b1: 5.2399001121521\n",
      "JGrad: tensor([0.1515]),  bGrad: tensor([1.6409, 0.8878])\n",
      "J: 13.489514350891113,  b0: -4.178958415985107, b1: 5.240653038024902\n",
      "JGrad: tensor([0.0872]),  bGrad: tensor([ 0.3149, -0.0007])\n",
      "J: 13.490726470947266,  b0: -4.18292760848999, b1: 5.241338729858398\n",
      "JGrad: tensor([0.1094]),  bGrad: tensor([-0.2783, -0.5242])\n",
      "J: 13.485588073730469,  b0: -4.184448719024658, b1: 5.24765682220459\n",
      "JGrad: tensor([0.1655]),  bGrad: tensor([2.1505, 1.2716])\n",
      "J: 13.471542358398438,  b0: -4.201666831970215, b1: 5.239519119262695\n",
      "JGrad: tensor([-0.0451]),  bGrad: tensor([0.0315, 0.1079])\n",
      "J: 13.461461067199707,  b0: -4.217407703399658, b1: 5.231016159057617\n",
      "JGrad: tensor([-0.2048]),  bGrad: tensor([-0.4418,  0.1171])\n",
      "J: 13.464056968688965,  b0: -4.228322982788086, b1: 5.222083568572998\n",
      "JGrad: tensor([-0.0880]),  bGrad: tensor([-0.2804, -0.0592])\n",
      "J: 13.47140884399414,  b0: -4.236083030700684, b1: 5.2146830558776855\n",
      "JGrad: tensor([-0.0944]),  bGrad: tensor([-0.6139, -0.3309])\n",
      "J: 13.483412742614746,  b0: -4.238533020019531, b1: 5.211624622344971\n",
      "JGrad: tensor([-0.2310]),  bGrad: tensor([-1.4380, -0.6218])\n",
      ">>>\t epoch 77:: loss = 0.11299528181552887, validation loss = 0.1680985987186432\n",
      "J: 13.507376670837402,  b0: -4.230108737945557, b1: 5.2156524658203125\n",
      "JGrad: tensor([-0.1936]),  bGrad: tensor([-1.0126, -0.4010])\n",
      "J: 13.539971351623535,  b0: -4.215036869049072, b1: 5.2236552238464355\n",
      "JGrad: tensor([-0.0410]),  bGrad: tensor([-0.3948, -0.2490])\n",
      "J: 13.571667671203613,  b0: -4.198541164398193, b1: 5.233582019805908\n",
      "JGrad: tensor([0.0414]),  bGrad: tensor([0.3176, 0.1243])\n",
      "J: 13.597855567932129,  b0: -4.186036109924316, b1: 5.241164684295654\n",
      "JGrad: tensor([0.1465]),  bGrad: tensor([0.9521, 0.3615])\n",
      "J: 13.613066673278809,  b0: -4.181830406188965, b1: 5.244040489196777\n",
      "JGrad: tensor([0.0209]),  bGrad: tensor([0.2389, 0.1105])\n",
      "J: 13.625574111938477,  b0: -4.179813385009766, b1: 5.245420932769775\n",
      "JGrad: tensor([0.1606]),  bGrad: tensor([0.6559, 0.0866])\n",
      "J: 13.627655029296875,  b0: -4.182862758636475, b1: 5.245715618133545\n",
      "JGrad: tensor([0.2317]),  bGrad: tensor([1.7090, 0.7469])\n",
      "J: 13.61629867553711,  b0: -4.198276519775391, b1: 5.237797737121582\n",
      "JGrad: tensor([0.0075]),  bGrad: tensor([0.4028, 0.2830])\n",
      "J: 13.605640411376953,  b0: -4.215147972106934, b1: 5.227563381195068\n",
      "JGrad: tensor([0.1426]),  bGrad: tensor([ 0.2956, -0.1934])\n",
      "J: 13.58789348602295,  b0: -4.232538223266602, b1: 5.2204670906066895\n",
      "JGrad: tensor([0.1116]),  bGrad: tensor([ 0.3660, -0.0467])\n",
      "J: 13.565529823303223,  b0: -4.25092077255249, b1: 5.214588165283203\n",
      "JGrad: tensor([-0.0612]),  bGrad: tensor([-1.2670, -0.9546])\n",
      "J: 13.548892974853516,  b0: -4.25805139541626, b1: 5.2197794914245605\n",
      "JGrad: tensor([-0.1060]),  bGrad: tensor([-1.1924, -0.7683])\n",
      "J: 13.539978981018066,  b0: -4.2556071281433105, b1: 5.232890605926514\n",
      "JGrad: tensor([-0.3437]),  bGrad: tensor([-1.5724, -0.4539])\n",
      ">>>\t epoch 78:: loss = 0.14196690917015076, validation loss = 0.15918388962745667\n",
      "J: 13.55161190032959,  b0: -4.241724491119385, b1: 5.249685764312744\n",
      "JGrad: tensor([-0.1849]),  bGrad: tensor([-0.3995,  0.0566])\n",
      "J: 13.572641372680664,  b0: -4.226250648498535, b1: 5.264190673828125\n",
      "JGrad: tensor([-0.0113]),  bGrad: tensor([0.2835, 0.2354])\n",
      "J: 13.592226028442383,  b0: -4.214423179626465, b1: 5.274663925170898\n",
      "JGrad: tensor([-0.0419]),  bGrad: tensor([-0.0687,  0.0264])\n",
      "J: 13.612260818481445,  b0: -4.203258037567139, b1: 5.283806800842285\n",
      "JGrad: tensor([0.0599]),  bGrad: tensor([0.3619, 0.1142])\n",
      "J: 13.626874923706055,  b0: -4.195899486541748, b1: 5.290782928466797\n",
      "JGrad: tensor([0.1586]),  bGrad: tensor([0.7508, 0.1707])\n",
      "J: 13.630949020385742,  b0: -4.194871425628662, b1: 5.295183181762695\n",
      "JGrad: tensor([0.0852]),  bGrad: tensor([0.9070, 0.4761])\n",
      "J: 13.629737854003906,  b0: -4.200712203979492, b1: 5.293890953063965\n",
      "JGrad: tensor([0.0085]),  bGrad: tensor([-0.0079, -0.0564])\n",
      "J: 13.628161430358887,  b0: -4.20591402053833, b1: 5.2933502197265625\n",
      "JGrad: tensor([0.1300]),  bGrad: tensor([0.6279, 0.1524])\n",
      "J: 13.619288444519043,  b0: -4.2152886390686035, b1: 5.2911787033081055\n",
      "JGrad: tensor([0.1213]),  bGrad: tensor([1.2664, 0.6826])\n",
      "J: 13.604340553283691,  b0: -4.233187675476074, b1: 5.281675815582275\n",
      "JGrad: tensor([0.0840]),  bGrad: tensor([1.5413, 0.9884])\n",
      "J: 13.586055755615234,  b0: -4.260804176330566, b1: 5.262196063995361\n",
      "JGrad: tensor([0.0244]),  bGrad: tensor([-2.0882, -1.8407])\n",
      "J: 13.568185806274414,  b0: -4.270052433013916, b1: 5.26500940322876\n",
      "JGrad: tensor([-0.0407]),  bGrad: tensor([0.1299, 0.1565])\n",
      "J: 13.55443286895752,  b0: -4.279352188110352, b1: 5.265815734863281\n",
      "JGrad: tensor([-0.0286]),  bGrad: tensor([-0.1126, -0.0660])\n",
      ">>>\t epoch 79:: loss = 0.19484631717205048, validation loss = 0.1928694099187851\n",
      "J: 13.543693542480469,  b0: -4.286887168884277, b1: 5.267270565032959\n",
      "JGrad: tensor([-0.0558]),  bGrad: tensor([0.0080, 0.0995])\n",
      "J: 13.537233352661133,  b0: -4.293734073638916, b1: 5.267480850219727\n",
      "JGrad: tensor([-0.1043]),  bGrad: tensor([-1.1233, -0.7252])\n",
      "J: 13.53742504119873,  b0: -4.2914958000183105, b1: 5.275689125061035\n",
      "JGrad: tensor([-0.2299]),  bGrad: tensor([-1.3724, -0.5882])\n",
      "J: 13.550835609436035,  b0: -4.279216766357422, b1: 5.289586544036865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.2520]),  bGrad: tensor([-1.7243, -0.8444])\n",
      "J: 13.577388763427734,  b0: -4.255281448364258, b1: 5.311437606811523\n",
      "JGrad: tensor([-0.1202]),  bGrad: tensor([0.3993, 0.5791])\n",
      "J: 13.608211517333984,  b0: -4.236711502075195, b1: 5.324702739715576\n",
      "JGrad: tensor([0.0736]),  bGrad: tensor([0.9262, 0.5172])\n",
      "J: 13.631730079650879,  b0: -4.22692346572876, b1: 5.3309197425842285\n",
      "JGrad: tensor([0.0583]),  bGrad: tensor([1.2210, 0.7998])\n",
      "J: 13.649554252624512,  b0: -4.2272515296936035, b1: 5.327656269073486\n",
      "JGrad: tensor([-0.0602]),  bGrad: tensor([0.1162, 0.2172])\n",
      "J: 13.66908073425293,  b0: -4.22841739654541, b1: 5.3223090171813965\n",
      "JGrad: tensor([0.1304]),  bGrad: tensor([1.4444, 0.7803])\n",
      "J: 13.679137229919434,  b0: -4.240283966064453, b1: 5.308844566345215\n",
      "JGrad: tensor([0.0475]),  bGrad: tensor([-0.0121, -0.1613])\n",
      "J: 13.68545150756836,  b0: -4.250881671905518, b1: 5.298506736755371\n",
      "JGrad: tensor([0.1615]),  bGrad: tensor([1.2297, 0.5513])\n",
      "J: 13.68181037902832,  b0: -4.269638538360596, b1: 5.283078670501709\n",
      "JGrad: tensor([0.1160]),  bGrad: tensor([0.4385, 0.0140])\n",
      "J: 13.671829223632812,  b0: -4.289820671081543, b1: 5.269027233123779\n",
      "JGrad: tensor([-0.1761]),  bGrad: tensor([-1.0144, -0.4376])\n",
      ">>>\t epoch 80:: loss = 0.08412119001150131, validation loss = 0.19008399546146393\n",
      "J: 13.673015594482422,  b0: -4.300378322601318, b1: 5.261237144470215\n",
      "JGrad: tensor([-0.0666]),  bGrad: tensor([-0.0192,  0.1051])\n",
      "J: 13.675474166870117,  b0: -4.305060863494873, b1: 5.257144451141357\n",
      "JGrad: tensor([-0.2396]),  bGrad: tensor([-2.1099, -1.1910])\n",
      "J: 13.684602737426758,  b0: -4.301357269287109, b1: 5.26008415222168\n",
      "JGrad: tensor([0.0120]),  bGrad: tensor([0.4524, 0.2657])\n",
      "J: 13.69247817993164,  b0: -4.29971981048584, b1: 5.261253356933594\n",
      "JGrad: tensor([-0.0184]),  bGrad: tensor([-1.0996, -0.9363])\n",
      "J: 13.700101852416992,  b0: -4.294117450714111, b1: 5.267513751983643\n",
      "JGrad: tensor([-0.1069]),  bGrad: tensor([-0.8841, -0.5108])\n",
      "J: 13.71005916595459,  b0: -4.28575325012207, b1: 5.275993824005127\n",
      "JGrad: tensor([0.0668]),  bGrad: tensor([-0.5709, -0.6655])\n",
      "J: 13.717092514038086,  b0: -4.27607536315918, b1: 5.2873334884643555\n",
      "JGrad: tensor([0.1176]),  bGrad: tensor([ 0.2268, -0.1705])\n",
      "J: 13.720020294189453,  b0: -4.268211364746094, b1: 5.298496723175049\n",
      "JGrad: tensor([0.1350]),  bGrad: tensor([0.5546, 0.0628])\n",
      "J: 13.718746185302734,  b0: -4.263216018676758, b1: 5.308201313018799\n",
      "JGrad: tensor([0.0987]),  bGrad: tensor([ 0.2670, -0.0663])\n",
      "J: 13.714737892150879,  b0: -4.259722709655762, b1: 5.317312240600586\n",
      "JGrad: tensor([0.0609]),  bGrad: tensor([0.9325, 0.5699])\n",
      "J: 13.70936107635498,  b0: -4.260090351104736, b1: 5.322333812713623\n",
      "JGrad: tensor([0.0813]),  bGrad: tensor([1.6140, 1.0641])\n",
      "J: 13.702157974243164,  b0: -4.266499042510986, b1: 5.320913314819336\n",
      "JGrad: tensor([0.0607]),  bGrad: tensor([0.6064, 0.3112])\n",
      "J: 13.693906784057617,  b0: -4.274555206298828, b1: 5.317896366119385\n",
      "JGrad: tensor([0.0013]),  bGrad: tensor([0.3479, 0.2542])\n",
      ">>>\t epoch 81:: loss = 0.11605735123157501, validation loss = 0.15276837348937988\n",
      "J: 13.686436653137207,  b0: -4.283123016357422, b1: 5.313758373260498\n",
      "JGrad: tensor([-0.1416]),  bGrad: tensor([0.1810, 0.4428])\n",
      "J: 13.683829307556152,  b0: -4.291522979736328, b1: 5.30755615234375\n",
      "JGrad: tensor([-0.0531]),  bGrad: tensor([0.2789, 0.2932])\n",
      "J: 13.683025360107422,  b0: -4.30014181137085, b1: 5.300329685211182\n",
      "JGrad: tensor([-0.3447]),  bGrad: tensor([-1.5950, -0.4804])\n",
      "J: 13.692309379577637,  b0: -4.30187463760376, b1: 5.296511650085449\n",
      "JGrad: tensor([-0.1097]),  bGrad: tensor([0.0473, 0.2498])\n",
      "J: 13.703853607177734,  b0: -4.303613662719727, b1: 5.29167366027832\n",
      "JGrad: tensor([0.0432]),  bGrad: tensor([-0.0840, -0.2385])\n",
      "J: 13.712995529174805,  b0: -4.3048624992370605, b1: 5.28865385055542\n",
      "JGrad: tensor([-0.2174]),  bGrad: tensor([-0.8188, -0.1822])\n",
      "J: 13.72753620147705,  b0: -4.302889823913574, b1: 5.286956310272217\n",
      "JGrad: tensor([-0.2356]),  bGrad: tensor([-0.7808, -0.1201])\n",
      "J: 13.747454643249512,  b0: -4.298158168792725, b1: 5.286101818084717\n",
      "JGrad: tensor([0.1387]),  bGrad: tensor([-0.7874, -1.0479])\n",
      "J: 13.761358261108398,  b0: -4.2909159660339355, b1: 5.291215419769287\n",
      "JGrad: tensor([0.0847]),  bGrad: tensor([-2.0669, -1.9463])\n",
      "J: 13.771417617797852,  b0: -4.27658748626709, b1: 5.306697845458984\n",
      "JGrad: tensor([0.2102]),  bGrad: tensor([ 0.5624, -0.1176])\n",
      "J: 13.774362564086914,  b0: -4.265812397003174, b1: 5.321300983428955\n",
      "JGrad: tensor([0.0719]),  bGrad: tensor([0.2723, 0.0136])\n",
      "J: 13.774925231933594,  b0: -4.257138729095459, b1: 5.334377765655518\n",
      "JGrad: tensor([0.0392]),  bGrad: tensor([0.9312, 0.6265])\n",
      "J: 13.7742919921875,  b0: -4.252857685089111, b1: 5.34263801574707\n",
      "JGrad: tensor([0.0847]),  bGrad: tensor([1.3607, 0.8419])\n",
      ">>>\t epoch 82:: loss = 0.25954264402389526, validation loss = 0.17918191850185394\n",
      "J: 13.771258354187012,  b0: -4.254160404205322, b1: 5.345351219177246\n",
      "JGrad: tensor([0.3241]),  bGrad: tensor([1.4647, 0.3108])\n",
      "J: 13.759119033813477,  b0: -4.260880947113037, b1: 5.34605073928833\n",
      "JGrad: tensor([0.0195]),  bGrad: tensor([0.9530, 0.6933])\n",
      "J: 13.74761962890625,  b0: -4.270543098449707, b1: 5.342788219451904\n",
      "JGrad: tensor([0.0544]),  bGrad: tensor([0.4710, 0.2158])\n",
      "J: 13.735681533813477,  b0: -4.281030654907227, b1: 5.338637828826904\n",
      "JGrad: tensor([0.0270]),  bGrad: tensor([0.1467, 0.0266])\n",
      "J: 13.724143981933594,  b0: -4.2910332679748535, b1: 5.334750175476074\n",
      "JGrad: tensor([0.0436]),  bGrad: tensor([0.8536, 0.5395])\n",
      "J: 13.712483406066895,  b0: -4.303280353546143, b1: 5.3282151222229\n",
      "JGrad: tensor([-0.1894]),  bGrad: tensor([-0.9696, -0.3625])\n",
      "J: 13.707507133483887,  b0: -4.310624122619629, b1: 5.32436990737915\n",
      "JGrad: tensor([-0.1255]),  bGrad: tensor([-0.1656,  0.1027])\n",
      "J: 13.706684112548828,  b0: -4.316608905792236, b1: 5.320328235626221\n",
      "JGrad: tensor([-0.1086]),  bGrad: tensor([-0.5586, -0.2205])\n",
      "J: 13.709107398986816,  b0: -4.319874286651611, b1: 5.317931175231934\n",
      "JGrad: tensor([-0.2785]),  bGrad: tensor([-1.0384, -0.2137])\n",
      "J: 13.719392776489258,  b0: -4.318864345550537, b1: 5.316977500915527\n",
      "JGrad: tensor([-0.1099]),  bGrad: tensor([-1.0985, -0.6710])\n",
      "J: 13.731854438781738,  b0: -4.313775062561035, b1: 5.3199052810668945\n",
      "JGrad: tensor([-0.1563]),  bGrad: tensor([-1.0040, -0.4935])\n",
      "J: 13.747625350952148,  b0: -4.30537223815918, b1: 5.325327396392822\n",
      "JGrad: tensor([-0.1914]),  bGrad: tensor([-1.2442, -0.5806])\n",
      "J: 13.767391204833984,  b0: -4.2930731773376465, b1: 5.333488464355469\n",
      "JGrad: tensor([0.2108]),  bGrad: tensor([ 0.6703, -0.0306])\n",
      ">>>\t epoch 83:: loss = 0.186319500207901, validation loss = 0.160580575466156\n",
      "J: 13.779037475585938,  b0: -4.284550666809082, b1: 5.341012001037598\n",
      "JGrad: tensor([0.0904]),  bGrad: tensor([0.8852, 0.4545])\n",
      "J: 13.786890983581543,  b0: -4.280250072479248, b1: 5.345216751098633\n",
      "JGrad: tensor([0.2293]),  bGrad: tensor([1.6886, 0.7369])\n",
      "J: 13.787280082702637,  b0: -4.282812595367432, b1: 5.344833850860596\n",
      "JGrad: tensor([-0.0267]),  bGrad: tensor([0.2179, 0.2266])\n",
      "J: 13.788409233093262,  b0: -4.285951137542725, b1: 5.343206405639648\n",
      "JGrad: tensor([0.1439]),  bGrad: tensor([1.1295, 0.5046])\n",
      "J: 13.785231590270996,  b0: -4.293081760406494, b1: 5.338882923126221\n",
      "JGrad: tensor([0.1665]),  bGrad: tensor([ 0.5488, -0.0239])\n",
      "J: 13.777520179748535,  b0: -4.301596641540527, b1: 5.335124492645264\n",
      "JGrad: tensor([0.0418]),  bGrad: tensor([0.3040, 0.1106])\n",
      "J: 13.769356727600098,  b0: -4.310425758361816, b1: 5.331111907958984\n",
      "JGrad: tensor([-0.1041]),  bGrad: tensor([-0.5710, -0.2585])\n",
      "J: 13.765044212341309,  b0: -4.316196441650391, b1: 5.328965187072754\n",
      "JGrad: tensor([-0.2501]),  bGrad: tensor([-0.5562,  0.1273])\n",
      "J: 13.768454551696777,  b0: -4.319267272949219, b1: 5.326308727264404\n",
      "JGrad: tensor([-0.1085]),  bGrad: tensor([0.4569, 0.5744])\n",
      "J: 13.774688720703125,  b0: -4.323780059814453, b1: 5.320652961730957\n",
      "JGrad: tensor([-0.3663]),  bGrad: tensor([-1.4907, -0.3474])\n",
      "J: 13.790936470031738,  b0: -4.322141170501709, b1: 5.317534923553467\n",
      "JGrad: tensor([-0.1135]),  bGrad: tensor([-1.0817, -0.6550])\n",
      "J: 13.808868408203125,  b0: -4.316529273986816, b1: 5.318453311920166\n",
      "JGrad: tensor([0.0950]),  bGrad: tensor([-0.3215, -0.5418])\n",
      "J: 13.822251319885254,  b0: -4.310244560241699, b1: 5.32236385345459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.0496]),  bGrad: tensor([-2.2991, -2.0470])\n",
      ">>>\t epoch 84:: loss = 0.21311965584754944, validation loss = 0.15868261456489563\n",
      "J: 13.832858085632324,  b0: -4.295812606811523, b1: 5.337481498718262\n",
      "JGrad: tensor([0.0687]),  bGrad: tensor([-0.2374, -0.3998])\n",
      "J: 13.840408325195312,  b0: -4.281907081604004, b1: 5.35336446762085\n",
      "JGrad: tensor([0.0872]),  bGrad: tensor([0.8537, 0.4309])\n",
      "J: 13.84466552734375,  b0: -4.2726521492004395, b1: 5.365220069885254\n",
      "JGrad: tensor([0.1329]),  bGrad: tensor([0.4771, 0.0220])\n",
      "J: 13.844619750976562,  b0: -4.266143798828125, b1: 5.3757734298706055\n",
      "JGrad: tensor([0.0504]),  bGrad: tensor([-0.0387, -0.1889])\n",
      "J: 13.843108177185059,  b0: -4.260133266448975, b1: 5.3863525390625\n",
      "JGrad: tensor([-0.0090]),  bGrad: tensor([0.8568, 0.6816])\n",
      "J: 13.842009544372559,  b0: -4.258005142211914, b1: 5.391999244689941\n",
      "JGrad: tensor([0.0668]),  bGrad: tensor([1.2757, 0.8244])\n",
      "J: 13.839065551757812,  b0: -4.260979175567627, b1: 5.392391681671143\n",
      "JGrad: tensor([-0.1118]),  bGrad: tensor([1.3627, 1.3269])\n",
      "J: 13.839685440063477,  b0: -4.268877983093262, b1: 5.3852033615112305\n",
      "JGrad: tensor([0.1333]),  bGrad: tensor([0.9688, 0.4042])\n",
      "J: 13.836342811584473,  b0: -4.279703140258789, b1: 5.376431465148926\n",
      "JGrad: tensor([0.0392]),  bGrad: tensor([0.2227, 0.0657])\n",
      "J: 13.832184791564941,  b0: -4.29030704498291, b1: 5.368156909942627\n",
      "JGrad: tensor([0.1934]),  bGrad: tensor([1.4571, 0.6382])\n",
      "J: 13.822781562805176,  b0: -4.3054375648498535, b1: 5.35707426071167\n",
      "JGrad: tensor([0.1582]),  bGrad: tensor([1.4267, 0.7117])\n",
      "J: 13.809687614440918,  b0: -4.324524402618408, b1: 5.343044281005859\n",
      "JGrad: tensor([-0.1694]),  bGrad: tensor([-1.0777, -0.5220])\n",
      "J: 13.802863121032715,  b0: -4.3375725746154785, b1: 5.333384990692139\n",
      "JGrad: tensor([-0.1015]),  bGrad: tensor([-0.3352, -0.0848])\n",
      ">>>\t epoch 85:: loss = 0.18882159888744354, validation loss = 0.18678408861160278\n",
      "J: 13.799692153930664,  b0: -4.3480377197265625, b1: 5.325168609619141\n",
      "JGrad: tensor([0.0026]),  bGrad: tensor([-1.5010, -1.2858])\n",
      "J: 13.796759605407715,  b0: -4.351693630218506, b1: 5.3251051902771\n",
      "JGrad: tensor([-0.1124]),  bGrad: tensor([-1.1780, -0.7623])\n",
      "J: 13.797414779663086,  b0: -4.350462913513184, b1: 5.3293914794921875\n",
      "JGrad: tensor([-0.0952]),  bGrad: tensor([-0.4614, -0.1924])\n",
      "J: 13.800798416137695,  b0: -4.3475823402404785, b1: 5.334348678588867\n",
      "JGrad: tensor([-0.1394]),  bGrad: tensor([-2.2638, -1.5685])\n",
      "J: 13.80793571472168,  b0: -4.336312294006348, b1: 5.347731590270996\n",
      "JGrad: tensor([-0.1713]),  bGrad: tensor([0.8436, 1.0533])\n",
      "J: 13.81938648223877,  b0: -4.32940149307251, b1: 5.353778839111328\n",
      "JGrad: tensor([-0.1017]),  bGrad: tensor([0.1632, 0.3362])\n",
      "J: 13.832682609558105,  b0: -4.323803424835205, b1: 5.3573102951049805\n",
      "JGrad: tensor([0.0227]),  bGrad: tensor([0.6933, 0.4727])\n",
      "J: 13.84399127960205,  b0: -4.321425914764404, b1: 5.357797145843506\n",
      "JGrad: tensor([0.1138]),  bGrad: tensor([1.1195, 0.5821])\n",
      "J: 13.850828170776367,  b0: -4.323586940765381, b1: 5.354918003082275\n",
      "JGrad: tensor([-0.0310]),  bGrad: tensor([-1.4722, -1.1563])\n",
      "J: 13.85789680480957,  b0: -4.319875717163086, b1: 5.358914852142334\n",
      "JGrad: tensor([0.0940]),  bGrad: tensor([-0.1716, -0.4163])\n",
      "J: 13.861495018005371,  b0: -4.315873622894287, b1: 5.36488676071167\n",
      "JGrad: tensor([-0.0261]),  bGrad: tensor([0.6718, 0.5794])\n",
      "J: 13.865503311157227,  b0: -4.314853668212891, b1: 5.366960048675537\n",
      "JGrad: tensor([0.1527]),  bGrad: tensor([1.3125, 0.6385])\n",
      "J: 13.864614486694336,  b0: -4.318984031677246, b1: 5.365184307098389\n",
      "JGrad: tensor([0.0757]),  bGrad: tensor([0.7724, 0.4000])\n",
      ">>>\t epoch 86:: loss = 0.30380162596702576, validation loss = 0.15163230895996094\n",
      "J: 13.86158275604248,  b0: -4.3256754875183105, b1: 5.361302375793457\n",
      "JGrad: tensor([0.0713]),  bGrad: tensor([0.7738, 0.4194])\n",
      "J: 13.856749534606934,  b0: -4.334680080413818, b1: 5.355411529541016\n",
      "JGrad: tensor([0.1200]),  bGrad: tensor([-0.2610, -0.5679])\n",
      "J: 13.848858833312988,  b0: -4.3417840003967285, b1: 5.353352069854736\n",
      "JGrad: tensor([-0.2323]),  bGrad: tensor([-0.5214,  0.0853])\n",
      "J: 13.848609924316406,  b0: -4.3461713790893555, b1: 5.351009368896484\n",
      "JGrad: tensor([-0.1311]),  bGrad: tensor([-0.9692, -0.5132])\n",
      "J: 13.852251052856445,  b0: -4.346384048461914, b1: 5.35183572769165\n",
      "JGrad: tensor([-0.1750]),  bGrad: tensor([-1.0596, -0.4745])\n",
      "J: 13.860688209533691,  b0: -4.3424882888793945, b1: 5.355295181274414\n",
      "JGrad: tensor([-0.0543]),  bGrad: tensor([-0.1022, -0.0094])\n",
      "J: 13.869890213012695,  b0: -4.338584899902344, b1: 5.358464241027832\n",
      "JGrad: tensor([0.1252]),  bGrad: tensor([ 0.1320, -0.2771])\n",
      "J: 13.874478340148926,  b0: -4.335578918457031, b1: 5.362906455993652\n",
      "JGrad: tensor([0.1576]),  bGrad: tensor([ 0.4872, -0.0504])\n",
      "J: 13.873956680297852,  b0: -4.334754943847656, b1: 5.367196559906006\n",
      "JGrad: tensor([-0.0288]),  bGrad: tensor([-0.0028,  0.0558])\n",
      "J: 13.874338150024414,  b0: -4.3340020179748535, b1: 5.3707404136657715\n",
      "JGrad: tensor([-0.0128]),  bGrad: tensor([-0.8299, -0.6690])\n",
      "J: 13.875059127807617,  b0: -4.330112457275391, b1: 5.377771854400635\n",
      "JGrad: tensor([0.1037]),  bGrad: tensor([ 0.1211, -0.1949])\n",
      "J: 13.872639656066895,  b0: -4.327078342437744, b1: 5.385224342346191\n",
      "JGrad: tensor([0.0925]),  bGrad: tensor([1.2394, 0.7239])\n",
      "J: 13.867722511291504,  b0: -4.329147815704346, b1: 5.387773036956787\n",
      "JGrad: tensor([0.0856]),  bGrad: tensor([1.2216, 0.7357])\n",
      ">>>\t epoch 87:: loss = 0.28869444131851196, validation loss = 0.1501152068376541\n",
      "J: 13.860759735107422,  b0: -4.335741996765137, b1: 5.385838508605957\n",
      "JGrad: tensor([0.1252]),  bGrad: tensor([0.4751, 0.0397])\n",
      "J: 13.85078239440918,  b0: -4.343522071838379, b1: 5.383867263793945\n",
      "JGrad: tensor([-0.2482]),  bGrad: tensor([-0.9155, -0.1740])\n",
      "J: 13.849156379699707,  b0: -4.346977233886719, b1: 5.38309383392334\n",
      "JGrad: tensor([-0.1247]),  bGrad: tensor([0.0987, 0.3205])\n",
      "J: 13.851383209228516,  b0: -4.3504719734191895, b1: 5.380551338195801\n",
      "JGrad: tensor([-0.1199]),  bGrad: tensor([-1.1420, -0.6969])\n",
      "J: 13.856940269470215,  b0: -4.349185943603516, b1: 5.382277965545654\n",
      "JGrad: tensor([-0.1989]),  bGrad: tensor([-0.1649,  0.3014])\n",
      "J: 13.867827415466309,  b0: -4.347387313842773, b1: 5.3820953369140625\n",
      "JGrad: tensor([-0.1167]),  bGrad: tensor([-0.4926, -0.1531])\n",
      "J: 13.881086349487305,  b0: -4.34385347366333, b1: 5.382813930511475\n",
      "JGrad: tensor([0.0065]),  bGrad: tensor([0.1420, 0.0723])\n",
      "J: 13.89283561706543,  b0: -4.341223239898682, b1: 5.3830437660217285\n",
      "JGrad: tensor([-0.0473]),  bGrad: tensor([0.7614, 0.7162])\n",
      "J: 13.90481948852539,  b0: -4.341817378997803, b1: 5.379114627838135\n",
      "JGrad: tensor([0.1361]),  bGrad: tensor([0.9852, 0.4041])\n",
      "J: 13.91157054901123,  b0: -4.34618616104126, b1: 5.373240947723389\n",
      "JGrad: tensor([0.1442]),  bGrad: tensor([0.9332, 0.3584])\n",
      "J: 13.913368225097656,  b0: -4.353752613067627, b1: 5.365879535675049\n",
      "JGrad: tensor([0.0722]),  bGrad: tensor([-1.0465, -1.0739])\n",
      "J: 13.912843704223633,  b0: -4.3564887046813965, b1: 5.3654632568359375\n",
      "JGrad: tensor([-0.2969]),  bGrad: tensor([-1.2337, -0.2992])\n",
      "J: 13.921174049377441,  b0: -4.354146957397461, b1: 5.366818428039551\n",
      "JGrad: tensor([0.2927]),  bGrad: tensor([ 0.7768, -0.1863])\n",
      ">>>\t epoch 88:: loss = 0.18769191205501556, validation loss = 0.15790241956710815\n",
      "J: 13.919997215270996,  b0: -4.355064868927002, b1: 5.369117259979248\n",
      "JGrad: tensor([0.0936]),  bGrad: tensor([-0.0009, -0.2956])\n",
      "J: 13.916166305541992,  b0: -4.3558878898620605, b1: 5.372899532318115\n",
      "JGrad: tensor([0.0649]),  bGrad: tensor([ 0.1494, -0.0694])\n",
      "J: 13.910792350769043,  b0: -4.357212066650391, b1: 5.376708030700684\n",
      "JGrad: tensor([-0.0599]),  bGrad: tensor([-0.6879, -0.4529])\n",
      "J: 13.90772819519043,  b0: -4.355719566345215, b1: 5.382763862609863\n",
      "JGrad: tensor([-0.1695]),  bGrad: tensor([-0.1592,  0.2249])\n",
      "J: 13.909997940063477,  b0: -4.353753089904785, b1: 5.386912822723389\n",
      "JGrad: tensor([0.1140]),  bGrad: tensor([-0.0594, -0.3787])\n",
      "J: 13.908659934997559,  b0: -4.351749897003174, b1: 5.392847537994385\n",
      "JGrad: tensor([0.0125]),  bGrad: tensor([0.3665, 0.2229])\n",
      "J: 13.907083511352539,  b0: -4.35137939453125, b1: 5.396896839141846\n",
      "JGrad: tensor([0.0957]),  bGrad: tensor([0.9146, 0.4696])\n",
      "J: 13.90282154083252,  b0: -4.354625225067139, b1: 5.39781379699707\n",
      "JGrad: tensor([-0.2758]),  bGrad: tensor([-0.7616,  0.0346])\n",
      "J: 13.907172203063965,  b0: -4.3545660972595215, b1: 5.398437976837158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0983]),  bGrad: tensor([-0.2664, -0.0291])\n",
      "J: 13.914007186889648,  b0: -4.353469371795654, b1: 5.399169445037842\n",
      "JGrad: tensor([0.1075]),  bGrad: tensor([0.7719, 0.3235])\n",
      "J: 13.916969299316406,  b0: -4.3555073738098145, b1: 5.39794397354126\n",
      "JGrad: tensor([0.1448]),  bGrad: tensor([1.5834, 0.8649])\n",
      "J: 13.915336608886719,  b0: -4.3635454177856445, b1: 5.39180326461792\n",
      "JGrad: tensor([-0.2456]),  bGrad: tensor([-1.6784, -0.7797])\n",
      "J: 13.921156883239746,  b0: -4.364202499389648, b1: 5.390817642211914\n",
      "JGrad: tensor([-0.1262]),  bGrad: tensor([-0.6011, -0.2345])\n",
      ">>>\t epoch 89:: loss = 0.15116937458515167, validation loss = 0.15314437448978424\n",
      "J: 13.930144309997559,  b0: -4.362438678741455, b1: 5.391296863555908\n",
      "JGrad: tensor([-0.2510]),  bGrad: tensor([-1.3130, -0.5022])\n",
      "J: 13.945670127868652,  b0: -4.355706691741943, b1: 5.394657611846924\n",
      "JGrad: tensor([0.1497]),  bGrad: tensor([ 0.1235, -0.3294])\n",
      "J: 13.955205917358398,  b0: -4.350127696990967, b1: 5.399606704711914\n",
      "JGrad: tensor([0.1663]),  bGrad: tensor([ 0.4569, -0.0851])\n",
      "J: 13.958854675292969,  b0: -4.346896171569824, b1: 5.4045610427856445\n",
      "JGrad: tensor([0.0896]),  bGrad: tensor([ 0.2970, -0.0141])\n",
      "J: 13.959480285644531,  b0: -4.345151901245117, b1: 5.4091057777404785\n",
      "JGrad: tensor([0.1233]),  bGrad: tensor([1.4901, 0.8438])\n",
      "J: 13.956384658813477,  b0: -4.34943151473999, b1: 5.408264636993408\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([-0.1265, -0.1358])\n",
      "J: 13.953621864318848,  b0: -4.352788925170898, b1: 5.40830135345459\n",
      "JGrad: tensor([0.0959]),  bGrad: tensor([0.5586, 0.1688])\n",
      "J: 13.948284149169922,  b0: -4.358007907867432, b1: 5.407346725463867\n",
      "JGrad: tensor([0.0789]),  bGrad: tensor([0.7695, 0.3916])\n",
      "J: 13.941129684448242,  b0: -4.3657331466674805, b1: 5.404193878173828\n",
      "JGrad: tensor([-0.0259]),  bGrad: tensor([-0.2194, -0.1766])\n",
      "J: 13.935456275939941,  b0: -4.371827125549316, b1: 5.402389049530029\n",
      "JGrad: tensor([-0.0747]),  bGrad: tensor([0.2408, 0.3277])\n",
      "J: 13.932572364807129,  b0: -4.3782639503479, b1: 5.398841857910156\n",
      "JGrad: tensor([-0.1747]),  bGrad: tensor([-0.3882,  0.0817])\n",
      "J: 13.935179710388184,  b0: -4.382531642913818, b1: 5.395167827606201\n",
      "JGrad: tensor([-0.2857]),  bGrad: tensor([-1.5565, -0.5915])\n",
      "J: 13.946019172668457,  b0: -4.380239963531494, b1: 5.395332336425781\n",
      "JGrad: tensor([0.0746]),  bGrad: tensor([0.8360, 0.4320])\n",
      ">>>\t epoch 90:: loss = 0.17884668707847595, validation loss = 0.16496405005455017\n",
      "J: 13.953560829162598,  b0: -4.381471157073975, b1: 5.392942905426025\n",
      "JGrad: tensor([-0.2551]),  bGrad: tensor([-1.2734, -0.4461])\n",
      "J: 13.967924118041992,  b0: -4.377561569213867, b1: 5.393413066864014\n",
      "JGrad: tensor([0.0225]),  bGrad: tensor([-0.4589, -0.5101])\n",
      "J: 13.98019027709961,  b0: -4.3722310066223145, b1: 5.3968353271484375\n",
      "JGrad: tensor([0.1372]),  bGrad: tensor([0.8015, 0.2581])\n",
      "J: 13.987149238586426,  b0: -4.370593070983887, b1: 5.3983988761901855\n",
      "JGrad: tensor([0.0168]),  bGrad: tensor([-0.3178, -0.3512])\n",
      "J: 13.99291706085205,  b0: -4.367863655090332, b1: 5.401874542236328\n",
      "JGrad: tensor([-0.0201]),  bGrad: tensor([-1.1354, -0.8947])\n",
      "J: 13.998709678649902,  b0: -4.360924243927002, b1: 5.410268783569336\n",
      "JGrad: tensor([0.1560]),  bGrad: tensor([0.8352, 0.2462])\n",
      "J: 13.999275207519531,  b0: -4.357974529266357, b1: 5.416378498077393\n",
      "JGrad: tensor([0.0600]),  bGrad: tensor([0.2661, 0.0291])\n",
      "J: 13.997995376586914,  b0: -4.356369972229004, b1: 5.4217095375061035\n",
      "JGrad: tensor([0.0862]),  bGrad: tensor([0.3623, 0.0303])\n",
      "J: 13.994270324707031,  b0: -4.356357574462891, b1: 5.426331996917725\n",
      "JGrad: tensor([0.1346]),  bGrad: tensor([0.7400, 0.2274])\n",
      "J: 13.98690128326416,  b0: -4.359274864196777, b1: 5.429152965545654\n",
      "JGrad: tensor([0.0951]),  bGrad: tensor([0.4336, 0.0835])\n",
      "J: 13.97742748260498,  b0: -4.363618850708008, b1: 5.4312005043029785\n",
      "JGrad: tensor([0.0655]),  bGrad: tensor([0.9918, 0.6053])\n",
      "J: 13.966938972473145,  b0: -4.371457099914551, b1: 5.429467678070068\n",
      "JGrad: tensor([-0.0404]),  bGrad: tensor([0.3250, 0.3386])\n",
      "J: 13.958700180053711,  b0: -4.379804611206055, b1: 5.425905227661133\n",
      "JGrad: tensor([-0.0111]),  bGrad: tensor([1.6703, 1.2803])\n",
      ">>>\t epoch 91:: loss = 0.3406672179698944, validation loss = 0.1678246706724167\n",
      "J: 13.95161247253418,  b0: -4.393929481506348, b1: 5.415139198303223\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([-0.3754, -0.3697])\n",
      "J: 13.945235252380371,  b0: -4.405162334442139, b1: 5.407629013061523\n",
      "JGrad: tensor([-0.2624]),  bGrad: tensor([-1.1567, -0.3273])\n",
      "J: 13.947349548339844,  b0: -4.410687446594238, b1: 5.402801513671875\n",
      "JGrad: tensor([-0.2044]),  bGrad: tensor([-0.8132, -0.2203])\n",
      "J: 13.955362319946289,  b0: -4.4124369621276855, b1: 5.399757385253906\n",
      "JGrad: tensor([-0.2887]),  bGrad: tensor([-1.9954, -0.9512])\n",
      "J: 13.97118091583252,  b0: -4.406105041503906, b1: 5.402646064758301\n",
      "JGrad: tensor([-0.2477]),  bGrad: tensor([-1.2284, -0.4323])\n",
      "J: 13.992793083190918,  b0: -4.3955397605896, b1: 5.407806396484375\n",
      "JGrad: tensor([-0.1384]),  bGrad: tensor([-1.2572, -0.7340])\n",
      "J: 14.016376495361328,  b0: -4.3810505867004395, b1: 5.416797637939453\n",
      "JGrad: tensor([0.1027]),  bGrad: tensor([ 0.2009, -0.1396])\n",
      "J: 14.0345458984375,  b0: -4.368797779083252, b1: 5.425722599029541\n",
      "JGrad: tensor([0.0191]),  bGrad: tensor([0.3054, 0.1792])\n",
      "J: 14.050337791442871,  b0: -4.358973979949951, b1: 5.4326982498168945\n",
      "JGrad: tensor([0.1131]),  bGrad: tensor([1.0596, 0.5453])\n",
      "J: 14.061176300048828,  b0: -4.354334831237793, b1: 5.435744762420654\n",
      "JGrad: tensor([0.1522]),  bGrad: tensor([2.0244, 1.2033])\n",
      "J: 14.066384315490723,  b0: -4.358188152313232, b1: 5.431352615356445\n",
      "JGrad: tensor([0.0447]),  bGrad: tensor([0.1713, 0.0005])\n",
      "J: 14.06973934173584,  b0: -4.362338066101074, b1: 5.427393436431885\n",
      "JGrad: tensor([0.1950]),  bGrad: tensor([ 0.1011, -0.4434])\n",
      "J: 14.066927909851074,  b0: -4.366476535797119, b1: 5.426459789276123\n",
      "JGrad: tensor([0.1933]),  bGrad: tensor([2.4970, 1.4738])\n",
      ">>>\t epoch 92:: loss = 0.22833845019340515, validation loss = 0.15432710945606232\n",
      "J: 14.058619499206543,  b0: -4.3800835609436035, b1: 5.4168877601623535\n",
      "JGrad: tensor([0.1393]),  bGrad: tensor([-0.0420, -0.4494])\n",
      "J: 14.046976089477539,  b0: -4.392171859741211, b1: 5.410932540893555\n",
      "JGrad: tensor([0.1794]),  bGrad: tensor([ 0.2480, -0.2823])\n",
      "J: 14.031135559082031,  b0: -4.404042720794678, b1: 5.4072442054748535\n",
      "JGrad: tensor([-0.0615]),  bGrad: tensor([-1.6762, -1.2842])\n",
      "J: 14.018709182739258,  b0: -4.40807580947876, b1: 5.411539077758789\n",
      "JGrad: tensor([0.0124]),  bGrad: tensor([-0.1074, -0.1884])\n",
      "J: 14.007147789001465,  b0: -4.411282062530518, b1: 5.416524410247803\n",
      "JGrad: tensor([-0.1561]),  bGrad: tensor([-1.7193, -1.0624])\n",
      "J: 14.00141429901123,  b0: -4.407349586486816, b1: 5.427308082580566\n",
      "JGrad: tensor([-0.1910]),  bGrad: tensor([-0.8279, -0.2443])\n",
      "J: 14.001971244812012,  b0: -4.4005255699157715, b1: 5.4384684562683105\n",
      "JGrad: tensor([-0.1264]),  bGrad: tensor([0.2339, 0.4491])\n",
      "J: 14.006255149841309,  b0: -4.395307540893555, b1: 5.445852279663086\n",
      "JGrad: tensor([-0.1519]),  bGrad: tensor([-0.5412, -0.1081])\n",
      "J: 14.01465892791748,  b0: -4.3884596824646, b1: 5.453144550323486\n",
      "JGrad: tensor([0.0576]),  bGrad: tensor([0.7949, 0.4741])\n",
      "J: 14.020500183105469,  b0: -4.385451793670654, b1: 5.456892967224121\n",
      "JGrad: tensor([0.0082]),  bGrad: tensor([0.5727, 0.4044])\n",
      "J: 14.02551555633545,  b0: -4.385019779205322, b1: 5.457864284515381\n",
      "JGrad: tensor([-0.0042]),  bGrad: tensor([-0.0477, -0.0583])\n",
      "J: 14.030158996582031,  b0: -4.384440898895264, b1: 5.459085941314697\n",
      "JGrad: tensor([0.1389]),  bGrad: tensor([1.3380, 0.6866])\n",
      "J: 14.030170440673828,  b0: -4.389242172241211, b1: 5.456099510192871\n",
      "JGrad: tensor([0.0976]),  bGrad: tensor([ 0.2710, -0.0690])\n",
      ">>>\t epoch 93:: loss = 0.1815822273492813, validation loss = 0.14746609330177307\n",
      "J: 14.027250289916992,  b0: -4.394644737243652, b1: 5.453820705413818\n",
      "JGrad: tensor([-0.1538]),  bGrad: tensor([-0.2426,  0.1361])\n",
      "J: 14.029240608215332,  b0: -4.3985443115234375, b1: 5.450957298278809\n",
      "JGrad: tensor([-0.0448]),  bGrad: tensor([0.3566, 0.3330])\n",
      "J: 14.032380104064941,  b0: -4.403477668762207, b1: 5.44639253616333\n",
      "JGrad: tensor([-0.2061]),  bGrad: tensor([-1.0317, -0.3798])\n",
      "J: 14.041394233703613,  b0: -4.403805732727051, b1: 5.4445481300354\n",
      "JGrad: tensor([-0.1892]),  bGrad: tensor([-0.4870,  0.0161])\n",
      "J: 14.05518627166748,  b0: -4.402158737182617, b1: 5.442790985107422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.0742]),  bGrad: tensor([-0.1534, -0.3519])\n",
      "J: 14.065376281738281,  b0: -4.4000630378723145, b1: 5.4433112144470215\n",
      "JGrad: tensor([0.0847]),  bGrad: tensor([ 0.1170, -0.1628])\n",
      "J: 14.072004318237305,  b0: -4.3986430168151855, b1: 5.4447526931762695\n",
      "JGrad: tensor([0.0527]),  bGrad: tensor([-0.5599, -0.6483])\n",
      "J: 14.07638931274414,  b0: -4.3951263427734375, b1: 5.449926853179932\n",
      "JGrad: tensor([-0.0310]),  bGrad: tensor([0.1265, 0.1592])\n",
      "J: 14.08127212524414,  b0: -4.392465114593506, b1: 5.453634262084961\n",
      "JGrad: tensor([0.0347]),  bGrad: tensor([0.2277, 0.0779])\n",
      "J: 14.084626197814941,  b0: -4.390979290008545, b1: 5.456506729125977\n",
      "JGrad: tensor([0.1314]),  bGrad: tensor([0.9012, 0.3644])\n",
      "J: 14.083687782287598,  b0: -4.393249988555908, b1: 5.456909656524658\n",
      "JGrad: tensor([0.1577]),  bGrad: tensor([1.2696, 0.5890])\n",
      "J: 14.078089714050293,  b0: -4.400376319885254, b1: 5.453742027282715\n",
      "JGrad: tensor([-0.0529]),  bGrad: tensor([0.1525, 0.2303])\n",
      "J: 14.0746431350708,  b0: -4.407405853271484, b1: 5.449507713317871\n",
      "JGrad: tensor([0.0210]),  bGrad: tensor([0.5137, 0.3388])\n",
      ">>>\t epoch 94:: loss = 0.08103422820568085, validation loss = 0.1580277532339096\n",
      "J: 14.070906639099121,  b0: -4.41579532623291, b1: 5.443661689758301\n",
      "JGrad: tensor([-0.2030]),  bGrad: tensor([-1.0120, -0.3591])\n",
      "J: 14.073668479919434,  b0: -4.419290065765381, b1: 5.440553665161133\n",
      "JGrad: tensor([-0.1999]),  bGrad: tensor([-1.4211, -0.6953])\n",
      "J: 14.082180976867676,  b0: -4.4167375564575195, b1: 5.44193172454834\n",
      "JGrad: tensor([-0.0911]),  bGrad: tensor([-0.3347, -0.1111])\n",
      "J: 14.0925931930542,  b0: -4.413095951080322, b1: 5.443840503692627\n",
      "JGrad: tensor([0.0896]),  bGrad: tensor([ 0.1514, -0.1428])\n",
      "J: 14.099265098571777,  b0: -4.41042423248291, b1: 5.446418762207031\n",
      "JGrad: tensor([0.0525]),  bGrad: tensor([-1.0094, -0.9966])\n",
      "J: 14.103689193725586,  b0: -4.403965950012207, b1: 5.45473051071167\n",
      "JGrad: tensor([0.0074]),  bGrad: tensor([0.2476, 0.1581])\n",
      "J: 14.107450485229492,  b0: -4.399144649505615, b1: 5.4612650871276855\n",
      "JGrad: tensor([0.1107]),  bGrad: tensor([0.8207, 0.3454])\n",
      "J: 14.107490539550781,  b0: -4.398102760314941, b1: 5.4650702476501465\n",
      "JGrad: tensor([0.0517]),  bGrad: tensor([0.2436, 0.0385])\n",
      "J: 14.105961799621582,  b0: -4.398144245147705, b1: 5.468265533447266\n",
      "JGrad: tensor([0.1340]),  bGrad: tensor([1.4420, 0.7969])\n",
      "J: 14.100529670715332,  b0: -4.403980255126953, b1: 5.466340065002441\n",
      "JGrad: tensor([0.0149]),  bGrad: tensor([-0.0081, -0.0752])\n",
      "J: 14.095187187194824,  b0: -4.409204006195068, b1: 5.465059280395508\n",
      "JGrad: tensor([0.1944]),  bGrad: tensor([1.7973, 0.9079])\n",
      "J: 14.084494590759277,  b0: -4.42112922668457, b1: 5.458433628082275\n",
      "JGrad: tensor([-0.1901]),  bGrad: tensor([-1.0469, -0.4161])\n",
      "J: 14.08062744140625,  b0: -4.4276533126831055, b1: 5.454977512359619\n",
      "JGrad: tensor([0.0408]),  bGrad: tensor([1.3189, 0.8612])\n",
      ">>>\t epoch 95:: loss = 0.27420908212661743, validation loss = 0.1760612428188324\n",
      "J: 14.075908660888672,  b0: -4.438828468322754, b1: 5.4466729164123535\n",
      "JGrad: tensor([-0.1358]),  bGrad: tensor([-1.0943, -0.6224])\n",
      "J: 14.075774192810059,  b0: -4.444486141204834, b1: 5.442951679229736\n",
      "JGrad: tensor([-0.0173]),  bGrad: tensor([0.1736, 0.1348])\n",
      "J: 14.076178550720215,  b0: -4.45028018951416, b1: 5.438786506652832\n",
      "JGrad: tensor([-0.1603]),  bGrad: tensor([-1.5307, -0.9006])\n",
      "J: 14.081402778625488,  b0: -4.449334144592285, b1: 5.440474510192871\n",
      "JGrad: tensor([-0.1410]),  bGrad: tensor([-0.4078, -0.0216])\n",
      "J: 14.090381622314453,  b0: -4.446840763092041, b1: 5.4421257972717285\n",
      "JGrad: tensor([-0.1910]),  bGrad: tensor([-2.4055, -1.5374])\n",
      "J: 14.104249954223633,  b0: -4.434934616088867, b1: 5.452880382537842\n",
      "JGrad: tensor([-0.1030]),  bGrad: tensor([-0.0675,  0.1163])\n",
      "J: 14.119861602783203,  b0: -4.423940181732178, b1: 5.461864471435547\n",
      "JGrad: tensor([0.0082]),  bGrad: tensor([-1.1938, -1.0447])\n",
      "J: 14.133672714233398,  b0: -4.409244060516357, b1: 5.476247787475586\n",
      "JGrad: tensor([-0.0439]),  bGrad: tensor([-0.0133,  0.0810])\n",
      "J: 14.147442817687988,  b0: -4.3959550857543945, b1: 5.488713264465332\n",
      "JGrad: tensor([0.1134]),  bGrad: tensor([1.4651, 0.8619])\n",
      "J: 14.156394958496094,  b0: -4.389892578125, b1: 5.494729042053223\n",
      "JGrad: tensor([0.0971]),  bGrad: tensor([0.9466, 0.4889])\n",
      "J: 14.161503791809082,  b0: -4.388244152069092, b1: 5.497193336486816\n",
      "JGrad: tensor([0.3005]),  bGrad: tensor([ 0.5896, -0.3241])\n",
      "J: 14.156974792480469,  b0: -4.389133930206299, b1: 5.501370906829834\n",
      "JGrad: tensor([0.1116]),  bGrad: tensor([0.9431, 0.4413])\n",
      "J: 14.149511337280273,  b0: -4.393733501434326, b1: 5.50246524810791\n",
      "JGrad: tensor([0.0725]),  bGrad: tensor([ 0.2647, -0.0030])\n",
      ">>>\t epoch 96:: loss = 0.2333630621433258, validation loss = 0.16089370846748352\n",
      "J: 14.140588760375977,  b0: -4.398942470550537, b1: 5.5034685134887695\n",
      "JGrad: tensor([0.1006]),  bGrad: tensor([0.5494, 0.1580])\n",
      "J: 14.129497528076172,  b0: -4.405848503112793, b1: 5.503416061401367\n",
      "JGrad: tensor([0.0898]),  bGrad: tensor([1.5246, 0.9670])\n",
      "J: 14.116779327392578,  b0: -4.41820764541626, b1: 5.497516632080078\n",
      "JGrad: tensor([0.0560]),  bGrad: tensor([0.2870, 0.0707])\n",
      "J: 14.103623390197754,  b0: -4.4304962158203125, b1: 5.491775035858154\n",
      "JGrad: tensor([0.0132]),  bGrad: tensor([0.7141, 0.4692])\n",
      "J: 14.091373443603516,  b0: -4.444443225860596, b1: 5.483761787414551\n",
      "JGrad: tensor([-0.1461]),  bGrad: tensor([-0.9661, -0.4872])\n",
      "J: 14.084794998168945,  b0: -4.453098773956299, b1: 5.479499816894531\n",
      "JGrad: tensor([-0.2221]),  bGrad: tensor([-0.8752, -0.2195])\n",
      "J: 14.085637092590332,  b0: -4.457357406616211, b1: 5.476992607116699\n",
      "JGrad: tensor([-0.2226]),  bGrad: tensor([-0.8632, -0.1695])\n",
      "J: 14.093164443969727,  b0: -4.457704544067383, b1: 5.475763320922852\n",
      "JGrad: tensor([-0.1894]),  bGrad: tensor([-1.2250, -0.5678])\n",
      "J: 14.105694770812988,  b0: -4.453068256378174, b1: 5.478104114532471\n",
      "JGrad: tensor([-0.2029]),  bGrad: tensor([-1.7671, -1.0055])\n",
      "J: 14.12313461303711,  b0: -4.441764831542969, b1: 5.486313343048096\n",
      "JGrad: tensor([-0.2571]),  bGrad: tensor([-0.7405, -0.0062])\n",
      "J: 14.146620750427246,  b0: -4.428596496582031, b1: 5.493744373321533\n",
      "JGrad: tensor([0.1709]),  bGrad: tensor([0.5798, 0.0068])\n",
      "J: 14.162568092346191,  b0: -4.419081687927246, b1: 5.500395774841309\n",
      "JGrad: tensor([0.0209]),  bGrad: tensor([-0.0247, -0.0978])\n",
      "J: 14.17629623413086,  b0: -4.410412311553955, b1: 5.506980895996094\n",
      "JGrad: tensor([0.0543]),  bGrad: tensor([-0.0576, -0.1945])\n",
      ">>>\t epoch 97:: loss = 0.06303466856479645, validation loss = 0.16516390442848206\n",
      "J: 14.18700885772705,  b0: -4.402370929718018, b1: 5.514095306396484\n",
      "JGrad: tensor([-0.0027]),  bGrad: tensor([-0.0078, -0.0146])\n",
      "J: 14.196738243103027,  b0: -4.395097255706787, b1: 5.5205912590026855\n",
      "JGrad: tensor([0.2348]),  bGrad: tensor([0.8388, 0.0428])\n",
      "J: 14.198349952697754,  b0: -4.391946315765381, b1: 5.526180744171143\n",
      "JGrad: tensor([0.1711]),  bGrad: tensor([2.3136, 1.3809])\n",
      "J: 14.194599151611328,  b0: -4.398471355438232, b1: 5.522799015045166\n",
      "JGrad: tensor([0.0408]),  bGrad: tensor([1.0514, 0.7160])\n",
      "J: 14.18997859954834,  b0: -4.408597469329834, b1: 5.515395641326904\n",
      "JGrad: tensor([0.1606]),  bGrad: tensor([0.8787, 0.2746])\n",
      "J: 14.18093490600586,  b0: -4.421269416809082, b1: 5.507055759429932\n",
      "JGrad: tensor([0.0715]),  bGrad: tensor([1.1593, 0.7137])\n",
      "J: 14.170614242553711,  b0: -4.437366008758545, b1: 5.495199680328369\n",
      "JGrad: tensor([0.0213]),  bGrad: tensor([-0.3987, -0.4007])\n",
      "J: 14.160672187805176,  b0: -4.450247764587402, b1: 5.486967086791992\n",
      "JGrad: tensor([-0.2396]),  bGrad: tensor([-1.0301, -0.2993])\n",
      "J: 14.159024238586426,  b0: -4.457672119140625, b1: 5.48137903213501\n",
      "JGrad: tensor([-0.1366]),  bGrad: tensor([-1.8636, -1.2226])\n",
      "J: 14.161699295043945,  b0: -4.456807613372803, b1: 5.4838056564331055\n",
      "JGrad: tensor([-0.2589]),  bGrad: tensor([0.0228, 0.5942])\n",
      "J: 14.171977996826172,  b0: -4.456121444702148, b1: 5.482367515563965\n",
      "JGrad: tensor([-0.2208]),  bGrad: tensor([-1.0668, -0.3518])\n",
      "J: 14.187934875488281,  b0: -4.451183795928955, b1: 5.483218193054199\n",
      "JGrad: tensor([-0.1344]),  bGrad: tensor([-1.0769, -0.6026])\n",
      "J: 14.206384658813477,  b0: -4.442377090454102, b1: 5.487661361694336\n",
      "JGrad: tensor([-0.0720]),  bGrad: tensor([-1.5762, -1.1530])\n",
      ">>>\t epoch 98:: loss = 0.1790802776813507, validation loss = 0.15173667669296265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 14.225187301635742,  b0: -4.428073406219482, b1: 5.498688697814941\n",
      "JGrad: tensor([0.1323]),  bGrad: tensor([1.4704, 0.8253])\n",
      "J: 14.23808765411377,  b0: -4.421154975891113, b1: 5.503580570220947\n",
      "JGrad: tensor([0.0994]),  bGrad: tensor([ 0.0993, -0.1956])\n",
      "J: 14.246678352355957,  b0: -4.4153265953063965, b1: 5.509179592132568\n",
      "JGrad: tensor([0.1152]),  bGrad: tensor([1.1808, 0.6276])\n",
      "J: 14.250904083251953,  b0: -4.414863109588623, b1: 5.51038932800293\n",
      "JGrad: tensor([0.0959]),  bGrad: tensor([ 0.0763, -0.2128])\n",
      "J: 14.251789093017578,  b0: -4.414755344390869, b1: 5.5127787590026855\n",
      "JGrad: tensor([0.0383]),  bGrad: tensor([0.8620, 0.5812])\n",
      "J: 14.25141716003418,  b0: -4.418153285980225, b1: 5.511378765106201\n",
      "JGrad: tensor([0.1790]),  bGrad: tensor([0.7839, 0.1383])\n",
      "J: 14.245628356933594,  b0: -4.424392223358154, b1: 5.509272575378418\n",
      "JGrad: tensor([0.1645]),  bGrad: tensor([1.1543, 0.4669])\n",
      "J: 14.235404968261719,  b0: -4.434690475463867, b1: 5.504519939422607\n",
      "JGrad: tensor([0.0330]),  bGrad: tensor([0.7562, 0.5000])\n",
      "J: 14.225192070007324,  b0: -4.4470319747924805, b1: 5.497181415557861\n",
      "JGrad: tensor([0.0204]),  bGrad: tensor([-0.5454, -0.5291])\n",
      "J: 14.215371131896973,  b0: -4.455930709838867, b1: 5.493813514709473\n",
      "JGrad: tensor([0.0242]),  bGrad: tensor([-0.1624, -0.2291])\n",
      "J: 14.20578670501709,  b0: -4.463284969329834, b1: 5.492183685302734\n",
      "JGrad: tensor([-0.1367]),  bGrad: tensor([-0.4143, -0.0529])\n",
      "J: 14.201334953308105,  b0: -4.468223571777344, b1: 5.491040229797363\n",
      "JGrad: tensor([-0.0647]),  bGrad: tensor([-0.5427, -0.3332])\n",
      "J: 14.199302673339844,  b0: -4.470462799072266, b1: 5.492054462432861\n",
      "JGrad: tensor([-0.1149]),  bGrad: tensor([0.1448, 0.3681])\n",
      ">>>\t epoch 99:: loss = 0.07072223722934723, validation loss = 0.17016640305519104\n",
      "J: 14.2009859085083,  b0: -4.473068714141846, b1: 5.490708351135254\n",
      "JGrad: tensor([-0.1578]),  bGrad: tensor([0.1582, 0.4770])\n",
      "J: 14.20732593536377,  b0: -4.476060390472412, b1: 5.486567497253418\n",
      "JGrad: tensor([-0.0857]),  bGrad: tensor([0.5164, 0.5788])\n",
      "J: 14.215656280517578,  b0: -4.480859279632568, b1: 5.479284763336182\n",
      "JGrad: tensor([-0.2028]),  bGrad: tensor([-2.6558, -1.7217])\n",
      "J: 14.229351043701172,  b0: -4.474369525909424, b1: 5.48329496383667\n",
      "JGrad: tensor([-0.0379]),  bGrad: tensor([-0.0807, -0.0303])\n",
      "J: 14.242844581604004,  b0: -4.468196392059326, b1: 5.4870924949646\n",
      "JGrad: tensor([-0.2051]),  bGrad: tensor([-1.9272, -1.1188])\n",
      "J: 14.26125717163086,  b0: -4.454813003540039, b1: 5.497364044189453\n",
      "JGrad: tensor([0.0986]),  bGrad: tensor([-0.3157, -0.5634])\n",
      "J: 14.27481746673584,  b0: -4.441476345062256, b1: 5.51006555557251\n",
      "JGrad: tensor([0.0234]),  bGrad: tensor([0.5551, 0.3648])\n",
      "J: 14.286312103271484,  b0: -4.43172550201416, b1: 5.519265651702881\n",
      "JGrad: tensor([0.0471]),  bGrad: tensor([0.4930, 0.2545])\n",
      "J: 14.295222282409668,  b0: -4.424951553344727, b1: 5.525988578796387\n",
      "JGrad: tensor([0.0364]),  bGrad: tensor([0.3868, 0.2022])\n",
      "J: 14.302130699157715,  b0: -4.420427322387695, b1: 5.530801773071289\n",
      "JGrad: tensor([0.1353]),  bGrad: tensor([1.3736, 0.7268])\n",
      "J: 14.304200172424316,  b0: -4.421951770782471, b1: 5.530670166015625\n",
      "JGrad: tensor([0.0376]),  bGrad: tensor([-0.3510, -0.4058])\n",
      "J: 14.304909706115723,  b0: -4.42189359664917, b1: 5.533045291900635\n",
      "JGrad: tensor([0.2024]),  bGrad: tensor([0.6804, 0.0051])\n",
      "J: 14.299341201782227,  b0: -4.424615859985352, b1: 5.535152912139893\n",
      "JGrad: tensor([0.1808]),  bGrad: tensor([ 0.4360, -0.1501])\n",
      ">>>\t epoch 100:: loss = 0.3348373472690582, validation loss = 0.16390223801136017\n"
     ]
    }
   ],
   "source": [
    "learning_curve = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for batch in trainloader:\n",
    "        X_batch, y_batch = Variable(batch['X'], requires_grad=False), Variable(batch['y'], requires_grad=False)\n",
    "        \n",
    "        print('J: {},  b0: {}, b1: {}'.format(j[0], b[0], b[1]))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        beliefs = model(j, b, X_batch)\n",
    "        loss = hinge_loss(beliefs, y_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        #b.grad.data[1].fill_(0)  # take b[1] as constant\n",
    "        print('JGrad: {},  bGrad: {}'.format(j.grad.data, b.grad.data))\n",
    "    \n",
    "        optimizer.step()\n",
    "     \n",
    "    decay_lr(optimizer, epoch) \n",
    "    \n",
    "    # evaluation\n",
    "    if epoch % 1 == 0:\n",
    "        valid = next(iter(validloader))\n",
    "        X_valid, y_valid = Variable(valid['X']), Variable(valid['y']) \n",
    "        with torch.no_grad():\n",
    "            beliefs_valid = model(j, b, X_valid)\n",
    "            loss_valid = hinge_loss(beliefs_valid, y_valid)\n",
    "\n",
    "        print('>>>\\t epoch {}:: loss = {}, validation loss = {}'. format(epoch, loss, loss_valid))\n",
    "        learning_curve.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': loss,\n",
    "            'loss_valid': loss_valid,\n",
    "            'b': [b.data.clone()[0], b.data.clone()[1]],\n",
    "            'j': j.data.clone()[0],\n",
    "            'b_grad': [b.grad.data.clone()[0], b.grad.data.clone()[1]],\n",
    "            'j_grad': j.grad.data.clone()[0]\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VOXZ//HPPXv2PQEStrDvq4A7iuIublVxq7VqH/1Z28eldWnVamtrterjXmu1rTu4FRVFUVBURBZl3yEhC9n3SWa/f3+cmWGSTCBgIEy43q8XLzMzJ2fuicl3rrnOfe6jtNYIIYToWUzdPQAhhBBdT8JdCCF6IAl3IYTogSTchRCiB5JwF0KIHkjCXQgheiAJdxETlFJXK6W+6qbnvksp9UJ3PLcQB8rS3QMQsUUpVQBcq7Ve2N1jOVS01g929xiE2F9SuYsjmlIq5gucnvAaRNeTcBddRil1nVJqm1KqRik1TynVJ3i/Uko9ppSqUErVK6XWKKVGBx87Uym1QSnVqJQqUUrd1snnGq6U+jT4XJuVUhdHPHaWUup7pVSDUqpIKXVfxGMDlFJaKfVzpdQu4POI+36qlNqllKpSSt0d8T33KaVeafP9HW0bp5T6t1KqVim1USn1G6VU8V5ex6iI11GulLoreP+/lFJ/jNhueuR+lFIFSqnfKqXWAE6l1O+UUm+12ff/KaWeCH6dopT6p1Jqd/Dn/EellLkzP2sRmyTcRZdQSp0M/Bm4GOgNFAJvBB+eCZwADAVSgUuA6uBj/wR+obVOAkYDn3fiuRKAT4HXgGxgNvCMUmpUcBMncFXwuc4CblBKnddmNycCI4DTIu47DhgGzADuUUqN2MswOtr2XmAAkA+cClyxl9eRBCwEPgb6AIOBz/bynG3Nxnh9qcDLwJlKqeTgvs0Y/y9eC277b8AXfI4JGP9Prt2P5xIxRsJddJXLgRe11qu01m7gTuBopdQAwAskAcMBpbXeqLXeHfw+LzBSKZWsta7VWq/qxHOdDRRorV/SWvuC3/M2cBGA1nqx1nqt1jqgtV4DvI4R5pHu01o7tdYtEff9QWvdorVeDawGxu1lDB1tezHwYPC1FANP7ON1lGmt/6a1dmmtG7XWyzrx+kOe0FoXBcdRCKwCQm9iJwPNWutvlVI5wBnAr4OvuQJ4DLh0P55LxBgJd9FV+mBU6wBorZswqvNcrfXnwFPA00C5Uur5UIUJXAicCRQqpb5QSh3diefqD0xVStWF/mG8ufQCUEpNVUotUkpVKqXqgf8BMtvsoyjKfssivm4GEvcyho627dNm39GeJ6QvsH0vj+9L232/hlHNA1zGnqq9P2AFdkf8vP6O8alH9FAS7qKrlGKECBBunWQAJQBa6ye01pOAURjtmduD9y/XWs/CCJr3gDmdeK4i4AutdWrEv0St9Q3Bx18D5gF9tdYpwHOAarOPg7Uc6m4gL+J2371sWwQM6uAxJxAfcbtXlG3avoa5wHSlVB5wPnvCvQhwA5kRP69krfUoRI8l4S4OhFUp5Yj4Z8EIkp8ppcYrpezAg8AyrXWBUuqoYDVtxQgtF+BXStmUUpcrpVK01l6gAfB34vk/AIYqpa5USlmD/46K6HsnATVaa5dSagpGFXuozAHuVEqlKaVygZv2su0HQC+l1K+VUnalVJJSamrwsR8weujpSqlewK/39cRa60pgMfASsFNrvTF4/27gE+BvSqlkpZRJKTVIKdW2VSV6EAl3cSDmAy0R/+7TWn8G/B6j970boyIN9XSTgX8AtRitm2rgkeBjVwIFSqkGjPZJhwcgQ7TWjRgHBC/F+MRQBjwE2IOb3Ajcr5RqBO6hc58Gusr9QDGwE+Ng6VsYVXM7wddxKnAOxmvYCpwUfPhljF5+AUYwv9nJ538NOIU9VXvIVYAN2IDx/+EtjAPfoodScrEOIQ4epdQNwKVaa6mSxSEllbsQXUgp1VspdWyw9TEMuBV4t7vHJY48cmabEF3LhjETZSBQhzHX/5luHZE4IklbRggheiBpywghRA/UbW2ZzMxMPWDAgO56eiGEiEkrV66s0lpn7Wu7bgv3AQMGsGLFiu56eiGEiElKqcJ9byVtGSGE6JEk3IUQogeScBdCiB5I5rkL0YN5vV6Ki4txuVzdPRSxnxwOB3l5eVit1gP6fgl3IXqw4uJikpKSGDBgAEq1XRhTHK601lRXV1NcXMzAgQMPaB/SlhGiB3O5XGRkZEiwxxilFBkZGT/qE5eEuxA9nAR7bPqx/99iLtyXF9Twt0824/UHunsoQghx2Iq5cF9VWMuTn2/D45NwFyIWJCbu7WqF4mCJuXC3mI0h+/yy4JkQQnQk5sLdZjb6UB5pywgRswoLC5kxYwZjx45lxowZ7Nq1C4C5c+cyevRoxo0bxwknnADA+vXrmTJlCuPHj2fs2LFs3bq1O4ceM2JuKmS4cg9IuAuxP/7w/no2lDZ06T5H9knm3nP2/zrbN910E1dddRU//elPefHFF7n55pt57733uP/++1mwYAG5ubnU1dUB8Nxzz/GrX/2Kyy+/HI/Hg9/fmcvsipir3C0mo3KXtowQsWvp0qVcdplx3fIrr7ySr776CoBjjz2Wq6++mn/84x/hED/66KN58MEHeeihhygsLCQuLq7bxh1LYq5ytwYrd5ktI8T+OZAK+1AJTft77rnnWLZsGR9++CHjx4/nhx9+4LLLLmPq1Kl8+OGHnHbaabzwwgucfPLJ3Tziw1/sVe7BnrsvIJW7ELHqmGOO4Y033gDg1Vdf5bjjjgNg+/btTJ06lfvvv5/MzEyKiorYsWMH+fn53HzzzZx77rmsWbOmO4ceM2KucreYpHIXIpY0NzeTl5cXvn3LLbfwxBNPcM011/Dwww+TlZXFSy+9BMDtt9/O1q1b0VozY8YMxo0bx1/+8hdeeeUVrFYrvXr14p577umulxJTYi7crWbpuQsRSwIdTH74/PPP2933zjvvtLvvzjvv5M477+zycfV0MdeWkZ67EELsW8yFe6jn7pXKXQghOhRz4W6Vee5CCLFPMRfuMs9dCCH2bZ/hrpR6USlVoZRa18HjSin1hFJqm1JqjVJqYtcPcw/puQshxL51pnL/F3D6Xh4/AxgS/Hc98OyPH1bHZJ67EELs2z7DXWv9JVCzl01mAf/Rhm+BVKVU764aYFtSuQsRO6ZPn86CBQta3ff4449z44037vX7QssEl5aWctFFF3W47xUrVux1P48//jjNzc3h22eeeWZ4zZof47777uORRx750fs5mLqi554LFEXcLg7e145S6nql1Aql1IrKysoDejJr+CQmqdyFONzNnj07fCZqyBtvvMHs2bM79f19+vThrbfeOuDnbxvu8+fPJzU19YD3F0u6ItyjXQsqavJqrZ/XWk/WWk/Oyso6oCcLt2WkchfisHfRRRfxwQcf4Ha7ASgoKKC0tJTjjjuOpqYmZsyYwcSJExkzZgz//e9/231/QUEBo0ePBqClpYVLL72UsWPHcskll9DS0hLe7oYbbmDy5MmMGjWKe++9F4AnnniC0tJSTjrpJE466SQABgwYQFVVFQCPPvooo0ePZvTo0Tz++OPh5xsxYgTXXXcdo0aNYubMma2eZ1+i7dPpdHLWWWcxbtw4Ro8ezZtvvgnAHXfcwciRIxk7diy33Xbbfv1cO6MrzlAtBvpG3M4DSrtgv1GF57lLz12I/fPRHVC2tmv32WsMnPGXDh/OyMhgypQpfPzxx8yaNYs33niDSy65BKUUDoeDd999l+TkZKqqqpg2bRrnnntuh9cOffbZZ4mPj2fNmjWsWbOGiRP3zN3405/+RHp6On6/nxkzZrBmzRpuvvlmHn30URYtWkRmZmarfa1cuZKXXnqJZcuWobVm6tSpnHjiiaSlpbF161Zef/11/vGPf3DxxRfz9ttvc8UVV+zzR9HRPnfs2EGfPn348MMPAaivr6empoZ3332XTZs2oZTqklZRW11Ruc8DrgrOmpkG1Gutd3fBfqMKtWWkchciNkS2ZiJbMlpr7rrrLsaOHcspp5xCSUkJ5eXlHe7nyy+/DIfs2LFjGTt2bPixOXPmMHHiRCZMmMD69evZsGHDXsf01Vdfcf7555OQkEBiYiIXXHABS5YsAWDgwIGMHz8egEmTJlFQUNCp19nRPseMGcPChQv57W9/y5IlS0hJSSE5ORmHw8G1117LO++8Q3x8fKeeY3/ss3JXSr0OTAcylVLFwL2AFUBr/RwwHzgT2AY0Az/r8lFGsMjaMkIcmL1U2AfTeeedxy233MKqVatoaWkJV9yvvvoqlZWVrFy5EqvVyoABA3C5XHvdV7SqfufOnTzyyCMsX76ctLQ0rr766n3uR+uO88Nut4e/NpvNnW7LdLTPoUOHsnLlSubPn8+dd97JzJkzueeee/juu+/47LPPeOONN3jqqaeirrXzY3RmtsxsrXVvrbVVa52ntf6n1vq5YLATnCXz/7TWg7TWY7TWez98/SOFZsvIZfaEiA2JiYlMnz6da665ptWB1Pr6erKzs7FarSxatIjCwsK97ueEE07g1VdfBWDdunXhpX8bGhpISEggJSWF8vJyPvroo/D3JCUl0djYGHVf7733Hs3NzTidTt59912OP/74H/U6O9pnaWkp8fHxXHHFFdx2222sWrWKpqYm6uvrOfPMM3n88cf54YcfftRzRxODq0LKBbKFiDWzZ8/mggsuaDVz5vLLL+ecc85h8uTJjB8/nuHDh+91HzfccAM/+9nPGDt2LOPHj2fKlCkAjBs3jgkTJjBq1Cjy8/M59thjw99z/fXXc8YZZ9C7d28WLVoUvn/ixIlcffXV4X1ce+21TJgwodMtGIA//vGP4YOmAMXFxVH3uWDBAm6//XZMJhNWq5Vnn32WxsZGZs2ahcvlQmvNY4891unn7Sy1t48nB9PkyZP1vuaodmTgnR9y00mDuXXmsC4elRA9y8aNGxkxYkR3D0McoGj//5RSK7XWk/f1vTG3tgwYB1VlnrsQQnQsJsPdYlYyW0YIIfYiNsPdpGRtGSE6qbtar+LH+bH/32Iv3JtrGGEuxuPzd/dIhDjsORwOqqurJeBjjNaa6upqHA7HAe8j5mbLsOo/vOm/l7t9n3T3SIQ47OXl5VFcXMyBruUkuo/D4Wh1YfH9FXvhbo0DwOTt/HoPQhyprFYrAwcO7O5hiG4Qe22ZYLgr/97PQBNCiCNZDIa7sQaDySeVuxBCdCT2wt1iHGBQPqnchRCiI7EX7sG2jNkvlbsQQnQkBsPdaMtIuAshRMdiMNyDs2X87m4eiBBCHL5iNtwtMltGCCE6FLPhbg1IuAshREdiMNyNnrtU7kII0bEYDPdgWyYgPXchhOhI7IW7RdoyQgixL7EX7iYTXmXDKpW7EEJ0KPbCHfCa7Ni0VO5CCNGRmAx3n7Jj057uHoYQQhy2YjLcvWaHVO5CCLEXMRnuPpMDm5aeuxBCdCQ2w93swCHhLoQQHYrJcPeb7NjwyHUhhRCiA7EZ7pY44nDjD0i4CyFENJ0Kd6XU6UqpzUqpbUqpO6I83k8ptUgp9b1Sao1S6syuH+oefrODODz4JNyFECKqfYa7UsoMPA2cAYwEZiulRrbZ7HfAHK31BOBS4JmuHmikgDkOh/Lg9QcO5tMIIUTM6kzlPgXYprXeobX2AG8As9pso4Hk4NcpQGnXDbG9gMWBAw8+v1TuQggRTWfCPRcoirhdHLwv0n3AFUqpYmA+8MtoO1JKXa+UWqGUWlFZWXkAwzUEgj13qdyFECK6zoS7inJf25J5NvAvrXUecCbwslKq3b611s9rrSdrrSdnZWXt/2hD+7EYPXcJdyGEiK4z4V4M9I24nUf7tsvPgTkAWuulgAPI7IoBRqMt8ZiUxueR66gKIUQ0nQn35cAQpdRApZQN44DpvDbb7AJmACilRmCE+4H3XfZBWxwA+N0S7kIIEc0+w11r7QNuAhYAGzFmxaxXSt2vlDo3uNmtwHVKqdXA68DV+mCeYRS8YEfA4zxoTyGEELHM0pmNtNbzMQ6URt53T8TXG4Bju3ZoexEOd6nchRAimpg8Q1UFw93vae7mkQghxOEpRsPduEi2VO5CCBFdTIY7NiPctfTchRAiqpgMd5PNaMtor1TuQggRTWyGe7Atg4S7EEJEFZPhruzByl167kIIEVVMhrvZnmB84ZXZMkIIEU1Mh7vySeUuhBDRxGa4B+e543N170CEEOIwFZPhbrXZ8WozJjmgKoQQUcVkuFvMihZs0pYRQogOxGS4W00mXNgx+SXchRAimpgMd4tZ4dJWTNJzF0KIqGIy3K1mEy3YMUvlLoQQUcVouCuacWDxyTx3IYSIJibDXSlFHYnYvXXdPRQhhDgsxWS4A9SRTJy3vruHIYQQh6WYDfd6lUycTyp3IYSIJmbDvcGUjC3gkpUhhRAiitgNd5VsfNFc070DEUKIw1DMhrvTFAr36u4diBBCHIZiNtybzCnGFxLuQgjRTgyHu1TuQgjRkZgNd6c51fhCeu5CCNFOzIa7yxqs3Fsk3IUQoq2YDfes5AQaVKK0ZYQQIoqYDfchOUlUBxIJOKu6eyhCCHHYidlwH5qTSI1OwlVf2d1DEUKIw06nwl0pdbpSarNSaptS6o4OtrlYKbVBKbVeKfVa1w6zvaE5SdToJLyNUrkLIURbln1toJQyA08DpwLFwHKl1Dyt9YaIbYYAdwLHaq1rlVLZB2vAIYOyEtlIIqaW4oP9VEIIEXM6U7lPAbZprXdorT3AG8CsNttcBzytta4F0FpXdO0w24uzmfE50mXZXyGEiKIz4Z4LFEXcLg7eF2koMFQp9bVS6lul1OnRdqSUul4ptUIptaKy8sf3yq2Jmdi0Bzxy0Q4hhIjUmXBXUe7TbW5bgCHAdGA28IJSKrXdN2n9vNZ6stZ6clZW1v6OtZ2EtBwAPI1yUFUIISJ1JtyLgb4Rt/OA0ijb/Fdr7dVa7wQ2Y4T9QZWW2QuA0tKSg/1UQggRUzoT7suBIUqpgUopG3ApMK/NNu8BJwEopTIx2jQ7unKg0WT36gNAWZmEuxBCRNpnuGutfcBNwAJgIzBHa71eKXW/Uurc4GYLgGql1AZgEXC71vqgnzraq5fR+m+s3n2wn0oIIWLKPqdCAmit5wPz29x3T8TXGrgl+O+Qic/IA8BXJ5W7EEJEitkzVAGwJ9GoErE2ylx3IYSIFNvhDtTZepHgkraMEEJEivlwb4nvQ4avHH+g7exMIYQ4csV8uOvkvvShirL6lu4eihBCHDZiPtytGf1IVC5Ky6Q1I4QQITEf7onZ+QDUlW7v5pEIIcThI+bDPa3PIACaKwu6dyBCCHEYiflwt2b0ByBQu6ubRyKEEIePmA934jNwY5e57kIIESH2w10p6mw5MtddCCEixH64A66EXDJ85dz46ko2lDZ093CEEKLb9Yhw79N/KINstSzeXMkjn2zu7uEIIUS369TCYYc7a0Z/rL46juvnoLzJ3d3DEUKIbtcjKncyhwIwzLybmmZPNw9GCCG6X88I96wRAAxSxdQ6vd08GCGE6H49I9zTBoDZRl/fLprcPjy+QHePSAghulXPCHezBTKGkOMuAKBOWjNCiCNczwh3gKxhpDXvBJC+uxDiiNeDwn048c5iHLipcbYO90aXl3Oe/IqNu2UOvBDiyNCDwn0YCs0gtZu65tYHVQurm1lbUs/a4vpuGpwQQhxaPSjchwMwWBW3q9wbXEbYN7l9h3xYQgjRHXpOuGcMQpssDDGVUNuuLWOEulPCXQhxhOg54W62orKGc775G6xVG1s9FAr3Jo+EuxDiyNBzwh3g7MexKx/XbLoWytaG724MtmWkchdCHCl6Vrj3PYrfpD2KTbth++fhu0OVe7Pb310jE0KIQ6pnhTvgT8qjTqVA9bbwfY1yQFUIcYTpceGenmBjl+oN1TvC94UPqErPXQhxhOhUuCulTldKbVZKbVNK3bGX7S5SSmml1OSuG+L+SY23st3fq03lHjygKm0ZIcQRYp/hrpQyA08DZwAjgdlKqZFRtksCbgaWdfUg90d6vI0tvl7QVAbuRmDPPHc5oCqEOFJ0pnKfAmzTWu/QWnuAN4BZUbZ7APgr4OrC8e23tAQbO3Uv40b1dkDmuQshjjydCfdcoCjidnHwvjCl1ASgr9b6gy4c2wFJi48Md6M1I1MhhRBHms6Eu4pynw4/qJQJeAy4dZ87Uup6pdQKpdSKysrKzo9yP6QlWCnoqHL3+NFad/StQgjRY3Qm3IuBvhG384DSiNtJwGhgsVKqAJgGzIt2UFVr/bzWerLWenJWVtaBj3ov0hNsuLHRHNc7onI3wt0f0LjlQh5CiCNAZ8J9OTBEKTVQKWUDLgXmhR7UWtdrrTO11gO01gOAb4FztdYrDsqI96FPahwA1Y5+UL0Nrz9Ai9dPZqIdkLnuQogjwz7DXWvtA24CFgAbgTla6/VKqfuVUuce7AHur2SHld4pDgrpDTXbaWox+u29UxyA9N2FEEcGS2c20lrPB+a3ue+eDrad/uOH9eMMzk5kbU0vjnPV01xZAECvFAdrS+pbVe5VTW4yEmwoFe2wghBCxK4ed4YqwJDsJBY29APAX7Qc2FO5N3uME5lK61qY+uBnfL2tunsGKYQQB1HPDPecRFZ78wiYHVh2rwSMyh329NxL6lrwBzQ7q5q6bZxCCHGw9MhwH5qTiA8LDWmjiK/4HoBeya177qELetQ4vdF30gn+gMbllSUNhBCHnx4Z7oOzkgAoiBtJUu16bHjDlXso3OuCB1prmz3Rd9KG0+1jW0XrKv+lr3cy429fdNWwhRCiy/TIcE+Jt5KdZOcHPQRzwMMIVUjvFGOKZGjxsLrmUOXeuXD/51c7Oe/pr1udBLVhdwMldS20eKR6F0IcXnpkuAMMzUlisbM/ABNM29q1Zeqa969yL2tw0eT2hQ/IAlQ0uPdrH0IIcaj02HAfnJ3Id9UO6q3ZHG3ZRJzNjM1iateW6Wzl3hDcPrTCJEBFo7FGmoS7EOJw02PDfVp+Os0ePwsDk5iuvofmGhLtlvAFO0JtmdrOhntwCYOGlj3z5MuDlXvoU4AQQhwuemy4nzw8h8xEGy80n4AdL6yZQ4LdjDPccw9W7p2suttW7i6vn/r9PCgrhBCHSo8Nd5vFxIWT8tio+7PFMhRW/ZsEqzk8z722ORTSgVYHREvqWqKuHBkK9VDIh/rtkfsSQojDRY8Nd4BLjzLOUl2SdCZUbODh5t9zXsXToDX1zR5MwVUHQtX7muI6jnvocxasL2+3r1A7JhTy5Y17rklS18nWjhBCHCo9OtwHZibwk0l5BEZdBCPPI416zmp6B0pWUdvsJS8tHtjTd39zeRFaw6cbooR7uHI3Qr68YU+4S+UuhDjc9OhwB3j4J+O47pQxcPG/ebTvE3iw4vvhDVq8fvKzEgBjxozL6+f91cYy9V9sqSQQ2NOacXn9eILrwIf67KGDqUl2S/jgrBBCHC56fLhHMselssR0FKb1b2PBx8BMI9xrmz0s3FhOg8vHeeP7UNXkZmNZQ/j7Iqc/7um5u7BZTPTPjJcDqkKIw84RFe4JdgvvBY7D1FLNcaa15GclAkbl/vbKYvqkOPjtGcMB+HJLVfj7Iqc/hnvuDS5yku2kxdukLSOEOOwcUeGeaLfwiXs0XlsqV5oXMiAjHqWMFss326s5bXQveqfEMbxXEl9sqQh/X+vKPdRzd5OT5AiGu1TuQojDyxEV7rlpcbi1hZV5VzHD/D39Kz4nNc7KF1sqcfsCTB2YAcBxgzNZWVgb7ruHWjEWk2o1WyYn2UFavLXTJ0IJIcShckSF+/i+qQA80TyTjYF+5H5zD/lxzWzcbfTXjxqQBhjXYfX69Z4ZMsGzU/ukxoXvq2xwk5VkJzXeRoPLh88vF94WQhw+jqhwH5qTRLzNzHe7GrnDey2mlmpeaf4ffml+h6FZcWQEL6KdnmAD9qw7E6rc89LiaGjx4XT7aHT7wpU7GLNoimqao54AJYQQh9oRFe5mk2JcXiq+gGajaSjc8DUb4iZzq/UtHlePgscJQFow3EO99FC1npdmVO4VjcY0yJxke3jbJVurOP6vi1i6XS7bJ4TofkdUuANM6Ge0ZlLjraisYczJf5B7vT9lRMPX8OQk+PIR0m3GcgS1Ti+4m5i64UH6mBvISrLT0OKlsNp4E8hNjSM13gj3d78vAWB9aUOUZxVCiEPriAv3UN89NdhOSUuw8W//aVRfOBeyR8DnD5C/9E5AG8sSrJ3DpIq3Oc++nJQ4KwEN60rqAcjPSiQ9GO5fbzOmTu6Qa7IKIQ4Dlu4ewKE2Ply5G6F80aQ8cpLtZI4ZCGNOgS8fJuHzP3KtOY5a5wjY+hoA40w7qHUYbwg/FNWR5LCQmWgLX0PVF5xZs6PSeahfkhBCtHPEhXt2koP+GfFkJxkHTwdnJzI4O3HPBsffht69hjs3vMZnO3KgeDl+TIzQ21kXtyfc8zMTUEqFe+5gXIR7Z5WEuxCi+x1xbRmAF68+irvPGhH9QaVQ5z3LTlNfZhY+CsrMAscZ5PmLSDMbB1Krmjzhs1sTbGasZoXFpLhoUh4Vje7wssIdCa1TI4QQB8sRGe6DshLDF8yOyp7IHxN/T5MpCYadwRImYkKT7dwU3iQ/uC6NUorUeBvj+6YyOjcZgIK9VO/bKhoZde/HrC2u75oXI4QQURyR4d4ZnuR+3JTxT7jgeVZ4BwCQVrc+/Hiocge49dSh/O+pQxmYady3vbLjg6rf7qjB69esLKw5OAMXMcvnD1DfzesUaa35dEN5q1VRRWyScO9AWoKNXS472hpPoSuBelsvEqrXhB8PLRcMcOmUfhw7OJP+wbVq9tZ3X19qVOxbK2RWjWjt30sLOflvi7s1WFcU1nLdf1bw7U45XyPWdSrclVKnK6U2K6W2KaXuiPL4LUqpDUqpNUqpz5RS/bt+qIdWeryNWqcHty+Axx+gKnkUtpJlTFUbMatAeLngSA6rmT4pcXsN93Ulxjz4nhLuWms5K7eL7KhsotrpodG192M2B1NonaTKRvc+thSHu32Gu1LKDDwNnAGMBGapsx4dAAAgAElEQVQrpUa22ex7YLLWeizwFvDXrh7ooZYWb6WuxRs+S3VXv1mo5hretD/Ay3GP4TBHbLxtIVRuAYyKvqNw9/oDbC5rNL6lh4T7Ax9s5KoXv+vuYfQIoeUuunOV0dBkgBpZDC/mdaZynwJs01rv0Fp7gDeAWZEbaK0Xaa2bgze/BfK6dpiHXlqCDa1hV7Xxshr6nQK/2cHT5is4JrASFt5nbLjyX/DKhfDWNaA1+ZkJ7Kx0tqpmmz0+imqa2VrehMcfYFzfVGqcHqqbOl8dnfvUVzy7eHu7+wMBzeLNFd1WPW8qawif1CV+nFCg1rV0X989fAF5CfeY15lwzwWKIm4XB+/ryM+Bj6I9oJS6Xim1Qim1orKysvOj7AahxcO+Ca4Vk5+ZCPZEUk79DSVDLodvnoC/DYf3fw0p/aB8LexYzMDMBBrdPqqa9vxx/Hn+JmY+9iUfry8D4PzxfYDOt2b8Ac26kvqoB2G/2lbF1S8tZ3lB7Y96vQeqxumhttkr0zu7wOFQuYdaQtUS7jGvM+GuotwXtUxUSl0BTAYejva41vp5rfVkrfXkrKyszo+yG6QFz2D9ZEM5CTYzI3onAXDFtP7kXvp/cMZfIX86HHUt/M8SSMiGb55kYHAWzY7gjBmvP8AHa0pp8fp56vOtJNjMnDqqFwBbyxs7NZa6Zg8BDbtqmts9Vhi8r6C6e06eCgVR5X58ChHRhSv3bgx3Z6hylwvQxLzOhHsx0Dfidh5Q2nYjpdQpwN3AuVrrmP9LD1XuG3c3MLF/GhZzxI/KbIWpv4Dzn4OzHoG4VOP29s8Y5t8K7Jkxs3R7NbXNXo4dnEFAw8g+yfRJcZBot3S6cg9VUbuiLClcUtvS6r+HktY6HEjlDa5D/vw9SSCgw4Fa6+z+toz03GNfZ8J9OTBEKTVQKWUDLgXmRW6glJoA/B0j2Cui7CPmhBYWA5jcP33f33DUzyGpDzmf3sRQSxnjl/4SvvsHH67ZTbo9wPOzenN0fganjeqFUorB2YlsLTfCvbLRzZX/XEZZffSArApWxS5voF2FXFoXDPe6Qx/uTW4fXr/xZlPRsPf38y3ljfxQVHcohhWT6lq8hGZAdmfl3uQK9dzlusCxbp/hrrX2ATcBC4CNwByt9Xql1P1KqXODmz0MJAJzlVI/KKXmdbC7mJEesWbMUQPT9v0NcWlw4Quo2p18ZLmN4bWL0Z/ew/J1G3k56WkSXjie168ew7XH5wMwJDuRrRVGW2bpjmqWbK1iydY9xyGqmtxc958VVDW5qY7o3xe1ac2Ew72LKvf1pfWc+PAiimvbt4DaigyAysaOK/eqJjeX/eNb7nh7TYfbhNS3eI/IqrHGuefNsTsvuN7olp57T9Gpee5a6/la66Fa60Fa6z8F77tHaz0v+PUpWuscrfX44L9z977Hw1+c1YzdYsJiUuFlgvdpwLFw2oMU2odxT9xdaJ+HZwIPMKppKbjrYeP74U2H9UqiqslDVZObbcHee2SbZsnWSj7dUM7ynTWtZtW07buXdHHlvnBDBYXVzcxb3a7z1k5NRIVZ0cG8aK01d7y9lqomT4fbRLrr3bXc8MrKzg+4h6iJeKPszn53ZM89Vs5fqGhwcc9/14VXaC2qaQ5/Hcnl9fPphvJDPbxuI2eodkApRXqCjVG5KcTb9mPxzGk3MGf8v3i9YQzfpZ/NcFMRgb7TIG0A/PBaeLMRvY11aDaXNbIl2J7ZEnGAdVNwPnxJXQs1Tg9KgVKwq3pPiHv9AcobXJhNitK6FvwdnNm4q7qZnVXOTv2xrtxlzLr5eF1Z+D6X18/r3+1q9/2R1WZHbZkvt1axcGM5ualx1DZ79nmt2V3VzWzu5IHmw9mHa3aH1/gPufvdtTyzeFvU7UM/S4fVRP1hMBXSH9Dhawcf7j7fVMF/lhayalctLR4/pz3+Ja98W9huu/lrd3Pdf1YcMSu3SrjvxfUn5HPj9EH7/X35mQl4/ZpbK85kSdKZmM5/DsbNhp1fQn0xAMN7GbNvNu5uCLdnQj14IHyyU2mdiyqnh4wEG72SHa0q97J6FwENo/ok4wtoKjpojZz3zNec9Mhijv7z53v9xQ4ENN8X1hJvM7OmuD7cAvpkQzl3vrOWNW0WOwtVm0kOC+UdPHdo1tBPJueh9b5bDlVNbuqavTS6Yrvn+8gnm3nui9bnJSzcWM4Xm6NPAQ61QfIzE6NW7ne/u5aXowRWV2ty+VDB+XGxMte9LHgwf0tZI5vLG2n2+Nkd5fhVebAAOVIO/ku478XPjh3IacFpi/sjtO5MiTeR8ukPQ/pAGHcpoOG9G2HVf8hwKLKS7Kwtqaegupk4q5mSupZw5bQn3FuobnKTkWCnb3o8u2r2hHOo337UgHRseCnfXdJuLC6vnxqnhxnDs6lv8fL4wi0djntrRRONbh/Xn2AcFwhV7xXBP4a2fzChP/7hvZI6rNwrG92YTYpBwSmi1c6OWzNa6/DxheJumP3TlSob3a1O4fcHdLv7ItUEX3d+VkK7g5lef4C5K4pZvOngz1VodPvolewAYqfvHgrtzeWNbNxtLO8R7dNPqL15pBzTkXA/CELrzpgUnDw827gzbQCccDtUbIB5v4S5VzMu24La+D65uoyTRxjbbS1vpL7ZGw7SkroWqhvd/Nn9Ry7h01aVe2m9EYBTBqTxtPX/GDLvPMCo6H/20nfUNXvCVeCMETn89JgBzFtd2uH8+pWFRkvmvPG5jM5NDp90FQqkthVPTbMHq9kI7o766VVNbjISbGQFL44SeXC4rUa3D0+wbdP2wPHB0OLxs7yghq+2Vu174/3cb1ObE9mqm9wEdMfHJqqdHhLtFrKTHO1my+yscuLxBw5J2DrdPvqmxwMHXrkvWF/Go59s7sph7VXo93JT2Z5wb4gW7sHXEytvWj+WhPtBkJ5gI9lhYfKA9Fazbjj5d3DbVuMEqM0f8uzui3lc/Y2/Wx/l7FFZZFBP5Zbv2FRm/IL2SXFQWtdCUuM2JrqWcVLd25Q3uMMHi0IzZI7xLeNU8yoSmovAWc2XWypZtLmSNcX14SolLd7K9SfkE2818+s3f+AvH20KX+g7ZGVhLRkJNvpnxDOhb1r4TaCig3CvdXpIi7eRneyg2umO2k+vavKQlWQnM9EevN1x5V4VEXz7U7lrrTsMoo6OMzS4vEx9cCE/eW4pV/xzWadmB3VWVbhCdIePg4Sqyya3j2ZP+152jdNDeoKNtHgrTo+/1Rm/ocBq2655dVkhizd3XTXvD2iaPX76BcO95gAP7L66bBdPL94e9aDmwRCaQrwlMtyjtPVC/1/2Z9mPWCbhfhAopfjrRWP5/Vlt11fDOCo69Rdw9mNUZR3NE77zGGEqYkbFv3jXfi8zvp5NxdblAJw0PJtqp4fxziUApLcUMFgVh6vakjoXufEBkj6/GyfGR2kq1rMt2Oeudhr9azDWyklPsPH7s0dS4/Tw9y+388+vdoaH5fEF+K6gmon901BK0TvVQYPLh9PtC1fuZW3CvToYSNlJdrSmVaUaUtXkJjPRTmai8Sa3t8o9sqIq2o+wfX/Nbo7+y2dRA/7WuauZ+dgX4T/6kI2lDTS4fFw5zVjA9LudXbe+fuhchIDeE8iRb4zRWli1zcbPMjVYDERW7xuCY49sJ2it+ctHm7j9rTW0eLomREMtwf6hcD/ACndzWQP+gGZ9acO+N+4CFY0u7BYTTo+fVbuMcynqW9q/gYZ+9/b1ugIBfUg+OR5sEu4HyemjezMmL6XjDSZfQ+2sl3nU9xNWmcZg+/oRMlUjTpXEpO/v5nzHSq6veohcKjmZ5dTG9UejOMP0XXi9m9K6Fi6M/x4ainkm8ZfGfsvXhyvu6qY9bZnQcgqXTunH0jtnMCY3JXxwtb7Fy09f/I6imhbOHWese9M7xXiz2F3v6rAtE67cgy2XaAd0qxqNcE92WLGY1F4r91BFZTUrimo6X7l/v6sWlzcQXooh0vKCGraUN3He01+zomBPgIdmJv3ixHySHBaWF3RduEd+Agm93sgDztFaM9VNxkHztODJc5EHnjfuNsba6PKFK/qqJmNp4MpGd9SZIQciFO5ZSXbsFtMBtWVqnJ7wp5TVh+CkNY8vQFWTh6n5GYDx6cNsUh20ZYKV+z5e14drd3PSI4u75cTAriTh3o0GZSdgMZl4t/evoc8EXur3IHf5rqWPaxuP8Tf6l7zPf2x/YYypgIL+F6L6TuF8x0rmrDDWcSupa+F4VkFCNjuyT6NOJUP5nsq9qskT/gNNS7C2eu7+GQnh9Wj+8tEmVhTW8Ngl4zgnHO7GZQjL6l3hSrTtGbQ1wWozJ3gArm1FqrWmqslDZpINk8mYWlrd5KHJ7WPOiqJ2LZPKYGU1onfyfrVJQssnl7b5Y/T5A5TWubj0qL7YLKbwzw2Mg29JDgu5qXFM7p92UCp3gKrGUOUeMW00ypvgnraM8SYc2YLZtLsBs8mYwhKq6ENvzGnxVp77Ynt4fvqPEdpHosNCeoJtrxWuy+vn5aUF7RaMC7UUAdYUH/xwD/0sTxiSGb5vdG5Ku3CPPFi/r7bM1vJGfAHNmhg/o1rCvRvZLWZuOnkw0487Hq5fzGlnX0zDgNP4ve8aPhx8L5Vn/4uByjio6RxwGoycRb5/J+dVPMM78z+msLKeMS0rYMhMhvZOYYM/D8/udeF+dXWTO1wBpsbZWj33wIx4Smpb8PgC/FBUx7GDMzl/wp6VmvsEw31XTXP4j7xteNeG2jLJocq99eMNLcYB0qxgvz0j0U610827q4r5zVtr+L7NH0/oj25sXgrFtS2dPommo3DfXe/CH9BM6JfKCUOyWLy5MrzPLWVNDMtJQinFUQPT2V7pDFfZgYD+UVMxQ4EOeyr3igYXDqsp+HX7N8Eap4f0RFt42YtQO626yU1Fo5txwU+BoT54aIrpnWeMoNrpYUmUg8Jun3+/LroRWhEy0W4hLd7W6g2m7UHeeT+U8vv/rueTDWWt7t8U/JQxoV8qa4rr+W5nDZMe+PSgzS0PvWkOykokNzUOpYwJBo1uX6vzPhpafPiCt/fVlikO/h5t2H1o2koHi4R7N/v1KUOZMSIHgMHZifznmincec/DnH7Z/5Iyfha/813DK74ZxPUeBuNm480/lZ+aF3DGsiu5NmUlDn8jDDmV44ZksinQD1WxkXjdwuXmhbQ0VFPj9JBkt2CztP5f3T8jgYA2VpPcXtHEsOC8+5CcFCOQ1wbXau+XHk+j2xeu7vwBTV2Ll7QEG5mJdkwKyupbh2uogg3NlMlMtFHV5GFDMABWtlmmuLrJQ1q8lQEZCTS5feGAi6rwG9jxBU1uX6uZRZFCfdO+afFMH5ZFRaObDbsb0FqzubyRocHXPHWgsXZQqG3z1qpipj742QEfZK1qcmMLLjQXbss0uBicnYjVrFq9CW4qa+Cb7dV4/AHS422kxrfuuYdaMscONirT0JTJHVVObBYT04cbq6vurm/fQnj0ky2c9cSSTo871JZJClbuofbFql21THjg01br9n+60TjTs+1Mo01lDWQk2DhlRA47qpzc8991VDs9zF+7u9Pj2B+hVmFOsoPRuckMykqkV7AwaYo4Casq2JJJsJn3Ge6hiQobDtExg4NFwv0wFG+zYDYpbBYTnyWcye98PzcOSManY73qLf4y9HX8mPmN52lQZhh0EuP7plJgHoA14OIJ61P8yfoi95VcR2blMlLbtGQABgSna36+qQKPP8CIXsmtHrdbzGQm2lhbYlTXY3KNyrGsthHe+3+4P7mfDF1PerwVq9lEXlo8O9pUZ6FgC82UyUiwUe10hz+6r2izPn1Vk5uMRHt4Kl6HM2Z08HyB925ke8S0zraVe+igbN/0eE4cZoTg4s2VVDS6qW/xMiwnKfjaUrFbTHy303iz2VDaQLPHz9OLWp+EFG2WSzSVjW76ZcRjM5vCb3DlDW5ykhxkJdrD5w0A3PjqKi5/YRlAeLYM7Om5h9YbOmZQMNzDlbuTgRkJZCXasZlN7Q52A3y6oZyKRne7lk1HZzI3hSt3K+kJtnBLb9GmCrQmfBKby+sPj2vJ1qpWn7A2lzUyvHcS4/KMJTs2lTViM5tYdJDm6Idahb1SHDxw3mhe/OlRpMQZP8PIue6hlszgnCRqnJ69Xqc29Ht3qA4IHywS7oe53FSjCskIBiTAby85BX3qH1ABL/Q7GhwpWM0m7LmjAZhh/p7VCcfRrK3cWHQLv9avgK91tTIgwwjQ0IlKbSt3MP5gQh+zRwfD3fb1o/DDK8R9+xhf2H9NnjbWoMnPSmBHZetwD7UEMiPaMlWNnvAJWisLa1sFQ3WTh8xEG3lpxmteV1of/SIg5eugdic0FFO2w1iMrG96HKV1rQOuqKYFs0nRO8VBdpKDMbkpLNpUEX7+ocFwt1lMjM1LCfeIQxX/3BVFFNcayyzfPnc10x78rFMzSKqa3GQFZwiFWjQVjS6ykx1kJTvClbs/OCtj6sB0zhjdi2MHZxJnNWOzmChvcPHnjzby9y93cPqoXgzONk4CCwXujqomBmYmoJQiJ8Xe7nhIUU1z+M029CZb3+zlyn8uY+ZjX0RteUX23HunOiitc9Ho8rI0eAB/e7AV9PW2KlzeADNH5lBS10JBdTNzVxTxzfYqNpc3MrxXcngyQf+MeK47YSCrdtX+qDNetdbcOmc1X25pfYZveaMLm9lEWryV7CQH/TLiSXYYy4VETocMtfyG5SQS0B1f7crnD1DW4CLJbqGswXXA0ya/2V7V6gB+d5BwP8z1SY3DbjGRYNtz0Va7xUzSMdfBlOvhmF+G7+8/fBIBrahWaXw69F5m+f7MJ47TuLDlbXjhZKjYCM014HUF5+KbqC/eiMVE+AzSSL1T4sJ9yjG5KYxRO8hd9zSMvYS1sxZgJsDonf8CjNPmd1Y5W1VEVe3aMnZavH6aPX7G5qVQ1eShsHpP66PKaVTu/dLjsZgUd76zlsl//LT9Ergb3yd0DRnzjs+xmhVH52e0q9x31TTTJ9URXov/pGFZrNpVy5vBA6tDc/a85kFZieG+cHFtC2PzUjApxf97dRW3zFnN3JXFNLh8fLyuDI8vwP8t3NqqAgejfeHzB4zpn0l2MpPsVDW58fqNGR05yXayk+zhg4BV5cW8aPoTdyXM49krJtEnNQ6lFGnxVv71TQF//2IHl03tx1OXTQj34qudxvo8u6qbw2dC906OC4f7ffPW85+lBa168JWNbhpdXs5/5muWbK1ie6Uz6sVVQitCJtoszBzZC48/wLzVpawOvumFwn3hxnIS7RZuO20YAL97by23v7WGO16Yx2vqd4xPaSYlzsqtpw7loQvHMnNkLwIavthy4Fdfq3Z6eHtVcbslGMrrXWQn21FqzzWFolXuVcE3ltAbenWTm/8sLWg35bG80Tg3YXrw5MMD6bvPXVHE5S8s45evf7/XTwgHm4T7Ye7ccX246uj+rX55ATCZ4MyHYdjp4bumDe/HI76L+Vfvu0lMzaDWa+Nu77W8kPcgNJTCM9PgrwPhsZGobZ/xlO0ZFtlv5bHEl7EpvxH8u76FDfOgpTY8HTIZJ5MKX2CO7X6arRlwxkMUW/ox138i2Tvfg8Yy8rMSaPH62R0ReFVNxtIDqcE/tozEPQd1r5hqzC8PnRULwWmTCTaSHFbevfFYbjppMA0uX7vep974PtUZk3AmDiCn8msGZCTQLz2eaqen1YkzRbXN9E2LD9/+6TEDGJCZwIdrdpOZaCdD1xotHoyziqudHupbvBTVNjOpfxoPnDeKqiYP735fwuwp/RiYmcCHa0t5a2Uxjy3cwtyVxXueq6aZC575hjeWF1HZ6CYz0TgWUdW0Z8mBnGRHMNzdUF9M8uvncLx5HSN3vQ7+Pa2Ts8f2YebIHF69dip/OisfS/UWrGYTKXFWap0eimpb8AV0+EzonBQHZQ3GwePXvtvFAx9s4PXvdoVn2FQ1uVlZWMuOKieXTe0HwLby9heKCbVlEuxmJvZLJTc1jsc+3YLXr8lIsLG9sgmtNZ9trOCEoZkMyTYOYn69rZopA9P5Y/4GJpq2cYzfOE/jlzOGMC0/gzG5KWQm2vksojWjteavH2/i5te/79SB89Cnwm93VLc6Wa68wR1eLiEkOfj7FjljJnSsIvQJ6IeiOu757/p200iLa5rJoo4bTe9gIrDfffevtlZx+1tr6JMSx+56FysKu+fylyDhftibOaoXd0c7GSqKQVkJrB90Lf0mnk5G8GSYaqeHkpzpcMNSmHEPnPYgxGfAqxdygudLFvvHcY7nI3hogBH8L54Gc66ER4Zy4/YbmGP7AyscNxD31Z9ZwgSeH/p3iEtj0+4G/uk/C6V9MP82jq6dx4mm1ZQUbAG/8UdV1WjM3TYFQyZ0IpNV+Tirv49kh4UvtlTS5Dbmbze4fOEWzpi8FK462ngD2FLeaITft89R/+G9qIoNPFU2grl1wxjcvJoRWTZyg62cyIOqRdXNXO2dA1/8FbQmI9HOa9dOo196PNekrzGugfvO9RAIhINyVWEtzR4/fdPiueSofnz125P44vbp/Om80Zw9tjdLt1fzf58Z6/NEfuwOLQvx0brdOD3+8IlbVU3uiIN+9uDyAl787/8vluYKnvOdg9VTC4Vfhff1+7NH8vxVkzl2cCbqvRvh2WOgbF34IGdopkx+8NNW7xQHZfWu8Ownr1+ztqSe6UON4wyVje7wQeefTDJmREW7CliT20uc1YzFbEIpxdlje1PV5MFsUlwwMZfi2hbWlzZQ0ejmhCFZKKWYOSqHrCQ7T86ewAnqBwAyqpa32q/JpJgxPJvPN5aHZyE9+fk2nlm8nXmrS1nciYp+Z5Ux3kaXj3URgVve4ApPxQ0Jh3tkW8bpJjXeGt52wXrjgHDbFUhL6lq43LKQERuf4PSknftduX+0bjeJdgvv//I4HFYT81a3X+/pUNmPtWzF4U4pxb+vmQLQ6gBWerwNknLg+FuNOyZcCYv+xH/rBvKr1X15fkwhMx2bIGMwZA0DexJsfB/ztpVoPHxgO4MLfnoLf32zkcEtRqCsLq7HkTMY1f8SWP06g3iff9uA9x6C9xRkDGa6dwKDLYmw6DuoL2ZiXS1PWas53ryBhGcaec8+gufWHceFa4fwmxG1PGhZRq+WSyAwCAJesko/4zbHPOp2+aDsT7B2LimABwtjTrmSHeuXEVe1gFMsq+mVNJAbzf8l4eN3YOQJtPSezGWuN5hZ8RZUYFTo026gl7uEhadWYP3wIUjqDWvngC2e/Cn3A0brwIGbkaoAAv1QJjP9M4zgP3tsH578fBvlDW7yMxNYWVhLIKAxmVQ4PL/ZXkUyzWQl2fE7q7mu5UXqS4yD1dlJDrKT3RxtWo952ycsHXgzj2+cwC/iPkNtmGdckzdS8UrY8J7x9fzbSIv7HbXNnnD7aFCwLdMr2YHbF2BVcLnmiyfnMWdFMRdOymPR5goqG91ojLWOxuSmkOSwhFcijdTk9pPo2BMJ54zrw9+/3MGY3BTG5qWiNbz+3S4Ajh5knDR095kjuG3mMBL8DVC8ApQJCr4yft4RnzYvn9aPN1cUMXdFMX1S43j00y2cPyGX5QU1PL5wK9OHZrX/dBphR6UTi0nhC2i+3lbF+L6paK0pa3AxfVh2q207OqCakWALFz2hA8JbytqEe20Lx5jWA3Ba/GaeK5/Q4ZiiWVFQy8T+aaQHZwzNX1vGveeMwmo+9HW0hHsPFdkCSU1oPccdRzKc8RC+lcWwejXWsRfB8NZ/IPQ/hh07qrnk+W85pm8GF+ROJCf5W8obXWhtVIanjMiG856FmX9C+1r42aNzOb9fM7PyFRR9x6k73saCH75QkNSLBGsio1UDmxMnM2Xq8fRf9TJ/df/DeL7t4DJbcaz4HFb8DwAKzU0Am98A4NHAbD5JPJdnZ4/mgr79aDlqBPVPPM05W+7EV/YcU6w7cRcmwva3iANuscKuvrPol5EIix80/gE2MN7IrvkElj4FXz3KQGcVGepsKjZ9zYe2Rxn06W5YmgPp+Ua7KmcUQ/sfyxUZDTTYsplxVD/um7eOgp1byE+1UFvTQBLNPGl5kmNM6yjZeSPJhQvIMG+haslmHNxNTrKDitoG7rS8hjshl4/iziUpqR415FTY9AEkZELZOjj3SYhPh4X3QnwmHH8LLLiLWxKfZF1TX7YWnktOsj08bbJXsH0WWj/+N6cP58ppAxidm0zveM3IHf+kf9MPnOmowlIQZ1wFLKIts66kntXFdTS5fSTZ90TCqD7JnDQsi5NH5IT7++99X0KfFEd4/RmL2WQc01j7OaBh/OXw/StQvR0yB4f3NTYvlUn903jx653YPXXclf4NP5v1B95eU80d76xl8eZKTmr7OxhhR5WTgZkJmE2Kb7ZX8f9OGky100Ozxx/+1BaSYDMHz1KNmAoZnImVFvxbcAcP1JfWu2hweUl2GG8IFVXVTDQZa+6P861hd8usDsfUVl2zh83ljZwzrjdgvDl+sGY332yv5sShWTz3xXYU8IsT938Z8QMh4d5DRc6uSY+3Rd1mxohsrjl2INOCp263FTpLNbS8wOCsRN5cUcTWiiZqnB7G5KUa1VlCBgqozTqKudrKrJOmAnDqg/M5emAqD148BcwW/F4/M//wCb+aNIQpxw/GfOz/QtVmKjZ+zfWfuNjgz+Pj0+rI18WAgr5T+cv3JuI2zOXkicN54pvBzL14GgP7GvPS4xKTifvfb+GzB7Bs+Zgbvb9iCceQ5S5ismkzcXg4b8bv6Nc3HXqNAb8HknONf73Hgi3BaFUlZGFecBcr7R9AM5SrVNyn/hl7ybfgrDbeCAq/Qa1/hz8COIFPYJYDeNn4Wf0cxcX2eOJx8V1gOMeufxK/yc7jvgu4ufldXoh7iox15Ryz7AUcpp18P+oRCkr9xsygEefChv/CFw+ByZHWWjsAABRLSURBVAL/OgtS8qBgibHI3FHXQeE3TNv8McdpH+Xb3mF071/AmhqoLWBq0UYesDRQvjmfDMd0MoLnHrDtM94J/JqcskoKLPnYTS3w6sXM7n0rj+8eAyWrYPN8yteXsLosgQ1pZ5JgD/6u+NwoVwMvXTUBzNbw+jVOj5/TRvdqX2Vv/RTi0uGYm41wL1jSKtwBrj5mALe9vow3bA8ywb8VvknjwhPv5JnF23no402cMDQrfJygrR2VTQzOTiQ3NZ5XlhXi8vrDJ69Nc30JT1wIF/wD8iahlGKUvZJjtr0LJ/wV4tKodnoYmpOI1Wwi2WGhweVjYr9UVu2qY2twho8GkiqWGwVJnwn03b0GT0sjLR4/cRETGqJyNeB86xbGqHFMHjANgBODr2f5zhpOHJrFy0sLafb4uO74/HCr8mCScO+hMiKq9bT49vPcAVLjbdxzTsf9/JwU4+Sk7GCf8uxxffj30kIeWWAs5zo2t/XaOflZiXy7w5g25w9oSpoVSalpYDZ+zRxWM+/fdFy46sNkguwRZGePYOr/b+/Mw6Mq7z3++c1kspKZhKyTYQmBJCwBDKCASAqo7DSgyFK3tvpw78XWqre9Wu3iU5+ioLW0ytVKsVetFqpFRctSBWRREBEJyBIIIFuABAMkELK/949zZpgkkzBsmUn6fp7nPDl555znfOd3zvzO+/7e5Ve+i61r9hOePRViLtTEkosO8OSW8WwrSSQ6rKRxysOIWBj/PMLzbJm1krLSCm7tdz2nK7J5N7+IhxNjjOsP+i/fX1IEBs8EZ1/eeu89dhTX8FnoEFYPmQzMvHCcUkaildJCKD2KKjvOcx/tpVNiHFMHd+PD1Z8Se66AT+y5LDjakS2ThcOVEcxdXE6FCuVR2yJkxZeExnRmRu2jpNTcyJFTRfTpEAPdxxtOMWM01NXA36bDmcMw6mnDsVssMO1Nnl26k43rPuL3tv/l7mOzYLF5H9ulMN5aSmzNx0yxrkA2HYWyQlg/l+qQTjweNZtPazIZ6LQyp2oWdxx6hknKAvPrQCzkKAs322r47MynlNrT4Y8PGkNNldlx2TOXiFueZEHkPDJr86k8OxxWJMG5YuPFVFNhtDwyx0B8BrRLMkIzA35gnF9bA5sXMG7/WnpE76FrdQEk94FP/4At+04eHd2dB97awtubDzPt+o6wZwV88jRkjIJhP6emTnGopJy7Op8itWMWr35ax7YjZ9hXfJZ+soeeG56G2kp46w647yOIdjKX50grPgRvF8Gd7/Dt2UrapxmVgvh2YZRW1HDXoM5sOXSa3cfLmPvxXnYWlvJQ3edUiw1bzv9gXTidGyy7KTxz3udosg/yCnl88Xb6uKL5Xd0cXMdXMzf0U1wp93ue97T4KHYfL6W0otrTH7TzWKlnaPG1RDv3Nkq4zUpUqJVzVbWepuilEhZiZd73+nnGLPfvFIsrJoJ/7TyBzSp0d9YfG58WH8W7Xx2lvKqGtXuKqaqp47oO9Z2xr/H0AD8bmcnYLCcpMfWb2O6hayt3FzGqV1KzscsOsRGUV9XwxNgexEaGcvJcpSd0cVFSh7AnLYY3j39DnzgfPzwRiOlobBgDMQsKNvPBsTKm9h3OK2tdxKeEMbJnMvEf7SE6awSOU+eBTygb8CNk/B+g4jSWyDiqXv+KVbuLOHbmPGN7O8EWDiOfunCtmRvAFgntEupJaB8VRp7qxpiqZ1h1VwKupERwuFDWCPr/YhnDZAvPRf0Vlv3MOKH3HbxQfT/rDpzj5LkKYnulwqgPyFu3hPUfv8fYIQNIHXYP/Wd/zqjqlTwZ8hq28gJwjYCs240w0elD8PmfYOf7fIcQ1tZlMazwQygEbBGwbZFxLVd/GPFLw05pw43yitNGC+TwJijaiSW2C93sVhj0HGSOhRcGwMK7GJsxijlxhYQv+zN1Gw9hKSkwWgFrZkPJfkpct/C85S9M+Hojtd84udUynRM7qkg9vJLXQ98BhwsmvQJ/mwovD4W4NFLVYVa1G8+I/R9S/edRPFUdgpzPBZVFfKSV7JD15G6ZiwqL4uAXw7n++BZyqOYmy2YKHb3pnDaMOksoOZZtFJ72cu51dVBdzvmKSn774U6ckTVMK5pLcs1qlspNjGU9bJoHOT8FYFB8BYVH8jm0qxZQgLBu70nt3DVXRly7MM6VlHsWo7ocxvR2evYtFuG716Xw0if7yEyOJiykflM1y3wJ/HXjQZZuP06n9pGM9DOTVYjVQl8ficjTky68DHIyEhp97s2vJ/Siuq7OE5JKjA5v9viGuEfMeA+fbI7+nWNZseMEJ89WcvxMJVkpDqbf0JEpAzoQYrWQGh/FohmDyO4UCyEWsBm2GJZhrHMDeCZs1SO2s8/ruXMDOKKjSek1xNNhGYIxl2BVaT8W3jiVmQMcUHUW2qcRs2w3hWeM1lRKTARYbSRcN5Znl4djj80iujaS0opaSrpP4YbdA5nQ18Uz0wfXv3DWbbBhHv+MvI1FR+MZ8cMBRsepqjNq7FXnoM9UTwuN0U9DTCfIWwjH8sCeAlNeN2r53uGcCXNhzRxk/fPcoRQnVTSF1r50GDfT6PRf9ztYM5vE7W8z0mLjeNYMko+tZn7o87AZ6rCwPmwIOXfPM2z2g+Xw2R9hx3sstt/NW+HTGDF4ICfWvkZ/SwnO/MfhhQW8cfoYYSHlcL4b4ySP8JOrqbFasISEYKmt4kDXeyA0ksqON/HDg8s5u3gYOGKhohTKjkFtFRHAchVFlCUMW00JS6MnM7N4EstSwujxydNQ+BVUlvHUgTXGd30floV2ZK11EJXb0iH7LuOldA3Rzr0NE9culEMl5Z4JMFeDide5eOmTffR2NXbEwzISGNUriWeW7aZOwW9yezUZQ/WX+HbGlPxT5dXkpDfv3JtdYtkP3M69Q3sfDtcH7tpX3uHTnDxbSbIjHBEhxHrhOw/00Z8xLDMRPthpXMvPFwlccO4D0+IaxbyT7eHGKJ4EuzEyCmO9IvcEMriwjLPTEU67sBD2HC/zLMFw16DOnKuqoUdnJ41w9YfJr5IL1O9etECviY2Pj2wPI54wtuboM8XYaqpALNz/0kbOVtTwUf/vGDHp4T+Hgf/BP9Z8wew1xSwfMwVsNbw4/08cOQf5tS46dUknx/0yTMiA3Bch90VWvfklpSfOsiH5Tqaf6cqPh3XhvxM2wY53Ces6ArqOgIzRzH5nA3u2rqN9t0G8cM9gKM6nS4IxOcsyeT6/fOYp7ok7SLo9HBKiwe7kjNh5ed1BBtu/JaeDFYb8hOGJ2Ty4Zh8xvV+ErS/C1++Axca+3g8z60sLfR3nGVG+ghnqHaREUb0rDtug+5u3zxWinXsbJi4qjKhQK+G2i3QGXQKZydH8YlwPn7VoEWH27X3YfmQd56truaN/xyu+nojQw2nneGmFZ82Za0V6UjssYnQc+0Mvp+HcV5nDThtOpmmK1PgoUuMi+ebbct819yZwt0jcC515k+wIJ+/IGc/wSDfezt0d8hIRsjvFsOlACVkuY5hm14R2LJzRoMbeUoSEIhiTzB75ex6LvzpKQdFZctLjGdw1jlWnEqiMMGbuIqHUZI5j0cq9KAXDm7hXjggbpeereXbFblwxEcwckQmhPaH/9+sd18mVwl+29Gb+oB4QEmZ0tJuERcezPHICVc5EZk82yuvqFA+8uoktKovp388BcxmPCOCRWzOME0fPglG/BREiTp9n5RerWHkK1naewIM5HZj113/y64ghXGtra+fehunpjG42IfXlcv/QtCY/i4kMZfHMIZyrqrn4CAM/efq23lTXXvtp3E5HBB/+eCjpSf45d0ekjY7tI1i5y3DuSQ7/w0DDuyfyxoaDnrWD/KGPy8FTE7O4vV+HRp85HRFYLUKnuPovwHivUVPe1xrcNY45y/PZdOAUoVZLo+GEgWBcHyezlu7ip2/nATB/3X5y0uNZnV/MD4akelorvV0O98Riz4zThtjDbRSVGcsl/3J8zyafxUnZLiwiF3IdNyDFEU7hmfOUVlTz9y8Os7OwlPUFJ/ntpKxGtq6HqdXpCPeMzunujOb6dBdljkyKlL3pc68S2rm3YR6+NYOH3bWJFiT5EpycP7gnEbUEPVMu7UeXleJgmbn4mvMSvvdDt2Qwvo/zklpVFot40gI25L6bujCkW3yjfhB3zT3cZqkXnjNWmcznw22FdI6LvOLw2dUgLMTKL8b15LN9J7n3xlTmLM9ndX4x378xtV7Kyt5enZG+RrHAhVmq4TYLk328DN3ERIZy742pTX7udERQUHyWNzYc5NkV+diswqRsF9+7oZNf30lE6O60s+lACZnJdiJCrax/dHizE7auFtq5t2Fa4gH6d6dXit3j3P0Ny4ARNujfuXF45XLp2D7SZ9jKnSjFvSiZm6wUO9HhIZRV1HgmKAUDE7NdTMw2OhoX3DuA3cfL6JVir6c90R5Okj2M4rJKUuN9157dzj23rwvHFfQ5OWPCWbe3mI93naBPBwfvPzDkkn9XPZKj2XSghO7mSLGW+l3qtWU0miugl1mLDLdZPNPegwlHhA2bVTyZtdyEWC0M7GJ09naJ9y8M1dKEWC1kuRw+nWG/TrF0TWjXqKXipkOMEaa6e7Dvlo6/pDgiOFdVy1eHTnNz96TLcsxD0xNItofTw3ntQzHe6Jq7RnMF9DLDOMn28KBsKVksQpf4KJ/9CDd2jePjXSeCqubuL09NzPLMmvXFsMwENjw2wjMB73Jxxlw4/+YeTS+P0By39Ezilp5JV6TjcvCr5i4io0UkX0QKROQxH5+Hicgi8/PPRST1agvVaIKRxGhjGd+GKxMGE4tmDObR0d0blY/slUQPp51BXXwvPxHMxHtl7PKFiFyxY4cLS3Ak2cM8L/LWwkVr7iJiBeYBtwJHgC9EZIlSaqfXYfcBp5RS3URkGjAbmHotBGs0wcbjY3sEZUjGTVMzlDvERrLsJ0NbWE3rwj3CaET3xKBsmTWHP2GZG4ACpdR+ABFZiDGXwdu55wJPmvvvAC+KiCh/09drNK0Ydwegpu2RZA/jwZvTyb0uJdBSLhl/wjIu4LDX/0fMMp/HKKVqgDNAo7aeiMwQkc0isrm4+PJTbmk0Gk1LICI8cmtGk0Mugxl/nLuvtkjDGrk/x6CUekUpNUApNSAhofmp5BqNRqO5fPxx7kcA73nkHTDWhPN5jIiEAA4gsKm/NRqN5t8Yf5z7F0C6iHQRkVBgGrCkwTFLgHvN/cnAKh1v12g0msBx0Q5VpVSNiPwIWAFYgVeVUjtE5DfAZqXUEmAB8IaIFGDU2KddS9EajUajaR6/JjEppZYCSxuU/cprvwK44+pK02g0Gs3lopcf0Gg0mjaIdu4ajUbTBtHOXaPRaNogEqhBLSJSDBy8zNPjgZNXUc61ojXobA0aQeu8mrQGjdA6dAZCY2el1EUnCgXMuV8JIrJZKTUg0DouRmvQ2Ro0gtZ5NWkNGqF16AxmjToso9FoNG0Q7dw1Go2mDdJanfsrgRbgJ61BZ2vQCFrn1aQ1aITWoTNoNbbKmLtGo9Fomqe11tw1Go1G0wzauWs0Gk0bpNU594vlcw0EItJRRFaLyC4R2SEiPzHLnxSRoyKy1dzGBoHWb0Rku6lns1nWXkQ+EpG95t/YAOrL9LLXVhEpFZGHgsGWIvKqiBSJyNdeZT5tJwZ/NJ/TbSLSL8A6nxWR3aaWd0UkxixPFZHzXnZ9OYAam7zHIvJz05b5IjKqJTQ2o3ORl8ZvRGSrWR4QWzaJUqrVbBirUu4D0oBQIA/oGQS6nEA/cz8a2AP0xEg9+NNA62ug9RsgvkHZHOAxc/8xYHagdXrd7+NA52CwJZAD9AO+vpjtgLHAMoxENoOAzwOscyQQYu7P9tKZ6n1cgDX6vMfmbykPCAO6mD7AGiidDT7/HfCrQNqyqa211dw9+VyVUlWAO59rQFFKHVNKbTH3y4BdNE5FGMzkAq+Z+68BEwOoxZubgX1KqcudyXxVUUqtpXESmqZslwu8rgw2AjEi4gyUTqXUv5SRAhNgI0bSnYDRhC2bIhdYqJSqVEodAAowfME1pzmdYmTMngL8rSW0XCqtzbn7k881oIhIKpANfG4W/chsCr8ayHCHFwr4l4h8KSIzzLIkpdQxMF5UQGLA1NVnGvV/OMFmS2jadsH8rP4Qo1XhpouIfCUia0RkaKBEmfi6x8Fqy6HACaXUXq+yoLFla3PufuVqDRQi0g74B/CQUqoUeAnoClwHHMNowgWaIUqpfsAY4AERyQm0IF+IkfXru8DbZlEw2rI5gvJZFZEngBrgTbPoGNBJKZUNPAK8JSL2AMlr6h4HpS2B6dSvfASTLVudc/cnn2tAEBEbhmN/Uym1GEApdUIpVauUqgPm00JNyeZQShWaf4uAdzE0nXCHDMy/RYFT6GEMsEUpdQKC05YmTdku6J5VEbkXGA/cqcwgsRnq+Nbc/xIjnp0RCH3N3ONgtGUIcBuwyF0WTLaE1ufc/cnn2uKYsbcFwC6l1PNe5d4x1knA1w3PbUlEJEpEot37GJ1sX1M/B+69wPuBUViPerWiYLOlF03ZbglwjzlqZhBwxh2+CQQiMhp4FPiuUqrcqzxBRKzmfhqQDuwPkMam7vESYJqIhIlIFwyNm1paXwNuAXYrpY64C4LJlkDrGi1jVjbGYoxG2Qc8EWg9pqabMJqJ24Ct5jYWeAPYbpYvAZwB1pmGMeogD9jhth8QB6wE9pp/2wdYZyTwLeDwKgu4LTFeNseAaoza5H1N2Q4jlDDPfE63AwMCrLMAI27tfj5fNo+93XwW8oAtwIQAamzyHgNPmLbMB8YE0pZm+f8B/9ng2IDYsqlNLz+g0Wg0bZDWFpbRaDQajR9o567RaDRtEO3cNRqNpg2inbtGo9G0QbRz12g0mjaIdu4ajUbTBtHOXaPRaNog/w9KNcVK6O1wdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([(v['loss'], v['loss_valid']) for v in learning_curve]);\n",
    "title('Loss learning curve');\n",
    "legend(['Loss', 'Validation Loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a452ec518>"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([(v['b_grad'][0], v['j_grad'],  v['b_grad'][1]) for v in learning_curve]);\n",
    "title('Gradients of the chain parameters')\n",
    "xlabel('epochs')\n",
    "legend(['b0', 'J', 'b1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([v['j'] for v in learning_curve]);\n",
    "title('value of chain parameter J');\n",
    "xlabel('epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([v['b'] for v in learning_curve]);\n",
    "title('value of chain parameter b');\n",
    "xlabel('epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([v['b'][1] / v['b'][0] for v in learning_curve]);\n",
    "title('internal ratio of chain parameter b');\n",
    "xlabel('epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([v['b'][1] / v['j'] for v in learning_curve]);\n",
    "title('ratio of chain parameter b / j');\n",
    "xlabel('epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "beliefs_pred = model(j, b, X_test)\n",
    "\n",
    "y_pred = (beliefs_pred > 0.5)\\\n",
    "    .float()\n",
    "    .detach()\\\n",
    "    .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4052\n",
      "           1       1.00      1.00      1.00      5948\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : 0, 1: 1}\n",
    "\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a459afb00>"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(200)\n",
    "plot(X_test[i], 'o')\n",
    "plot(y_test[i] + 0.05, 'ro')\n",
    "plot(y_pred[i] + 0.1, 'ko')\n",
    "legend(['observations', 'labels', 'NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity - check that we can reach loss zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(1000)\n",
    "j = [2.5] #[1]\n",
    "b = [-0.8, 1.]\n",
    "labels = y_dataset[ind]\n",
    "observations = X_dataset[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50,), (50,))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape, observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.expand_dims(labels, axis=0)\n",
    "observations = np.expand_dims(observations, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = torch.Tensor(j)\n",
    "b = torch.Tensor(b)\n",
    "labels = torch.Tensor(labels)\n",
    "observations = torch.Tensor(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 ms, sys: 1.31 ms, total: 16.3 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)\n",
    "beliefs = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T, train=False)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4884),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]], dtype=torch.uint8),\n",
       " tensor(1, dtype=torch.uint8))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, torch.eq(labels, beliefs.float()), torch.all(torch.eq(labels, beliefs.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  target loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4683), 1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = [2.5]\n",
    "b = [-0.8, 1.]\n",
    "\n",
    "len_ = len(X_train[:10])\n",
    "\n",
    "j = torch.Tensor(j) \n",
    "b = torch.Tensor(b)\n",
    "\n",
    "observations = torch.Tensor(X_train[:10])\n",
    "labels = torch.Tensor(y_train[:10])\n",
    "\n",
    "target_loss = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)\n",
    "beliefs = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T, train=False)\n",
    "\n",
    "target_loss, int(torch.all(torch.eq(labels, beliefs.float())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = progressbar.ProgressBar(maxval=3000, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "res = {'b0': [], 'b1': [], 'j': [], 'loss': [], 'zero_one_loss': []}\n",
    "\n",
    "bar.start()\n",
    "for i_sample in range(3000):\n",
    "    bar.update(i_sample + 1)\n",
    "    j_val = 2.5 + 5 * (np.random.rand() - 0.5)\n",
    "    b_base = [2 * (np.random.rand() - 0.5) , 1]\n",
    "  \n",
    "    j = torch.Tensor([j_val])\n",
    "    b = torch.Tensor(b_base)\n",
    "    \n",
    "    labels = torch.Tensor(y_train[:10])\n",
    "    observations = torch.Tensor(X_train[:10])\n",
    "    \n",
    "    res['b0'].append(b_base[0])\n",
    "    res['b1'].append(b_base[1])\n",
    "    res['j'].append(j_val)\n",
    "    res['loss'].append(float(belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)))\n",
    "    \n",
    "    beliefs = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T, train=False)\n",
    "    res['zero_one_loss'].append(int(torch.all(torch.eq(labels, beliefs.float()))))\n",
    "    \n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2988\n",
       "1      12\n",
       "Name: zero_one_loss, dtype: int64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.zero_one_loss.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "        x=df['b0'],\n",
    "        y=df['j'], \n",
    "        z=df['loss'], \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=df['zero_one_loss'],                # set color to an array/list of desired values\n",
    "            colorscale='Viridis',   # choose a colorscale\n",
    "            opacity=0.8\n",
    "        ),\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "scene = go.layout.Scene(\n",
    "        annotations=[\n",
    "            dict(\n",
    "                x=-.8,\n",
    "                y=2.5,\n",
    "                z=target_loss,\n",
    "                text=\"target\",\n",
    "                textangle=0,\n",
    "                ax=0,\n",
    "                ay=-75,\n",
    "                font=dict(\n",
    "                    color=\"red\",\n",
    "                    size=18\n",
    "                ),\n",
    "                arrowcolor=\"red\",\n",
    "                arrowsize=3,\n",
    "                arrowwidth=1,\n",
    "                arrowhead=1\n",
    "        )],\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(trace)\n",
    "fig.update_layout(scene=scene)\n",
    "fig.write_html('loss_vs_data_term.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
