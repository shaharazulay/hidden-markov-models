{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _chain import Chain\n",
    "from _pytorch_chain_loss import belief_propagation_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Binary HMM "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> phi(x,_i y_i) represents the data term\n",
    ">>> phi(y_i, y_i+1) represents the smoothness term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_phi(x1, x2):\n",
    "#     p = np.array([\n",
    "#     [0.58, 0.42],\n",
    "#     [0.42, 0.58]])\n",
    "#     return p[x1, x2]\n",
    "    b = [-0.32, 0.4]\n",
    "    return np.round(exp(b[x2] * (x1 - 0.5)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_psi(x1, x2):\n",
    "#     p = np.array([\n",
    "#     [0.62, 0.38],\n",
    "#     [0.34, 0.66]])\n",
    "#     return p[x1, x2]\n",
    "    j = 1\n",
    "    return np.round(exp(j * (x1 - 0.5) * (x2 - 0.5)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = f_phi\n",
    "psi = f_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50 # chain length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = Chain(length=T, phi=phi, psi=psi, possible_values=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_values = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "WARNING: May cause numerical issue for MAP!\n",
      "CPU times: user 6.13 s, sys: 30.9 ms, total: 6.16 s\n",
      "Wall time: 6.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X_dataset = []\n",
    "y_dataset= []\n",
    "\n",
    "for i in range(N):\n",
    "    x = np.random.rand(T)\n",
    "    x_binary = 1 * (x > 0.5)\n",
    "    \n",
    "    chain.update_observed(x_binary)\n",
    "    y = chain.get_max_apostriori_beliefs()\n",
    "\n",
    "    X_dataset.append(x_binary)\n",
    "    y_dataset.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn to numpy arrays\n",
    "X_dataset = np.array([np.array(xi) for xi in X_dataset])\n",
    "y_dataset = np.array([np.array(yi) for yi in y_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a32fd17b8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(X_dataset[0], 'o')\n",
    "plot(y_dataset[0] + 0.05, 'ro')\n",
    "legend(['observations', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dummy Model (predicts y = x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.79      0.68      3755\n",
      "           1       0.84      0.67      0.75      6245\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.73      0.71     10000\n",
      "weighted avg       0.75      0.72      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : 0, 1: 1}\n",
    "\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    features = [\n",
    "        'x.current=' + str(x)\n",
    "    ]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(y):\n",
    "    return str(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for xseq, yseq in zip(X_dataset, y_dataset):\n",
    "    X_features = [extract_features(x_i) for x_i in xseq]\n",
    "    y_labels = [extract_labels(y_i) for y_i in yseq]\n",
    "    \n",
    "    X.append(X_features)\n",
    "    y.append(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 250 ms, sys: 8.02 ms, total: 258 ms\n",
      "Wall time: 259 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0,\n",
    "    c2=0,  # regulate this up to 1 if needed\n",
    "    max_iterations=5000,\n",
    "    all_possible_transitions=True,\n",
    "    all_possible_states=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      3879\n",
      "           1      1.000     1.000     1.000      6121\n",
      "\n",
      "   micro avg      1.000     1.000     1.000     10000\n",
      "   macro avg      1.000     1.000     1.000     10000\n",
      "weighted avg      1.000     1.000     1.000     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:\n",
      "0      -> 0       201.433958\n",
      "1      -> 1       181.121610\n",
      "1      -> 0       -190.162631\n",
      "0      -> 1       -192.392937\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States:\n",
      "160.814494 1        x.current=1\n",
      "111.539195 0        x.current=0\n",
      "-111.539195 1        x.current=0\n",
      "-160.814494 0        x.current=1\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"States:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training FC NN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "batch_size, D_in, D_hidden, D_out = 256, T, T, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_out),\n",
    "          torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network has 15300 parameters, notice your training set size!\n"
     ]
    }
   ],
   "source": [
    "print('Network has {} parameters, notice your training set size!'.format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, flatten=True):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'X': torch.from_numpy(self._X[idx]).float(),\n",
    "            'y': torch.from_numpy(self._y[idx]).float()  \n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ChainDataset(X_train, y_train)\n",
    "testset = ChainDataset(X_test, y_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10:: loss = 0.6386070847511292, validation loss = 0.6420876383781433\n",
      "epoch 20:: loss = 0.5417201519012451, validation loss = 0.5618528723716736\n",
      "epoch 30:: loss = 0.4871368110179901, validation loss = 0.543056070804596\n",
      "epoch 40:: loss = 0.4642716944217682, validation loss = 0.5319937467575073\n",
      "epoch 50:: loss = 0.426086962223053, validation loss = 0.5039685964584351\n",
      "epoch 60:: loss = 0.3601410984992981, validation loss = 0.4992850124835968\n",
      "epoch 70:: loss = 0.3880794942378998, validation loss = 0.5033949017524719\n",
      "epoch 80:: loss = 0.3555992841720581, validation loss = 0.5435436964035034\n",
      "epoch 90:: loss = 0.30707454681396484, validation loss = 0.5567889213562012\n",
      "epoch 100:: loss = 0.3293323814868927, validation loss = 0.5889564156532288\n",
      "epoch 110:: loss = 0.2705768644809723, validation loss = 0.620589554309845\n",
      "epoch 120:: loss = 0.26991507411003113, validation loss = 0.6075847148895264\n",
      "epoch 130:: loss = 0.2661522924900055, validation loss = 0.6937414407730103\n",
      "epoch 140:: loss = 0.2466992884874344, validation loss = 0.642142653465271\n",
      "epoch 150:: loss = 0.23383773863315582, validation loss = 0.6901923418045044\n",
      "epoch 160:: loss = 0.2348562777042389, validation loss = 0.7198590636253357\n",
      "epoch 170:: loss = 0.20908235013484955, validation loss = 0.7527441382408142\n",
      "epoch 180:: loss = 0.16872523725032806, validation loss = 0.742645263671875\n",
      "epoch 190:: loss = 0.18181857466697693, validation loss = 0.839095413684845\n",
      "epoch 200:: loss = 0.1568867713212967, validation loss = 0.8617414832115173\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "learning_curve = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for batch in trainloader:\n",
    "        \n",
    "        X_batch, y_batch = Variable(batch['X']), Variable(batch['y'])\n",
    "        model.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = F.binary_cross_entropy(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        valid = next(iter(validloader))\n",
    "        X_valid, y_valid = Variable(valid['X']), Variable(valid['y']) \n",
    "        y_pred_valid = model(X_valid)\n",
    "        loss_valid = F.binary_cross_entropy(y_pred_valid, y_valid)\n",
    "        \n",
    "        print('epoch {}:: loss = {}, validation loss = {}'. format(epoch, loss, loss_valid))\n",
    "        learning_curve.append((loss, loss_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2d73e5c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([tr_loss for tr_loss, valid_loss in learning_curve]);\n",
    "plot([valid_loss for tr_loss, valid_loss in learning_curve]);\n",
    "legend(['train_loss', 'valid_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (9): ReLU()\n",
       "  (10): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (11): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([model(torch.from_numpy(xseq).float()).detach().numpy() for xseq in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = 1 * (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.52      0.44      3714\n",
      "           1       0.64      0.50      0.56      6286\n",
      "\n",
      "   micro avg       0.51      0.51      0.51     10000\n",
      "   macro avg       0.51      0.51      0.50     10000\n",
      "weighted avg       0.54      0.51      0.51     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : 0, 1: 1}\n",
    "\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a34cde6a0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(200)\n",
    "plot(X_test[i], 'o')\n",
    "plot(y_test[i] + 0.05, 'ro')\n",
    "plot(y_pred[i] + 0.1, 'ko')\n",
    "legend(['observations', 'labels', 'NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training MPNN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size, D_in, D_hidden = 256, T, T\n",
    "D_out = 3 # J is one parameter, b is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_out),\n",
    "          torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "optimizer = optim.Adam(energy_model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len, train=True):\n",
    "    batch_size = labels.size()[0]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    labels_out = torch.Tensor()\n",
    "    for b_idx in range(batch_size):\n",
    "\n",
    "        values = torch.Tensor([0, 1]) - 0.5\n",
    "        pairs = torch.mul(values.view(-1, 2).t(), values)\n",
    "        unit_msg = torch.ones([2, 1]) / 2\n",
    "        \n",
    "        forward_messages = unit_msg\n",
    "        msg_left = unit_msg # no information traveling left to x1\n",
    "        \n",
    "        # forward pass    \n",
    "        for i in range(0, chain_len - 1):\n",
    "            \n",
    "            phi = torch.exp(torch.mul(b[b_idx][int(observations[b_idx][i])], values))\n",
    "            psi = torch.exp(torch.mul(j[b_idx], pairs))\n",
    "  \n",
    "            step1 = torch.mul(phi, msg_left.t())\n",
    "            step2 = torch.mul(step1, psi)\n",
    "            step3, _ = torch.max(step2, dim=1)\n",
    "\n",
    "            msg = step3.view(-1 ,1)\n",
    "            norm_ = torch.norm(msg, p=1, dim=0)  # L1 norm\n",
    "            msg = torch.div(msg, norm_)\n",
    "            \n",
    "            forward_messages = torch.cat((forward_messages, msg), dim=1)    \n",
    "            msg_left = msg\n",
    "        \n",
    "        \n",
    "        backward_messages = unit_msg\n",
    "        msg_right = unit_msg # no information traveling right to x_n\n",
    "        \n",
    "        # backward pass    \n",
    "        for i in range(chain_len - 1, 0, -1):\n",
    "\n",
    "            phi = torch.exp(torch.mul(b[b_idx][int(observations[b_idx][i])], values))\n",
    "            psi = torch.exp(torch.mul(j[b_idx], pairs))\n",
    "            step1 = torch.mul(phi, msg_right.t())\n",
    "            step2 = torch.mul(step1, psi)\n",
    "            step3, _ = torch.max(step2, dim=1)\n",
    "\n",
    "            msg = step3.view(-1 ,1)\n",
    "            norm_ = torch.norm(msg, p=1, dim=0)  # L1 norm\n",
    "            msg = torch.div(msg, norm_)\n",
    "            \n",
    "            backward_messages = torch.cat((msg, backward_messages), dim=1)    \n",
    "            msg_right = msg\n",
    "\n",
    "        # calculate message propagation\n",
    "        messages = torch.mul(forward_messages, backward_messages)\n",
    "        # add data term\n",
    "        data_term = torch.Tensor()\n",
    "        for i in range(0, chain_len):\n",
    "            phi = torch.exp(torch.mul(b[b_idx][int(observations[b_idx][i])], values))\n",
    "            data_term = torch.cat((data_term, phi.view(-1, 1)), dim=1)\n",
    "        \n",
    "        # calculate beliefs\n",
    "        beliefs = torch.mul(data_term, messages)\n",
    "        norm_ = torch.norm(beliefs, p=1, dim=0)  # L1 norm\n",
    "        beliefs_norm = torch.div(beliefs, norm_)\n",
    "        \n",
    "        beliefs_softmax = torch.softmax(beliefs_norm * 1, dim=0)  ## make softmax harder\n",
    "        loss += F.binary_cross_entropy(beliefs_softmax[1, :].float(), labels[b_idx]) \n",
    "\n",
    "        labels_out = torch.cat((labels_out, (beliefs_norm[1, :] > 0.5).float().view(1, -1)), dim=0)\n",
    "    #print(beliefs)\n",
    "    loss = torch.div(loss, batch_size)\n",
    "    \n",
    "    if train:\n",
    "        return loss\n",
    "    else:\n",
    "        return labels_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move to single batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 0.0-0.40148305892944336,  b0: 0.0-0.1439114809036255, b1: 0.0-0.44260817766189575\n",
      "epoch 1:: loss = 1.7194749116897583, validation loss = 0.7133952975273132\n",
      "J: 0.0-0.15621677041053772,  b0: 0.0-0.09101728349924088, b1: 0.0-0.2661215662956238\n",
      "epoch 2:: loss = 0.7144585251808167, validation loss = 0.6937128305435181\n",
      "J: 0.0-0.03142271935939789,  b0: 0.0-0.03667411953210831, b1: 0.0-0.14584827423095703\n",
      "epoch 3:: loss = 0.6944941878318787, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.03883896768093109\n",
      "epoch 4:: loss = 0.6929583549499512, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 5:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 6:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 7:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 8:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 9:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 10:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 11:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 12:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 13:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 14:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 15:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 16:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 17:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 18:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 19:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 20:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 21:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 22:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 23:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 24:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 25:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 26:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 27:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 28:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 29:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 30:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 31:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 32:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 33:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 34:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 35:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 36:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 37:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 38:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 39:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 40:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 41:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 42:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 43:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 44:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 45:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 46:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 47:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 48:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 49:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n",
      "J: 0.0-0.0,  b0: 0.0-0.0, b1: 0.0-0.0\n",
      "epoch 50:: loss = 0.6931481957435608, validation loss = 0.6931462287902832\n"
     ]
    }
   ],
   "source": [
    "energy_model.train()\n",
    "learning_curve = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for batch in trainloader:\n",
    "        X_batch, y_batch = Variable(batch['X']), Variable(batch['y'])\n",
    "        energy_model.zero_grad()\n",
    "        \n",
    "        energy = energy_model(X_batch)\n",
    "        j, b = energy[:, 0], energy[:, 1:]\n",
    "        \n",
    "        print('J: {}-{},  b0: {}-{}, b1: {}-{}'.format(\n",
    "            j.min().detach(),\n",
    "            j.max().detach(), \n",
    "            b[:, 0].min().detach(),\n",
    "            b[:, 0].max().detach(),\n",
    "            b[:, 1].min().detach(),\n",
    "            b[:, 1].max().detach(),\n",
    "        ))\n",
    "        loss = belief_propagation_cross_entropy_loss(j, b, X_batch, y_batch, chain_len=T)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            valid = next(iter(validloader))\n",
    "            X_valid, y_valid = Variable(valid['X']), Variable(valid['y']) \n",
    "            energy_valid = energy_model(X_valid)\n",
    "            j_valid, b_valid = energy_valid[:, 0], energy_valid[:, 1:]\n",
    "            loss_valid = belief_propagation_cross_entropy_loss(j_valid, b_valid, X_valid, y_valid, chain_len=T)\n",
    "\n",
    "            print('epoch {}:: loss = {}, validation loss = {}'. format(epoch, loss, loss_valid))\n",
    "            learning_curve.append((loss, loss_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=3, bias=True)\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_pred = energy_model(torch.from_numpy(X_test).float()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = energy_pred[:, 0]\n",
    "b = energy_pred[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = belief_propagation_cross_entropy_loss(j, b, X_test, torch.Tensor(y_test), chain_len=T, train=False)\\\n",
    "    .detach()\\\n",
    "    .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68      3714\n",
      "           1       0.85      0.68      0.76      6286\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.74      0.72     10000\n",
      "weighted avg       0.75      0.72      0.73     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : 0, 1: 1}\n",
    "\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity - check that we can reach loss zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(1000)\n",
    "j = np.array([1])\n",
    "b = np.array([-0.32, 0.4])\n",
    "labels = y_dataset[ind]\n",
    "observations = X_dataset[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), (2,), (50,), (50,))"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.shape, b.shape, labels.shape, observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = np.expand_dims(j, axis=0)\n",
    "b = np.expand_dims(b, axis=0)\n",
    "labels = np.expand_dims(labels, axis=0)\n",
    "observations = np.expand_dims(observations, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = torch.Tensor(j)\n",
    "b = torch.Tensor(b)\n",
    "labels = torch.Tensor(labels)\n",
    "observations = torch.Tensor(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 ms, sys: 12.6 ms, total: 28.8 ms\n",
      "Wall time: 42.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)\n",
    "beliefs = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T, train=False)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5682),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]], dtype=torch.uint8),\n",
       " tensor(1, dtype=torch.uint8))"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, torch.eq(labels, beliefs.float()), torch.all(torch.eq(labels, beliefs.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  target loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0357)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_base = [-0.32, 0.4]\n",
    "j_val = 1\n",
    "\n",
    "len_ = len(X_train[:10])\n",
    "j = np.expand_dims(j_val, axis=0)\n",
    "j = np.repeat(j, len_, axis=0)\n",
    "j = torch.Tensor(j)\n",
    "b = np.expand_dims(b_base, axis=0)\n",
    "b = np.repeat(b, len_, axis=0)\n",
    "b = torch.Tensor(b)\n",
    "target_loss = belief_propagation_cross_entropy_loss(j, b, torch.Tensor(X_train[:10]), torch.Tensor(y_train[:10]), chain_len=T)\n",
    "\n",
    "target_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss as a function of b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = progressbar.ProgressBar(maxval=3000, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\r"
     ]
    }
   ],
   "source": [
    "res = {'b0': [], 'b1': [], 'loss': []}\n",
    "\n",
    "bar.start()\n",
    "for i_sample in range(3000):\n",
    "    bar.update(i_sample + 1)\n",
    "    j_val = 0\n",
    "    b_base = 2 * (np.random.rand(2) - 0.5)\n",
    "  \n",
    "    len_ = len(X_train[:10])\n",
    "    j = np.expand_dims(j_val, axis=0)\n",
    "    j = np.repeat(j, len_, axis=0)\n",
    "    j = torch.Tensor(j)\n",
    "    \n",
    "    b = np.expand_dims(b_base, axis=0)\n",
    "    b = np.repeat(b, len_, axis=0)\n",
    "    b = torch.Tensor(b)\n",
    "    \n",
    "    labels = torch.Tensor(y_train[:10])\n",
    "    observations = torch.Tensor(X_train[:10])\n",
    "    \n",
    "    res['b0'].append(b_base[0])\n",
    "    res['b1'].append(b_base[1])\n",
    "    res['loss'].append(float(belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)))\n",
    "    \n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "        x=df['b0'],\n",
    "        y=df['b1'], \n",
    "        z=df['loss'], \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=df['loss'],                # set color to an array/list of desired values\n",
    "            colorscale='Viridis',   # choose a colorscale\n",
    "            opacity=0.8\n",
    "        ),\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "scene = go.layout.Scene(\n",
    "        annotations=[\n",
    "            dict(\n",
    "                x=-0.32,\n",
    "                y=0.4,\n",
    "                z=target_loss,\n",
    "                text=\"target\",\n",
    "                textangle=0,\n",
    "                ax=0,\n",
    "                ay=-75,\n",
    "                font=dict(\n",
    "                    color=\"red\",\n",
    "                    size=18\n",
    "                ),\n",
    "                arrowcolor=\"red\",\n",
    "                arrowsize=3,\n",
    "                arrowwidth=1,\n",
    "                arrowhead=1\n",
    "        )],\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(trace)\n",
    "fig.update_layout(scene=scene)\n",
    "fig.write_html('loss_vs_data_term.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df, x=\"b0\", y=\"b1\", z=\"loss\", color=\"loss\",\n",
    "                 hover_data=['b0', 'b1', 'loss'])\n",
    "fig.write_html('loss_vs_data_term.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing the same as a function of b[0] and j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'b0': [], 'j': [], 'loss': []}\n",
    "\n",
    "for i_sample in range(1000):\n",
    "    labels = y_dataset[1]\n",
    "    observations = X_dataset[1]\n",
    "    j_val = np.random.rand() + 0.5  \n",
    "    b1 = 0.4\n",
    "    b_base = 2 * (np.random.rand(2) - 0.5)\n",
    "    b_base[1] = b1 # constant\n",
    "  \n",
    "    j = np.expand_dims(j_val, axis=0)\n",
    "    b = np.expand_dims(b_base, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)\n",
    "    observations = np.expand_dims(observations, axis=0)\n",
    "    \n",
    "    j = torch.Tensor(j)\n",
    "    b = torch.Tensor(b)\n",
    "    labels = torch.Tensor(labels)\n",
    "    observations = torch.Tensor(observations)\n",
    "    \n",
    "    res['b0'].append(b_base[0])\n",
    "    res['j'].append(j_val)\n",
    "    res['loss'].append(float(belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df, x=\"b0\", y=\"j\", z=\"loss\", color=\"loss\",\n",
    "                 hover_data=['b0', 'j', 'loss'])\n",
    "fig.write_html('loss_vs_b_j.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing the same as a function of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6150)\n"
     ]
    }
   ],
   "source": [
    "res = {'b0': [], 'b1': [], 'j': [], 'loss': []}\n",
    "\n",
    "for i_sample in range(10000):\n",
    "    labels = y_dataset[1]\n",
    "    observations = X_dataset[1]\n",
    "    \n",
    "    j_val = np.random.rand()\n",
    "    b_base = 2 * (np.random.rand(2) - 0.5)\n",
    "    \n",
    "    b = np.expand_dims(b_base, axis=0)\n",
    "    j = np.expand_dims(j_val, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)\n",
    "    observations = np.expand_dims(observations, axis=0)\n",
    "    \n",
    "    j = torch.Tensor(j)\n",
    "    b = torch.Tensor(b)\n",
    "    labels = torch.Tensor(labels)\n",
    "    observations = torch.Tensor(observations)\n",
    "    \n",
    "    res['b0'].append(b_base[0])\n",
    "    res['b1'].append(b_base[1])\n",
    "    res['j'].append(j_val)\n",
    "    res['loss'].append(float(belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)))\n",
    "    \n",
    "# make sure real values are on the graph\n",
    "b_base = [-0.32, 0.4]\n",
    "j_val = 1\n",
    "j = np.expand_dims(j_val, axis=0)\n",
    "j = torch.Tensor(j)\n",
    "b = np.expand_dims(b_base, axis=0)\n",
    "b = torch.Tensor(b)\n",
    "res['b0'].append(b_base[0])\n",
    "res['b1'].append(b_base[1])\n",
    "res['j'].append(j_val)\n",
    "target_loss = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)\n",
    "print(target_loss)\n",
    "res['loss'].append(float(target_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(df, x=\"b0\", y=\"b1\", z=\"j\", color=\"loss\",\n",
    "                 hover_data=['b0', 'b1', 'j', 'loss'],\n",
    "                   )\n",
    "fig.write_html('loss_vs_all.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
