{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _chain import Chain, f_phi, f_psi\n",
    "from _chain_bp_loss import belief_propagation_cross_entropy_loss\n",
    "from _data_utils import ChainDataset, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Binary HMM "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> phi(x,_i y_i) represents the data term\n",
    ">>> phi(y_i, y_i+1) represents the smoothness term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = f_phi(b=[-0.8, 1])\n",
    "psi = f_psi(j=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50 # chain length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = Chain(length=T, phi=phi, psi=psi, possible_values=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_values = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.76 s, sys: 24.1 ms, total: 5.78 s\n",
      "Wall time: 5.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X_dataset = []\n",
    "y_dataset= []\n",
    "\n",
    "for i in range(N):\n",
    "    x = np.random.rand(T)\n",
    "    x_binary = 1 * (x > 0.5)\n",
    "    \n",
    "    chain.update_observed(x_binary)\n",
    "    y = chain.get_max_apostriori_beliefs()\n",
    "\n",
    "    X_dataset.append(x_binary)\n",
    "    y_dataset.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn to numpy arrays\n",
    "X_dataset = np.array([np.array(xi) for xi in X_dataset])\n",
    "y_dataset = np.array([np.array(yi) for yi in y_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a34b3f358>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(1000)\n",
    "plot(X_dataset[i], 'o')\n",
    "plot(y_dataset[i] + 0.05, 'ro')\n",
    "legend(['observations', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    features = [\n",
    "        'x.current=' + str(x)\n",
    "    ]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(y):\n",
    "    return str(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for xseq, yseq in zip(X_dataset, y_dataset):\n",
    "    X_features = [extract_features(x_i) for x_i in xseq]\n",
    "    y_labels = [extract_labels(y_i) for y_i in yseq]\n",
    "    \n",
    "    X.append(X_features)\n",
    "    y.append(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 192 ms, sys: 3.28 ms, total: 195 ms\n",
      "Wall time: 195 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0,\n",
    "    c2=0,  # regulate this up to 1 if needed\n",
    "    max_iterations=5000,\n",
    "    all_possible_transitions=True,\n",
    "    all_possible_states=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      3775\n",
      "           1      1.000     1.000     1.000      6225\n",
      "\n",
      "   micro avg      1.000     1.000     1.000     10000\n",
      "   macro avg      1.000     1.000     1.000     10000\n",
      "weighted avg      1.000     1.000     1.000     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:\n",
      "1      -> 1       359.975983\n",
      "0      -> 0       315.672201\n",
      "0      -> 1       -336.769906\n",
      "1      -> 0       -338.878278\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States:\n",
      "241.725664 1        x.current=1\n",
      "234.406002 0        x.current=0\n",
      "-234.406002 1        x.current=0\n",
      "-241.725664 0        x.current=1\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"States:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training MPNN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 64 # len(X_train) # 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ChainDataset(X_train, y_train)\n",
    "testset = ChainDataset(X_test, y_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = Variable(torch.tensor([20.]), requires_grad=True)\n",
    "b = Variable(torch.tensor([-5., 10.]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam([j, b], lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len, train=True):\n",
    "    batch_size = labels.size()[0]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    labels_out = torch.Tensor()\n",
    "    for b_idx in range(batch_size):\n",
    "\n",
    "        values = torch.Tensor([0, 1]) - 0.5\n",
    "        pairs = torch.mul(values.view(-1, 2).t(), values)\n",
    "        unit_msg = torch.ones([2, 1]) / 2\n",
    "        \n",
    "        forward_messages = unit_msg\n",
    "        msg_left = unit_msg # no information traveling left to x1\n",
    "        \n",
    "        # forward pass    \n",
    "        for i in range(0, chain_len - 1):\n",
    "            \n",
    "            phi = torch.exp(torch.mul(b[int(observations[b_idx][i])], values))\n",
    "            psi = torch.exp(torch.mul(j, pairs))\n",
    "  \n",
    "            step1 = torch.mul(phi, msg_left.t())\n",
    "            step2 = torch.mul(step1, psi)\n",
    "            step3, _ = torch.max(step2, dim=1)\n",
    "\n",
    "            msg = step3.view(-1 ,1)\n",
    "            norm_ = torch.norm(msg, p=1, dim=0)  # L1 norm\n",
    "            msg = torch.div(msg, norm_)\n",
    "            \n",
    "            forward_messages = torch.cat((forward_messages, msg), dim=1)    \n",
    "            msg_left = msg\n",
    "        \n",
    "        \n",
    "        backward_messages = unit_msg\n",
    "        msg_right = unit_msg # no information traveling right to x_n\n",
    "        \n",
    "        # backward pass    \n",
    "        for i in range(chain_len - 1, 0, -1):\n",
    "\n",
    "            phi = torch.exp(torch.mul(b[int(observations[b_idx][i])], values))\n",
    "            psi = torch.exp(torch.mul(j, pairs))\n",
    "            step1 = torch.mul(phi, msg_right.t())\n",
    "            step2 = torch.mul(step1, psi)\n",
    "            step3, _ = torch.max(step2, dim=1)\n",
    "\n",
    "            msg = step3.view(-1 ,1)\n",
    "            norm_ = torch.norm(msg, p=1, dim=0)  # L1 norm\n",
    "            msg = torch.div(msg, norm_)\n",
    "            \n",
    "            backward_messages = torch.cat((msg, backward_messages), dim=1)    \n",
    "            msg_right = msg\n",
    "\n",
    "        # calculate message propagation\n",
    "        messages = torch.mul(forward_messages, backward_messages)\n",
    "        # add data term\n",
    "        data_term = torch.Tensor()\n",
    "        for i in range(0, chain_len):\n",
    "            phi = torch.exp(torch.mul(b[int(observations[b_idx][i])], values))\n",
    "            data_term = torch.cat((data_term, phi.view(-1, 1)), dim=1)\n",
    "        \n",
    "        # calculate beliefs\n",
    "        beliefs = torch.mul(data_term, messages)\n",
    "        norm_ = torch.norm(beliefs, p=1, dim=0)  # L1 norm\n",
    "        beliefs_norm = torch.div(beliefs, norm_)\n",
    "        \n",
    "        beliefs_softmax = torch.softmax(beliefs_norm , dim=0)\n",
    "        loss += F.binary_cross_entropy(beliefs_softmax[1, :].float(), labels[b_idx]) ###\n",
    "        \n",
    "        labels_out = torch.cat((labels_out, (beliefs_norm[1, :] > 0.5).float().view(1, -1)), dim=0)\n",
    "        \n",
    "    loss = torch.div(loss, batch_size)\n",
    "    \n",
    "    if train:\n",
    "        return loss\n",
    "    else:\n",
    "        return labels_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 20.0,  b0: -5.0, b1: 10.0\n",
      "JGrad: tensor([0.0147]),  bGrad: tensor([0.1105, 0.0000])\n",
      "J: 19.900001525878906,  b0: -5.099999904632568, b1: 10.0\n",
      "JGrad: tensor([0.0120]),  bGrad: tensor([0.0965, 0.0000])\n",
      "J: 19.801008224487305,  b0: -5.199422359466553, b1: 10.0\n",
      "JGrad: tensor([0.0067]),  bGrad: tensor([0.0613, 0.0000])\n",
      "J: 19.707578659057617,  b0: -5.294965744018555, b1: 10.0\n",
      "JGrad: tensor([0.0095]),  bGrad: tensor([0.0901, 0.0000])\n",
      "J: 19.613555908203125,  b0: -5.39171028137207, b1: 10.0\n",
      "JGrad: tensor([0.0042]),  bGrad: tensor([0.0509, 0.0000])\n",
      "J: 19.5252742767334,  b0: -5.485133171081543, b1: 10.0\n",
      "JGrad: tensor([0.0058]),  bGrad: tensor([0.0487, 0.0000])\n",
      "J: 19.43861198425293,  b0: -5.576122760772705, b1: 10.0\n",
      "JGrad: tensor([0.0098]),  bGrad: tensor([0.0802, 0.0000])\n",
      "J: 19.349197387695312,  b0: -5.668857574462891, b1: 10.0\n",
      "JGrad: tensor([0.0074]),  bGrad: tensor([0.0648, 0.0000])\n",
      "J: 19.259634017944336,  b0: -5.761552810668945, b1: 10.0\n",
      "JGrad: tensor([0.0069]),  bGrad: tensor([0.0656, 0.0000])\n",
      "J: 19.170379638671875,  b0: -5.854356288909912, b1: 10.0\n",
      "JGrad: tensor([0.0051]),  bGrad: tensor([0.0456, 0.0000])\n",
      "J: 19.083158493041992,  b0: -5.945021629333496, b1: 10.0\n",
      "JGrad: tensor([0.0024]),  bGrad: tensor([0.0435, 0.0000])\n",
      "J: 19.001157760620117,  b0: -6.033706188201904, b1: 10.0\n",
      "JGrad: tensor([0.0022]),  bGrad: tensor([0.0354, 0.0000])\n",
      "J: 18.923803329467773,  b0: -6.119656562805176, b1: 10.0\n",
      "JGrad: tensor([0.0070]),  bGrad: tensor([0.0673, 0.0000])\n",
      ">>>\t epoch 1:: loss = 0.40218016505241394, validation loss = 0.40446117520332336\n",
      "J: 18.84437370300293,  b0: -6.207254886627197, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0442, 0.0000])\n",
      "J: 18.77204704284668,  b0: -6.293604373931885, b1: 10.0\n",
      "JGrad: tensor([-0.0069]),  bGrad: tensor([0.0175, 0.0000])\n",
      "J: 18.71988296508789,  b0: -6.374908924102783, b1: 10.0\n",
      "JGrad: tensor([-0.0046]),  bGrad: tensor([0.0312, 0.0000])\n",
      "J: 18.680706024169922,  b0: -6.454004764556885, b1: 10.0\n",
      "JGrad: tensor([-0.0038]),  bGrad: tensor([0.0192, 0.0000])\n",
      "J: 18.651662826538086,  b0: -6.529252529144287, b1: 10.0\n",
      "JGrad: tensor([-0.0030]),  bGrad: tensor([0.0407, 0.0000])\n",
      "J: 18.630388259887695,  b0: -6.604526519775391, b1: 10.0\n",
      "JGrad: tensor([-0.0068]),  bGrad: tensor([0.0045, 0.0000])\n",
      "J: 18.622507095336914,  b0: -6.673806190490723, b1: 10.0\n",
      "JGrad: tensor([-0.0058]),  bGrad: tensor([0.0142, 0.0000])\n",
      "J: 18.624876022338867,  b0: -6.739488124847412, b1: 10.0\n",
      "JGrad: tensor([-0.0053]),  bGrad: tensor([0.0118, 0.0000])\n",
      "J: 18.635587692260742,  b0: -6.801508903503418, b1: 10.0\n",
      "JGrad: tensor([-0.0027]),  bGrad: tensor([0.0243, 0.0000])\n",
      "J: 18.649633407592773,  b0: -6.862531661987305, b1: 10.0\n",
      "JGrad: tensor([-0.0051]),  bGrad: tensor([0.0224, 0.0000])\n",
      "J: 18.670482635498047,  b0: -6.922364711761475, b1: 10.0\n",
      "JGrad: tensor([-0.0052]),  bGrad: tensor([0.0204, 0.0000])\n",
      "J: 18.69755744934082,  b0: -6.980808258056641, b1: 10.0\n",
      "JGrad: tensor([-0.0062]),  bGrad: tensor([0.0159, 0.0000])\n",
      "J: 18.73168182373047,  b0: -7.037191867828369, b1: 10.0\n",
      "JGrad: tensor([-0.0076]),  bGrad: tensor([0.0040, 0.0000])\n",
      ">>>\t epoch 2:: loss = 0.38500428199768066, validation loss = 0.38458624482154846\n",
      "J: 18.77403450012207,  b0: -7.089376449584961, b1: 10.0\n",
      "JGrad: tensor([-0.0059]),  bGrad: tensor([0.0043, 0.0000])\n",
      "J: 18.821325302124023,  b0: -7.137803077697754, b1: 10.0\n",
      "JGrad: tensor([-0.0064]),  bGrad: tensor([0.0087, 0.0000])\n",
      "J: 18.873794555664062,  b0: -7.18372917175293, b1: 10.0\n",
      "JGrad: tensor([-0.0050]),  bGrad: tensor([0.0154, 0.0000])\n",
      "J: 18.929065704345703,  b0: -7.228781223297119, b1: 10.0\n",
      "JGrad: tensor([-0.0067]),  bGrad: tensor([0.0014, 0.0000])\n",
      "J: 18.989120483398438,  b0: -7.2701287269592285, b1: 10.0\n",
      "JGrad: tensor([-0.0095]),  bGrad: tensor([-0.0054,  0.0000])\n",
      "J: 19.056598663330078,  b0: -7.306618690490723, b1: 10.0\n",
      "JGrad: tensor([-0.0050]),  bGrad: tensor([0.0126, 0.0000])\n",
      "J: 19.125240325927734,  b0: -7.342601776123047, b1: 10.0\n",
      "JGrad: tensor([-0.0126]),  bGrad: tensor([-0.0278,  0.0000])\n",
      "J: 19.203189849853516,  b0: -7.369014263153076, b1: 10.0\n",
      "JGrad: tensor([-0.0069]),  bGrad: tensor([-0.0021,  0.0000])\n",
      "J: 19.28328514099121,  b0: -7.392592430114746, b1: 10.0\n",
      "JGrad: tensor([-0.0083]),  bGrad: tensor([0.0034, 0.0000])\n",
      "J: 19.366857528686523,  b0: -7.414846420288086, b1: 10.0\n",
      "JGrad: tensor([-0.0078]),  bGrad: tensor([0.0065, 0.0000])\n",
      "J: 19.452930450439453,  b0: -7.436598777770996, b1: 10.0\n",
      "JGrad: tensor([-0.0088]),  bGrad: tensor([0.0133, 0.0000])\n",
      "J: 19.542285919189453,  b0: -7.459486484527588, b1: 10.0\n",
      "JGrad: tensor([-0.0088]),  bGrad: tensor([0.0056, 0.0000])\n",
      "J: 19.634483337402344,  b0: -7.481642246246338, b1: 10.0\n",
      "JGrad: tensor([-0.0087]),  bGrad: tensor([-0.0152,  0.0000])\n",
      ">>>\t epoch 3:: loss = 0.36806243658065796, validation loss = 0.37579336762428284\n",
      "J: 19.729122161865234,  b0: -7.498165130615234, b1: 10.0\n",
      "JGrad: tensor([-0.0064]),  bGrad: tensor([0.0078, 0.0000])\n",
      "J: 19.823484420776367,  b0: -7.515069961547852, b1: 10.0\n",
      "JGrad: tensor([-0.0080]),  bGrad: tensor([-0.0083,  0.0000])\n",
      "J: 19.919349670410156,  b0: -7.528427600860596, b1: 10.0\n",
      "JGrad: tensor([-0.0111]),  bGrad: tensor([-0.0194,  0.0000])\n",
      "J: 20.019498825073242,  b0: -7.535789489746094, b1: 10.0\n",
      "JGrad: tensor([-0.0111]),  bGrad: tensor([-0.0022,  0.0000])\n",
      "J: 20.12331771850586,  b0: -7.5419464111328125, b1: 10.0\n",
      "JGrad: tensor([-0.0116]),  bGrad: tensor([0.0026, 0.0000])\n",
      "J: 20.23063850402832,  b0: -7.548205852508545, b1: 10.0\n",
      "JGrad: tensor([-0.0077]),  bGrad: tensor([0.0051, 0.0000])\n",
      "J: 20.33740234375,  b0: -7.5551862716674805, b1: 10.0\n",
      "JGrad: tensor([-0.0088]),  bGrad: tensor([0.0033, 0.0000])\n",
      "J: 20.444772720336914,  b0: -7.562385082244873, b1: 10.0\n",
      "JGrad: tensor([-0.0124]),  bGrad: tensor([-0.0021,  0.0000])\n",
      "J: 20.555788040161133,  b0: -7.568384170532227, b1: 10.0\n",
      "JGrad: tensor([-0.0090]),  bGrad: tensor([0.0169, 0.0000])\n",
      "J: 20.666969299316406,  b0: -7.578225135803223, b1: 10.0\n",
      "JGrad: tensor([-0.0098]),  bGrad: tensor([-0.0055,  0.0000])\n",
      "J: 20.779033660888672,  b0: -7.585720539093018, b1: 10.0\n",
      "JGrad: tensor([-0.0092]),  bGrad: tensor([-0.0034,  0.0000])\n",
      "J: 20.891265869140625,  b0: -7.591638565063477, b1: 10.0\n",
      "JGrad: tensor([-0.0131]),  bGrad: tensor([-0.0059,  0.0000])\n",
      "J: 21.0069580078125,  b0: -7.5954413414001465, b1: 10.0\n",
      "JGrad: tensor([-0.0157]),  bGrad: tensor([-0.0360,  0.0000])\n",
      ">>>\t epoch 4:: loss = 0.36512255668640137, validation loss = 0.3619637191295624\n",
      "J: 21.127426147460938,  b0: -7.5892181396484375, b1: 10.0\n",
      "JGrad: tensor([-0.0093]),  bGrad: tensor([-0.0094,  0.0000])\n",
      "J: 21.246896743774414,  b0: -7.581037521362305, b1: 10.0\n",
      "JGrad: tensor([-0.0124]),  bGrad: tensor([-0.0149,  0.0000])\n",
      "J: 21.3680362701416,  b0: -7.5695719718933105, b1: 10.0\n",
      "JGrad: tensor([-0.0105]),  bGrad: tensor([-0.0074,  0.0000])\n",
      "J: 21.48900604248047,  b0: -7.5571417808532715, b1: 10.0\n",
      "JGrad: tensor([-0.0088]),  bGrad: tensor([0.0139, 0.0000])\n",
      "J: 21.608264923095703,  b0: -7.549701690673828, b1: 10.0\n",
      "JGrad: tensor([-0.0108]),  bGrad: tensor([-0.0084,  0.0000])\n",
      "J: 21.727760314941406,  b0: -7.540599346160889, b1: 10.0\n",
      "JGrad: tensor([-0.0112]),  bGrad: tensor([0.0024, 0.0000])\n",
      "J: 21.8477840423584,  b0: -7.533005237579346, b1: 10.0\n",
      "JGrad: tensor([-0.0123]),  bGrad: tensor([0.0087, 0.0000])\n",
      "J: 21.96917724609375,  b0: -7.528585910797119, b1: 10.0\n",
      "JGrad: tensor([-0.0124]),  bGrad: tensor([-0.0081,  0.0000])\n",
      "J: 22.09181022644043,  b0: -7.5222601890563965, b1: 10.0\n",
      "JGrad: tensor([-0.0072]),  bGrad: tensor([0.0206, 0.0000])\n",
      "J: 22.2108211517334,  b0: -7.522461414337158, b1: 10.0\n",
      "JGrad: tensor([-0.0089]),  bGrad: tensor([-0.0041,  0.0000])\n",
      "J: 22.328216552734375,  b0: -7.521449089050293, b1: 10.0\n",
      "JGrad: tensor([-0.0092]),  bGrad: tensor([0.0177, 0.0000])\n",
      "J: 22.44438362121582,  b0: -7.525699138641357, b1: 10.0\n",
      "JGrad: tensor([-0.0076]),  bGrad: tensor([0.0169, 0.0000])\n",
      "J: 22.55790901184082,  b0: -7.534511089324951, b1: 10.0\n",
      "JGrad: tensor([-0.0152]),  bGrad: tensor([-0.0130,  0.0000])\n",
      ">>>\t epoch 5:: loss = 0.3545047640800476, validation loss = 0.34752264618873596\n",
      "J: 22.675798416137695,  b0: -7.5386433601379395, b1: 10.0\n",
      "JGrad: tensor([-0.0088]),  bGrad: tensor([0.0023, 0.0000])\n",
      "J: 22.79190444946289,  b0: -7.543065071105957, b1: 10.0\n",
      "JGrad: tensor([-0.0082]),  bGrad: tensor([0.0070, 0.0000])\n",
      "J: 22.905853271484375,  b0: -7.549185752868652, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0074]),  bGrad: tensor([0.0131, 0.0000])\n",
      "J: 23.01714324951172,  b0: -7.558677673339844, b1: 10.0\n",
      "JGrad: tensor([-0.0069]),  bGrad: tensor([0.0255, 0.0000])\n",
      "J: 23.125490188598633,  b0: -7.5749711990356445, b1: 10.0\n",
      "JGrad: tensor([-0.0036]),  bGrad: tensor([0.0403, 0.0000])\n",
      "J: 23.227745056152344,  b0: -7.601744651794434, b1: 10.0\n",
      "JGrad: tensor([-0.0069]),  bGrad: tensor([0.0162, 0.0000])\n",
      "J: 23.32806396484375,  b0: -7.630880832672119, b1: 10.0\n",
      "JGrad: tensor([-0.0046]),  bGrad: tensor([0.0230, 0.0000])\n",
      "J: 23.424123764038086,  b0: -7.6642045974731445, b1: 10.0\n",
      "JGrad: tensor([-0.0097]),  bGrad: tensor([0.0082, 0.0000])\n",
      "J: 23.521686553955078,  b0: -7.696921348571777, b1: 10.0\n",
      "JGrad: tensor([-0.0063]),  bGrad: tensor([-0.0025,  0.0000])\n",
      "J: 23.617155075073242,  b0: -7.725815296173096, b1: 10.0\n",
      "JGrad: tensor([-0.0084]),  bGrad: tensor([0.0145, 0.0000])\n",
      "J: 23.712919235229492,  b0: -7.7564697265625, b1: 10.0\n",
      "JGrad: tensor([-0.0051]),  bGrad: tensor([0.0153, 0.0000])\n",
      "J: 23.80544662475586,  b0: -7.788976669311523, b1: 10.0\n",
      "JGrad: tensor([-0.0101]),  bGrad: tensor([-0.0024,  0.0000])\n",
      "J: 23.9002742767334,  b0: -7.817661285400391, b1: 10.0\n",
      "JGrad: tensor([-0.0077]),  bGrad: tensor([-0.0147,  0.0000])\n",
      ">>>\t epoch 6:: loss = 0.3304584324359894, validation loss = 0.33480367064476013\n",
      "J: 23.99472427368164,  b0: -7.838960647583008, b1: 10.0\n",
      "JGrad: tensor([-0.0082]),  bGrad: tensor([-0.0004,  0.0000])\n",
      "J: 24.08941650390625,  b0: -7.858119487762451, b1: 10.0\n",
      "JGrad: tensor([-0.0056]),  bGrad: tensor([0.0113, 0.0000])\n",
      "J: 24.18149757385254,  b0: -7.87907075881958, b1: 10.0\n",
      "JGrad: tensor([-0.0094]),  bGrad: tensor([-0.0059,  0.0000])\n",
      "J: 24.2752685546875,  b0: -7.896162509918213, b1: 10.0\n",
      "JGrad: tensor([-0.0060]),  bGrad: tensor([-0.0076,  0.0000])\n",
      "J: 24.36705207824707,  b0: -7.9091901779174805, b1: 10.0\n",
      "JGrad: tensor([-0.0087]),  bGrad: tensor([0.0108, 0.0000])\n",
      "J: 24.459848403930664,  b0: -7.924487113952637, b1: 10.0\n",
      "JGrad: tensor([-0.0057]),  bGrad: tensor([-0.0053,  0.0000])\n",
      "J: 24.550395965576172,  b0: -7.936603546142578, b1: 10.0\n",
      "JGrad: tensor([-0.0044]),  bGrad: tensor([0.0196, 0.0000])\n",
      "J: 24.637500762939453,  b0: -7.953973770141602, b1: 10.0\n",
      "JGrad: tensor([-0.0070]),  bGrad: tensor([-0.0084,  0.0000])\n",
      "J: 24.724388122558594,  b0: -7.966925144195557, b1: 10.0\n",
      "JGrad: tensor([-0.0058]),  bGrad: tensor([-0.0158,  0.0000])\n",
      "J: 24.809785842895508,  b0: -7.973391532897949, b1: 10.0\n",
      "JGrad: tensor([-0.0042]),  bGrad: tensor([-0.0103,  0.0000])\n",
      "J: 24.892070770263672,  b0: -7.975823402404785, b1: 10.0\n",
      "JGrad: tensor([-0.0034]),  bGrad: tensor([-0.0034,  0.0000])\n",
      "J: 24.970590591430664,  b0: -7.976889610290527, b1: 10.0\n",
      "JGrad: tensor([-0.0036]),  bGrad: tensor([-0.0010,  0.0000])\n",
      "J: 25.045942306518555,  b0: -7.977505207061768, b1: 10.0\n",
      "JGrad: tensor([-0.0033]),  bGrad: tensor([0.0197, 0.0000])\n",
      ">>>\t epoch 7:: loss = 0.332557737827301, validation loss = 0.32937830686569214\n",
      "J: 25.11815643310547,  b0: -7.984731197357178, b1: 10.0\n",
      "JGrad: tensor([-0.0038]),  bGrad: tensor([0.0027, 0.0000])\n",
      "J: 25.188024520874023,  b0: -7.992181301116943, b1: 10.0\n",
      "JGrad: tensor([-0.0020]),  bGrad: tensor([0.0048, 0.0000])\n",
      "J: 25.253719329833984,  b0: -8.00057315826416, b1: 10.0\n",
      "JGrad: tensor([-0.0043]),  bGrad: tensor([-0.0096,  0.0000])\n",
      "J: 25.3183650970459,  b0: -8.00484561920166, b1: 10.0\n",
      "JGrad: tensor([-0.0020]),  bGrad: tensor([-0.0054,  0.0000])\n",
      "J: 25.379314422607422,  b0: -8.006836891174316, b1: 10.0\n",
      "JGrad: tensor([-0.0020]),  bGrad: tensor([0.0061, 0.0000])\n",
      "J: 25.436992645263672,  b0: -8.010770797729492, b1: 10.0\n",
      "JGrad: tensor([-0.0034]),  bGrad: tensor([0.0034, 0.0000])\n",
      "J: 25.49334144592285,  b0: -8.015527725219727, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([-0.0219,  0.0000])\n",
      "J: 25.545869827270508,  b0: -8.012138366699219, b1: 10.0\n",
      "JGrad: tensor([-0.0027]),  bGrad: tensor([-0.0055,  0.0000])\n",
      "J: 25.596820831298828,  b0: -8.007128715515137, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([0.0074, 0.0000])\n",
      "J: 25.64371681213379,  b0: -8.005217552185059, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([0.0220, 0.0000])\n",
      "J: 25.68758201599121,  b0: -8.011287689208984, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([0.0080, 0.0000])\n",
      "J: 25.727094650268555,  b0: -8.019607543945312, b1: 10.0\n",
      "JGrad: tensor([-0.0023]),  bGrad: tensor([0.0007, 0.0000])\n",
      "J: 25.765836715698242,  b0: -8.02738094329834, b1: 10.0\n",
      "JGrad: tensor([-0.0032]),  bGrad: tensor([0.0137, 0.0000])\n",
      ">>>\t epoch 8:: loss = 0.32677674293518066, validation loss = 0.3287067115306854\n",
      "J: 25.80499267578125,  b0: -8.039314270019531, b1: 10.0\n",
      "JGrad: tensor([-0.0028]),  bGrad: tensor([-0.0073,  0.0000])\n",
      "J: 25.843984603881836,  b0: -8.047468185424805, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([-0.0003,  0.0000])\n",
      "J: 25.881446838378906,  b0: -8.05473804473877, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([-0.0065,  0.0000])\n",
      "J: 25.91513442993164,  b0: -8.058937072753906, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([-0.0016,  0.0000])\n",
      "J: 25.946413040161133,  b0: -8.06213092803955, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([-0.0126,  0.0000])\n",
      "J: 25.976625442504883,  b0: -8.060379028320312, b1: 10.0\n",
      "JGrad: tensor([-9.6349e-05]),  bGrad: tensor([-0.0090,  0.0000])\n",
      "J: 26.00407600402832,  b0: -8.055481910705566, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0142, 0.0000])\n",
      "J: 26.027568817138672,  b0: -8.05630874633789, b1: 10.0\n",
      "JGrad: tensor([-8.5140e-06]),  bGrad: tensor([0.0128, 0.0000])\n",
      "J: 26.048824310302734,  b0: -8.061800956726074, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([-0.0033,  0.0000])\n",
      "J: 26.068845748901367,  b0: -8.06554126739502, b1: 10.0\n",
      "JGrad: tensor([-6.3076e-06]),  bGrad: tensor([0.0093, 0.0000])\n",
      "J: 26.086957931518555,  b0: -8.072399139404297, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([0.0079, 0.0000])\n",
      "J: 26.10266876220703,  b0: -8.081563949584961, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([-0.0077,  0.0000])\n",
      "J: 26.11918067932129,  b0: -8.086952209472656, b1: 10.0\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([0.0005, 0.0000])\n",
      ">>>\t epoch 9:: loss = 0.3292034864425659, validation loss = 0.32894352078437805\n",
      "J: 26.132192611694336,  b0: -8.09200382232666, b1: 10.0\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([-0.0139,  0.0000])\n",
      "J: 26.142080307006836,  b0: -8.091254234313965, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([0.0034, 0.0000])\n",
      "J: 26.15214729309082,  b0: -8.091894149780273, b1: 10.0\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([0.0072, 0.0000])\n",
      "J: 26.163005828857422,  b0: -8.095240592956543, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([-0.0004,  0.0000])\n",
      "J: 26.172460556030273,  b0: -8.098119735717773, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0089,  0.0000])\n",
      "J: 26.181554794311523,  b0: -8.097254753112793, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([0.0054, 0.0000])\n",
      "J: 26.19033432006836,  b0: -8.098556518554688, b1: 10.0\n",
      "JGrad: tensor([-0.0021]),  bGrad: tensor([-0.0126,  0.0000])\n",
      "J: 26.201295852661133,  b0: -8.094810485839844, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([-0.0030,  0.0000])\n",
      "J: 26.210268020629883,  b0: -8.090265274047852, b1: 10.0\n",
      "JGrad: tensor([-5.5387e-05]),  bGrad: tensor([0.0066, 0.0000])\n",
      "J: 26.218456268310547,  b0: -8.088770866394043, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([0.0007, 0.0000])\n",
      "J: 26.2248477935791,  b0: -8.08770751953125, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([-0.0070,  0.0000])\n",
      "J: 26.231937408447266,  b0: -8.083976745605469, b1: 10.0\n",
      "JGrad: tensor([0.0025]),  bGrad: tensor([-0.0100,  0.0000])\n",
      "J: 26.234664916992188,  b0: -8.076617240905762, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([0.0042, 0.0000])\n",
      ">>>\t epoch 10:: loss = 0.32330483198165894, validation loss = 0.32917240262031555\n",
      "J: 26.239404678344727,  b0: -8.071645736694336, b1: 10.0\n",
      "JGrad: tensor([-0.0023]),  bGrad: tensor([0.0028, 0.0000])\n",
      "J: 26.24700164794922,  b0: -8.068280220031738, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([-0.0001,  0.0000])\n",
      "J: 26.25153160095215,  b0: -8.065190315246582, b1: 10.0\n",
      "JGrad: tensor([0.0021]),  bGrad: tensor([0.0018, 0.0000])\n",
      "J: 26.252500534057617,  b0: -8.063128471374512, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0068, 0.0000])\n",
      "J: 26.25206184387207,  b0: -8.06402587890625, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0069, 0.0000])\n",
      "J: 26.25017547607422,  b0: -8.06765365600586, b1: 10.0\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([0.0065, 0.0000])\n",
      "J: 26.250396728515625,  b0: -8.073601722717285, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([-0.0175,  0.0000])\n",
      "J: 26.253114700317383,  b0: -8.071806907653809, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0118, 0.0000])\n",
      "J: 26.254182815551758,  b0: -8.075044631958008, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([0.0006, 0.0000])\n",
      "J: 26.255542755126953,  b0: -8.078227996826172, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0091,  0.0000])\n",
      "J: 26.25649070739746,  b0: -8.077337265014648, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([-0.0054,  0.0000])\n",
      "J: 26.255910873413086,  b0: -8.074286460876465, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0085, 0.0000])\n",
      "J: 26.2539119720459,  b0: -8.075063705444336, b1: 10.0\n",
      "JGrad: tensor([0.0023]),  bGrad: tensor([0.0005, 0.0000])\n",
      ">>>\t epoch 11:: loss = 0.3352183997631073, validation loss = 0.3291741907596588\n",
      "J: 26.248632431030273,  b0: -8.075976371765137, b1: 10.0\n",
      "JGrad: tensor([0.0017]),  bGrad: tensor([-0.0004,  0.0000])\n",
      "J: 26.24127960205078,  b0: -8.076637268066406, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0008, 0.0000])\n",
      "J: 26.233240127563477,  b0: -8.077587127685547, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([0.0047, 0.0000])\n",
      "J: 26.22494125366211,  b0: -8.08043384552002, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([0.0029, 0.0000])\n",
      "J: 26.21630859375,  b0: -8.084245681762695, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([0.0011, 0.0000])\n",
      "J: 26.210140228271484,  b0: -8.08817195892334, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([0.0007, 0.0000])\n",
      "J: 26.206249237060547,  b0: -8.09202766418457, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([-0.0236,  0.0000])\n",
      "J: 26.204626083374023,  b0: -8.0853910446167, b1: 10.0\n",
      "JGrad: tensor([-0.0019]),  bGrad: tensor([-0.0044,  0.0000])\n",
      "J: 26.206146240234375,  b0: -8.077507019042969, b1: 10.0\n",
      "JGrad: tensor([0.0019]),  bGrad: tensor([-0.0076,  0.0000])\n",
      "J: 26.204456329345703,  b0: -8.067096710205078, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([0.0135, 0.0000])\n",
      "J: 26.201032638549805,  b0: -8.063518524169922, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([-0.0038,  0.0000])\n",
      "J: 26.196918487548828,  b0: -8.058643341064453, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([0.0086, 0.0000])\n",
      "J: 26.19366455078125,  b0: -8.05795955657959, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([0.0148, 0.0000])\n",
      ">>>\t epoch 12:: loss = 0.32570651173591614, validation loss = 0.3291112780570984\n",
      "J: 26.191068649291992,  b0: -8.063785552978516, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0049,  0.0000])\n",
      "J: 26.189538955688477,  b0: -8.066914558410645, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([-0.0025,  0.0000])\n",
      "J: 26.189661026000977,  b0: -8.06866455078125, b1: 10.0\n",
      "JGrad: tensor([-2.5719e-05]),  bGrad: tensor([0.0004, 0.0000])\n",
      "J: 26.18981170654297,  b0: -8.070401191711426, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([-0.0170,  0.0000])\n",
      "J: 26.192659378051758,  b0: -8.064480781555176, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([-0.0087,  0.0000])\n",
      "J: 26.192855834960938,  b0: -8.055304527282715, b1: 10.0\n",
      "JGrad: tensor([0.0013]),  bGrad: tensor([0.0169, 0.0000])\n",
      "J: 26.19091796875,  b0: -8.05449390411377, b1: 10.0\n",
      "JGrad: tensor([0.0013]),  bGrad: tensor([0.0064, 0.0000])\n",
      "J: 26.187089920043945,  b0: -8.05661392211914, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0111, 0.0000])\n",
      "J: 26.183048248291016,  b0: -8.063481330871582, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([0.0067, 0.0000])\n",
      "J: 26.176916122436523,  b0: -8.072665214538574, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([0.0109, 0.0000])\n",
      "J: 26.1710205078125,  b0: -8.085838317871094, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([0.0041, 0.0000])\n",
      "J: 26.167753219604492,  b0: -8.099590301513672, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([-0.0183,  0.0000])\n",
      "J: 26.16532325744629,  b0: -8.10377025604248, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0030, 0.0000])\n",
      ">>>\t epoch 13:: loss = 0.3301069140434265, validation loss = 0.3289998173713684\n",
      "J: 26.16240882873535,  b0: -8.108916282653809, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0242,  0.0000])\n",
      "J: 26.159427642822266,  b0: -8.102644920349121, b1: 10.0\n",
      "JGrad: tensor([0.0025]),  bGrad: tensor([0.0036, 0.0000])\n",
      "J: 26.152637481689453,  b0: -8.098620414733887, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([0.0015, 0.0000])\n",
      "J: 26.14740753173828,  b0: -8.095670700073242, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([-0.0010,  0.0000])\n",
      "J: 26.145164489746094,  b0: -8.092569351196289, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([0.0111, 0.0000])\n",
      "J: 26.141239166259766,  b0: -8.094839096069336, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([-0.0113,  0.0000])\n",
      "J: 26.138729095458984,  b0: -8.091708183288574, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([0.0005, 0.0000])\n",
      "J: 26.13783073425293,  b0: -8.089125633239746, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([-0.0024,  0.0000])\n",
      "J: 26.139842987060547,  b0: -8.08570671081543, b1: 10.0\n",
      "JGrad: tensor([-0.0024]),  bGrad: tensor([-0.0130,  0.0000])\n",
      "J: 26.14576530456543,  b0: -8.076644897460938, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0037,  0.0000])\n",
      "J: 26.151897430419922,  b0: -8.066774368286133, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([0.0069, 0.0000])\n",
      "J: 26.158309936523438,  b0: -8.061055183410645, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0094,  0.0000])\n",
      "J: 26.16472053527832,  b0: -8.051543235778809, b1: 10.0\n",
      "JGrad: tensor([0.0055]),  bGrad: tensor([0.0285, 0.0000])\n",
      ">>>\t epoch 14:: loss = 0.3350081443786621, validation loss = 0.3290919065475464\n",
      "J: 26.16101837158203,  b0: -8.056215286254883, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([-9.7595e-05,  0.0000e+00])\n",
      "J: 26.157472610473633,  b0: -8.06038761138916, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([0.0056, 0.0000])\n",
      "J: 26.1533203125,  b0: -8.066766738891602, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0057, 0.0000])\n",
      "J: 26.147842407226562,  b0: -8.075172424316406, b1: 10.0\n",
      "JGrad: tensor([0.0022]),  bGrad: tensor([0.0230, 0.0000])\n",
      "J: 26.139095306396484,  b0: -8.093475341796875, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0059,  0.0000])\n",
      "J: 26.130802154541016,  b0: -8.107211112976074, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([0.0087, 0.0000])\n",
      "J: 26.12540626525879,  b0: -8.123682975769043, b1: 10.0\n",
      "JGrad: tensor([-0.0028]),  bGrad: tensor([-0.0196,  0.0000])\n",
      "J: 26.12543296813965,  b0: -8.12932300567627, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([-0.0163,  0.0000])\n",
      "J: 26.123933792114258,  b0: -8.12672233581543, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([-0.0091,  0.0000])\n",
      "J: 26.12360382080078,  b0: -8.120081901550293, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([-0.0150,  0.0000])\n",
      "J: 26.12474250793457,  b0: -8.107033729553223, b1: 10.0\n",
      "JGrad: tensor([-0.0019]),  bGrad: tensor([-0.0117,  0.0000])\n",
      "J: 26.1291446685791,  b0: -8.089712142944336, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0070,  0.0000])\n",
      "J: 26.13393783569336,  b0: -8.070775985717773, b1: 10.0\n",
      "JGrad: tensor([-0.0027]),  bGrad: tensor([-0.0080,  0.0000])\n",
      ">>>\t epoch 15:: loss = 0.3229004442691803, validation loss = 0.3290940821170807\n",
      "J: 26.143037796020508,  b0: -8.049880981445312, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([0.0016, 0.0000])\n",
      "J: 26.1528377532959,  b0: -8.031786918640137, b1: 10.0\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([0.0019, 0.0000])\n",
      "J: 26.159198760986328,  b0: -8.016385078430176, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0170, 0.0000])\n",
      "J: 26.16322135925293,  b0: -8.010639190673828, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0135, 0.0000])\n",
      "J: 26.16543960571289,  b0: -8.011920928955078, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0063, 0.0000])\n",
      "J: 26.165620803833008,  b0: -8.016127586364746, b1: 10.0\n",
      "JGrad: tensor([0.0013]),  bGrad: tensor([0.0168, 0.0000])\n",
      "J: 26.16346549987793,  b0: -8.027995109558105, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([0.0024, 0.0000])\n",
      "J: 26.16132354736328,  b0: -8.039838790893555, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0005]),  bGrad: tensor([0.0226, 0.0000])\n",
      "J: 26.16038703918457,  b0: -8.061405181884766, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([0.0003, 0.0000])\n",
      "J: 26.15731430053711,  b0: -8.081019401550293, b1: 10.0\n",
      "JGrad: tensor([-6.9713e-05]),  bGrad: tensor([-0.0032,  0.0000])\n",
      "J: 26.1546688079834,  b0: -8.097148895263672, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([-0.0142,  0.0000])\n",
      "J: 26.151264190673828,  b0: -8.10479736328125, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([-0.0145,  0.0000])\n",
      "J: 26.149730682373047,  b0: -8.104620933532715, b1: 10.0\n",
      "JGrad: tensor([-0.0030]),  bGrad: tensor([-0.0202,  0.0000])\n",
      ">>>\t epoch 16:: loss = 0.32624804973602295, validation loss = 0.3289746940135956\n",
      "J: 26.1539249420166,  b0: -8.094656944274902, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([-0.0111,  0.0000])\n",
      "J: 26.156679153442383,  b0: -8.080265045166016, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([0.0092, 0.0000])\n",
      "J: 26.16031265258789,  b0: -8.071757316589355, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([0.0052, 0.0000])\n",
      "J: 26.16156578063965,  b0: -8.06660270690918, b1: 10.0\n",
      "JGrad: tensor([0.0013]),  bGrad: tensor([-0.0025,  0.0000])\n",
      "J: 26.160289764404297,  b0: -8.060718536376953, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([-0.0024,  0.0000])\n",
      "J: 26.16144561767578,  b0: -8.054244995117188, b1: 10.0\n",
      "JGrad: tensor([0.0021]),  bGrad: tensor([0.0039, 0.0000])\n",
      "J: 26.15846061706543,  b0: -8.050313949584961, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([0.0049, 0.0000])\n",
      "J: 26.15778350830078,  b0: -8.049190521240234, b1: 10.0\n",
      "JGrad: tensor([-8.2050e-05]),  bGrad: tensor([-0.0005,  0.0000])\n",
      "J: 26.157325744628906,  b0: -8.047943115234375, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([0.0117, 0.0000])\n",
      "J: 26.156604766845703,  b0: -8.052627563476562, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([-0.0011,  0.0000])\n",
      "J: 26.157501220703125,  b0: -8.056325912475586, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([0.0010, 0.0000])\n",
      "J: 26.156179428100586,  b0: -8.060157775878906, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([0.0081, 0.0000])\n",
      "J: 26.155696868896484,  b0: -8.067676544189453, b1: 10.0\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([-0.0196,  0.0000])\n",
      ">>>\t epoch 17:: loss = 0.3279649615287781, validation loss = 0.32904502749443054\n",
      "J: 26.157798767089844,  b0: -8.064631462097168, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0103,  0.0000])\n",
      "J: 26.16074562072754,  b0: -8.056708335876465, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0140, 0.0000])\n",
      "J: 26.16148567199707,  b0: -8.056568145751953, b1: 10.0\n",
      "JGrad: tensor([0.0042]),  bGrad: tensor([0.0049, 0.0000])\n",
      "J: 26.154115676879883,  b0: -8.058923721313477, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0074,  0.0000])\n",
      "J: 26.148727416992188,  b0: -8.057332038879395, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([0.0047, 0.0000])\n",
      "J: 26.146026611328125,  b0: -8.058259963989258, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0013,  0.0000])\n",
      "J: 26.144851684570312,  b0: -8.058452606201172, b1: 10.0\n",
      "JGrad: tensor([0.0017]),  bGrad: tensor([0.0031, 0.0000])\n",
      "J: 26.140588760375977,  b0: -8.060218811035156, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([-0.0044,  0.0000])\n",
      "J: 26.137325286865234,  b0: -8.059588432312012, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([0.0009, 0.0000])\n",
      "J: 26.13750457763672,  b0: -8.059481620788574, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([-0.0066,  0.0000])\n",
      "J: 26.135658264160156,  b0: -8.056035041809082, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([0.0169, 0.0000])\n",
      "J: 26.135087966918945,  b0: -8.06154727935791, b1: 10.0\n",
      "JGrad: tensor([-0.0018]),  bGrad: tensor([0.0026, 0.0000])\n",
      "J: 26.138044357299805,  b0: -8.06784725189209, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([0.0069, 0.0000])\n",
      ">>>\t epoch 18:: loss = 0.32970255613327026, validation loss = 0.32897019386291504\n",
      "J: 26.13783836364746,  b0: -8.077054023742676, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0123,  0.0000])\n",
      "J: 26.13721466064453,  b0: -8.079047203063965, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([0.0024, 0.0000])\n",
      "J: 26.137117385864258,  b0: -8.082072257995605, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([-0.0094,  0.0000])\n",
      "J: 26.13563346862793,  b0: -8.079936981201172, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([0.0043, 0.0000])\n",
      "J: 26.13652801513672,  b0: -8.080260276794434, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([-0.0013,  0.0000])\n",
      "J: 26.13797378540039,  b0: -8.079885482788086, b1: 10.0\n",
      "JGrad: tensor([-0.0014]),  bGrad: tensor([0.0002, 0.0000])\n",
      "J: 26.141971588134766,  b0: -8.079655647277832, b1: 10.0\n",
      "JGrad: tensor([0.0024]),  bGrad: tensor([-0.0042,  0.0000])\n",
      "J: 26.140804290771484,  b0: -8.077260971069336, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([-0.0008,  0.0000])\n",
      "J: 26.138927459716797,  b0: -8.074700355529785, b1: 10.0\n",
      "JGrad: tensor([-0.0025]),  bGrad: tensor([-0.0124,  0.0000])\n",
      "J: 26.142269134521484,  b0: -8.065905570983887, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0039,  0.0000])\n",
      "J: 26.146726608276367,  b0: -8.055912017822266, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0064, 0.0000])\n",
      "J: 26.15019416809082,  b0: -8.050235748291016, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0161, 0.0000])\n",
      "J: 26.151424407958984,  b0: -8.053584098815918, b1: 10.0\n",
      "JGrad: tensor([0.0017]),  bGrad: tensor([0.0271, 0.0000])\n",
      ">>>\t epoch 19:: loss = 0.3292671740055084, validation loss = 0.32900670170783997\n",
      "J: 26.149181365966797,  b0: -8.070779800415039, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0018, 0.0000])\n",
      "J: 26.14508819580078,  b0: -8.08721923828125, b1: 10.0\n",
      "JGrad: tensor([0.0021]),  bGrad: tensor([-0.0028,  0.0000])\n",
      "J: 26.1370906829834,  b0: -8.10056209564209, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([0.0155, 0.0000])\n",
      "J: 26.127620697021484,  b0: -8.12072467803955, b1: 10.0\n",
      "JGrad: tensor([-0.0028]),  bGrad: tensor([-0.0192,  0.0000])\n",
      "J: 26.124738693237305,  b0: -8.128725051879883, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([-0.0047,  0.0000])\n",
      "J: 26.118776321411133,  b0: -8.133454322814941, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([-0.0207,  0.0000])\n",
      "J: 26.11690902709961,  b0: -8.126786231994629, b1: 10.0\n",
      "JGrad: tensor([-6.1917e-05]),  bGrad: tensor([-0.0072,  0.0000])\n",
      "J: 26.1153507232666,  b0: -8.116950035095215, b1: 10.0\n",
      "JGrad: tensor([-0.0020]),  bGrad: tensor([0.0004, 0.0000])\n",
      "J: 26.117965698242188,  b0: -8.108294486999512, b1: 10.0\n",
      "JGrad: tensor([-0.0021]),  bGrad: tensor([-0.0008,  0.0000])\n",
      "J: 26.124696731567383,  b0: -8.100069999694824, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([-0.0167,  0.0000])\n",
      "J: 26.132671356201172,  b0: -8.08381175994873, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0012,  0.0000])\n",
      "J: 26.14087677001953,  b0: -8.068512916564941, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0003,  0.0000])\n",
      "J: 26.149219512939453,  b0: -8.054573059082031, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([0.0095, 0.0000])\n",
      ">>>\t epoch 20:: loss = 0.3287803530693054, validation loss = 0.3291415274143219\n",
      "J: 26.15813446044922,  b0: -8.047097206115723, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([0.0031, 0.0000])\n",
      "J: 26.168020248413086,  b0: -8.041991233825684, b1: 10.0\n",
      "JGrad: tensor([0.0023]),  bGrad: tensor([0.0131, 0.0000])\n",
      "J: 26.17218589782715,  b0: -8.04442310333252, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([-8.5726e-05,  0.0000e+00])\n",
      "J: 26.173521041870117,  b0: -8.046570777893066, b1: 10.0\n",
      "JGrad: tensor([-7.8487e-05]),  bGrad: tensor([-0.0091,  0.0000])\n",
      "J: 26.174888610839844,  b0: -8.043597221374512, b1: 10.0\n",
      "JGrad: tensor([0.0024]),  bGrad: tensor([0.0094, 0.0000])\n",
      "J: 26.171077728271484,  b0: -8.046004295349121, b1: 10.0\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([0.0089, 0.0000])\n",
      "J: 26.16473388671875,  b0: -8.052998542785645, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0057,  0.0000])\n",
      "J: 26.160444259643555,  b0: -8.056227684020996, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0026, 0.0000])\n",
      "J: 26.156028747558594,  b0: -8.060528755187988, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([0.0223, 0.0000])\n",
      "J: 26.153684616088867,  b0: -8.076467514038086, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0016]),  bGrad: tensor([-0.0084,  0.0000])\n",
      "J: 26.15494728088379,  b0: -8.086299896240234, b1: 10.0\n",
      "JGrad: tensor([-0.0019]),  bGrad: tensor([-0.0008,  0.0000])\n",
      "J: 26.160146713256836,  b0: -8.094736099243164, b1: 10.0\n",
      "JGrad: tensor([-2.5131e-05]),  bGrad: tensor([0.0028, 0.0000])\n",
      "J: 26.164888381958008,  b0: -8.1038818359375, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([-0.0296,  0.0000])\n",
      ">>>\t epoch 21:: loss = 0.32833611965179443, validation loss = 0.3289923369884491\n",
      "J: 26.16602325439453,  b0: -8.09598159790039, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([-0.0073,  0.0000])\n",
      "J: 26.164644241333008,  b0: -8.0848970413208, b1: 10.0\n",
      "JGrad: tensor([-0.0001]),  bGrad: tensor([-0.0064,  0.0000])\n",
      "J: 26.163652420043945,  b0: -8.071423530578613, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0047, 0.0000])\n",
      "J: 26.16188621520996,  b0: -8.061841011047363, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([-0.0055,  0.0000])\n",
      "J: 26.163681030273438,  b0: -8.050195693969727, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([0.0062, 0.0000])\n",
      "J: 26.163785934448242,  b0: -8.043112754821777, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([0.0305, 0.0000])\n",
      "J: 26.16358184814453,  b0: -8.053437232971191, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0002, 0.0000])\n",
      "J: 26.161653518676758,  b0: -8.062874794006348, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([-0.0140,  0.0000])\n",
      "J: 26.162294387817383,  b0: -8.06371784210205, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([-0.0035,  0.0000])\n",
      "J: 26.164207458496094,  b0: -8.062544822692871, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0116, 0.0000])\n",
      "J: 26.164236068725586,  b0: -8.067870140075684, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([0.0030, 0.0000])\n",
      "J: 26.167551040649414,  b0: -8.074322700500488, b1: 10.0\n",
      "JGrad: tensor([0.0023]),  bGrad: tensor([-0.0003,  0.0000])\n",
      "J: 26.165430068969727,  b0: -8.079994201660156, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0158,  0.0000])\n",
      ">>>\t epoch 22:: loss = 0.3285016715526581, validation loss = 0.3290136754512787\n",
      "J: 26.1630916595459,  b0: -8.07637882232666, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([0.0071, 0.0000])\n",
      "J: 26.163541793823242,  b0: -8.07706069946289, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([0.0012, 0.0000])\n",
      "J: 26.167287826538086,  b0: -8.078336715698242, b1: 10.0\n",
      "JGrad: tensor([0.0018]),  bGrad: tensor([0.0103, 0.0000])\n",
      "J: 26.166799545288086,  b0: -8.085199356079102, b1: 10.0\n",
      "JGrad: tensor([-0.0020]),  bGrad: tensor([-0.0024,  0.0000])\n",
      "J: 26.170663833618164,  b0: -8.090031623840332, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([-0.0108,  0.0000])\n",
      "J: 26.173826217651367,  b0: -8.088397979736328, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([-0.0117,  0.0000])\n",
      "J: 26.173147201538086,  b0: -8.080431938171387, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([-0.0136,  0.0000])\n",
      "J: 26.171585083007812,  b0: -8.06567668914795, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0017,  0.0000])\n",
      "J: 26.171796798706055,  b0: -8.051441192626953, b1: 10.0\n",
      "JGrad: tensor([0.0025]),  bGrad: tensor([0.0017, 0.0000])\n",
      "J: 26.166452407836914,  b0: -8.039582252502441, b1: 10.0\n",
      "JGrad: tensor([6.2014e-05]),  bGrad: tensor([0.0101, 0.0000])\n",
      "J: 26.161495208740234,  b0: -8.034578323364258, b1: 10.0\n",
      "JGrad: tensor([7.8021e-05]),  bGrad: tensor([-0.0009,  0.0000])\n",
      "J: 26.156850814819336,  b0: -8.029573440551758, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0179, 0.0000])\n",
      "J: 26.15081024169922,  b0: -8.035135269165039, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([0.0110, 0.0000])\n",
      ">>>\t epoch 23:: loss = 0.32254600524902344, validation loss = 0.32912230491638184\n",
      "J: 26.145893096923828,  b0: -8.046351432800293, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([0.0107, 0.0000])\n",
      "J: 26.142854690551758,  b0: -8.062488555908203, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0115,  0.0000])\n",
      "J: 26.141677856445312,  b0: -8.07056999206543, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([-0.0044,  0.0000])\n",
      "J: 26.13986587524414,  b0: -8.075345039367676, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0056, 0.0000])\n",
      "J: 26.137659072875977,  b0: -8.082830429077148, b1: 10.0\n",
      "JGrad: tensor([-0.0014]),  bGrad: tensor([-0.0064,  0.0000])\n",
      "J: 26.13888168334961,  b0: -8.085943222045898, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([-0.0111,  0.0000])\n",
      "J: 26.142194747924805,  b0: -8.0824556350708, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([0.0040, 0.0000])\n",
      "J: 26.147130966186523,  b0: -8.081598281860352, b1: 10.0\n",
      "JGrad: tensor([0.0026]),  bGrad: tensor([0.0110, 0.0000])\n",
      "J: 26.14577865600586,  b0: -8.0871000289917, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([-0.0009,  0.0000])\n",
      "J: 26.14227294921875,  b0: -8.091525077819824, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0079,  0.0000])\n",
      "J: 26.140649795532227,  b0: -8.090988159179688, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([0.0064, 0.0000])\n",
      "J: 26.141029357910156,  b0: -8.094141960144043, b1: 10.0\n",
      "JGrad: tensor([-0.0001]),  bGrad: tensor([-0.0123,  0.0000])\n",
      "J: 26.14165687561035,  b0: -8.089941024780273, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([0.0043, 0.0000])\n",
      ">>>\t epoch 24:: loss = 0.3303382992744446, validation loss = 0.32895711064338684\n",
      "J: 26.140605926513672,  b0: -8.088608741760254, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([-0.0063,  0.0000])\n",
      "J: 26.139001846313477,  b0: -8.08378791809082, b1: 10.0\n",
      "JGrad: tensor([0.0020]),  bGrad: tensor([0.0021, 0.0000])\n",
      "J: 26.132917404174805,  b0: -8.080657005310059, b1: 10.0\n",
      "JGrad: tensor([9.2790e-05]),  bGrad: tensor([0.0095, 0.0000])\n",
      "J: 26.12721824645996,  b0: -8.0833101272583, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([0.0041, 0.0000])\n",
      "J: 26.122961044311523,  b0: -8.088072776794434, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([-0.0105,  0.0000])\n",
      "J: 26.12125015258789,  b0: -8.086318969726562, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([0.0035, 0.0000])\n",
      "J: 26.12125587463379,  b0: -8.086735725402832, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([-0.0168,  0.0000])\n",
      "J: 26.119001388549805,  b0: -8.077376365661621, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([-0.0044,  0.0000])\n",
      "J: 26.1163330078125,  b0: -8.066390991210938, b1: 10.0\n",
      "JGrad: tensor([0.0027]),  bGrad: tensor([0.0189, 0.0000])\n",
      "J: 26.107738494873047,  b0: -8.067450523376465, b1: 10.0\n",
      "JGrad: tensor([-0.0021]),  bGrad: tensor([-0.0085,  0.0000])\n",
      "J: 26.10484504699707,  b0: -8.063464164733887, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([0.0080, 0.0000])\n",
      "J: 26.10601234436035,  b0: -8.064499855041504, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([-0.0094,  0.0000])\n",
      "J: 26.11086082458496,  b0: -8.059981346130371, b1: 10.0\n",
      "JGrad: tensor([-0.0025]),  bGrad: tensor([-0.0088,  0.0000])\n",
      ">>>\t epoch 25:: loss = 0.32410210371017456, validation loss = 0.3290475010871887\n",
      "J: 26.120983123779297,  b0: -8.050808906555176, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([-0.0015,  0.0000])\n",
      "J: 26.1335506439209,  b0: -8.041637420654297, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([0.0103, 0.0000])\n",
      "J: 26.14727783203125,  b0: -8.0393705368042, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0052, 0.0000])\n",
      "J: 26.15763282775879,  b0: -8.040392875671387, b1: 10.0\n",
      "JGrad: tensor([0.0033]),  bGrad: tensor([-0.0075,  0.0000])\n",
      "J: 26.15923309326172,  b0: -8.036934852600098, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([0.0082, 0.0000])\n",
      "J: 26.159446716308594,  b0: -8.038623809814453, b1: 10.0\n",
      "JGrad: tensor([-0.0014]),  bGrad: tensor([0.0077, 0.0000])\n",
      "J: 26.16297721862793,  b0: -8.044681549072266, b1: 10.0\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([0.0116, 0.0000])\n",
      "J: 26.16923713684082,  b0: -8.056974411010742, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([-0.0070,  0.0000])\n",
      "J: 26.175609588623047,  b0: -8.063940048217773, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([-0.0093,  0.0000])\n",
      "J: 26.178403854370117,  b0: -8.064729690551758, b1: 10.0\n",
      "JGrad: tensor([0.0019]),  bGrad: tensor([0.0219, 0.0000])\n",
      "J: 26.176490783691406,  b0: -8.078368186950684, b1: 10.0\n",
      "JGrad: tensor([-0.0001]),  bGrad: tensor([-0.0099,  0.0000])\n",
      "J: 26.17504119873047,  b0: -8.084794044494629, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0013, 0.0000])\n",
      "J: 26.172998428344727,  b0: -8.091371536254883, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0006,  0.0000])\n",
      ">>>\t epoch 26:: loss = 0.327629417181015, validation loss = 0.32900142669677734\n",
      "J: 26.172021865844727,  b0: -8.096942901611328, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([0.0035, 0.0000])\n",
      "J: 26.16998291015625,  b0: -8.104052543640137, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([-0.0103,  0.0000])\n",
      "J: 26.17045783996582,  b0: -8.104350090026855, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([-0.0176,  0.0000])\n",
      "J: 26.16886329650879,  b0: -8.094159126281738, b1: 10.0\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([-0.0140,  0.0000])\n",
      "J: 26.170547485351562,  b0: -8.076661109924316, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([-0.0023,  0.0000])\n",
      "J: 26.172557830810547,  b0: -8.059503555297852, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([0.0040, 0.0000])\n",
      "J: 26.17616081237793,  b0: -8.046435356140137, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([0.0052, 0.0000])\n",
      "J: 26.181766510009766,  b0: -8.037752151489258, b1: 10.0\n",
      "JGrad: tensor([0.0022]),  bGrad: tensor([0.0314, 0.0000])\n",
      "J: 26.18160057067871,  b0: -8.048639297485352, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([0.0048, 0.0000])\n",
      "J: 26.18348503112793,  b0: -8.061306953430176, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([-0.0034,  0.0000])\n",
      "J: 26.183542251586914,  b0: -8.070671081542969, b1: 10.0\n",
      "JGrad: tensor([-0.0014]),  bGrad: tensor([-0.0036,  0.0000])\n",
      "J: 26.187063217163086,  b0: -8.076944351196289, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0012, 0.0000])\n",
      "J: 26.18962287902832,  b0: -8.083296775817871, b1: 10.0\n",
      "JGrad: tensor([0.0061]),  bGrad: tensor([0.0086, 0.0000])\n",
      ">>>\t epoch 27:: loss = 0.3348829448223114, validation loss = 0.3290095627307892\n",
      "J: 26.177080154418945,  b0: -8.094170570373535, b1: 10.0\n",
      "JGrad: tensor([-7.0313e-05]),  bGrad: tensor([0.0048, 0.0000])\n",
      "J: 26.165943145751953,  b0: -8.106829643249512, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([-0.0085,  0.0000])\n",
      "J: 26.158668518066406,  b0: -8.11310863494873, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0039,  0.0000])\n",
      "J: 26.151714324951172,  b0: -8.11642837524414, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0136,  0.0000])\n",
      "J: 26.147249221801758,  b0: -8.111210823059082, b1: 10.0\n",
      "JGrad: tensor([-0.0014]),  bGrad: tensor([-0.0053,  0.0000])\n",
      "J: 26.146650314331055,  b0: -8.103340148925781, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([0.0084, 0.0000])\n",
      "J: 26.146881103515625,  b0: -8.10129451751709, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([0.0018, 0.0000])\n",
      "J: 26.149127960205078,  b0: -8.100542068481445, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([-0.0114,  0.0000])\n",
      "J: 26.151630401611328,  b0: -8.092939376831055, b1: 10.0\n",
      "JGrad: tensor([-5.4557e-05]),  bGrad: tensor([-0.0014,  0.0000])\n",
      "J: 26.154020309448242,  b0: -8.08521842956543, b1: 10.0\n",
      "JGrad: tensor([0.0036]),  bGrad: tensor([-0.0064,  0.0000])\n",
      "J: 26.147226333618164,  b0: -8.074348449707031, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([-0.0111,  0.0000])\n",
      "J: 26.143993377685547,  b0: -8.057839393615723, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([0.0002, 0.0000])\n",
      "J: 26.142349243164062,  b0: -8.04308032989502, b1: 10.0\n",
      "JGrad: tensor([-0.0019]),  bGrad: tensor([0.0079, 0.0000])\n",
      ">>>\t epoch 28:: loss = 0.3247397840023041, validation loss = 0.32920894026756287\n",
      "J: 26.145593643188477,  b0: -8.034621238708496, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([-0.0108,  0.0000])\n",
      "J: 26.144670486450195,  b0: -8.020437240600586, b1: 10.0\n",
      "JGrad: tensor([0.0019]),  bGrad: tensor([0.0150, 0.0000])\n",
      "J: 26.13912010192871,  b0: -8.016843795776367, b1: 10.0\n",
      "JGrad: tensor([7.2628e-05]),  bGrad: tensor([0.0125, 0.0000])\n",
      "J: 26.133935928344727,  b0: -8.021215438842773, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([0.0277, 0.0000])\n",
      "J: 26.133563995361328,  b0: -8.041967391967773, b1: 10.0\n",
      "JGrad: tensor([0.0020]),  bGrad: tensor([-0.0006,  0.0000])\n",
      "J: 26.12836265563965,  b0: -8.060302734375, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([-0.0036,  0.0000])\n",
      "J: 26.124284744262695,  b0: -8.074638366699219, b1: 10.0\n",
      "JGrad: tensor([0.0020]),  bGrad: tensor([0.0041, 0.0000])\n",
      "J: 26.115711212158203,  b0: -8.09006118774414, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([0.0010, 0.0000])\n",
      "J: 26.110240936279297,  b0: -8.1045503616333, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([-0.0048,  0.0000])\n",
      "J: 26.109243392944336,  b0: -8.114683151245117, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([-0.0124,  0.0000])\n",
      "J: 26.106964111328125,  b0: -8.116196632385254, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0052,  0.0000])\n",
      "J: 26.10614013671875,  b0: -8.114336013793945, b1: 10.0\n",
      "JGrad: tensor([-0.0028]),  bGrad: tensor([-0.0195,  0.0000])\n",
      "J: 26.112524032592773,  b0: -8.100662231445312, b1: 10.0\n",
      "JGrad: tensor([-0.0030]),  bGrad: tensor([-0.0072,  0.0000])\n",
      ">>>\t epoch 29:: loss = 0.3257906436920166, validation loss = 0.3289394676685333\n",
      "J: 26.125722885131836,  b0: -8.083909034729004, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([0.0071, 0.0000])\n",
      "J: 26.137210845947266,  b0: -8.073205947875977, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0090, 0.0000])\n",
      "J: 26.14544677734375,  b0: -8.069128036499023, b1: 10.0\n",
      "JGrad: tensor([-0.0022]),  bGrad: tensor([-0.0042,  0.0000])\n",
      "J: 26.158382415771484,  b0: -8.062888145446777, b1: 10.0\n",
      "JGrad: tensor([0.0019]),  bGrad: tensor([0.0175, 0.0000])\n",
      "J: 26.165212631225586,  b0: -8.068047523498535, b1: 10.0\n",
      "JGrad: tensor([0.0019]),  bGrad: tensor([0.0082, 0.0000])\n",
      "J: 26.166528701782227,  b0: -8.077757835388184, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([-0.0152,  0.0000])\n",
      "J: 26.17085838317871,  b0: -8.07711410522461, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([-0.0001,  0.0000])\n",
      "J: 26.17302703857422,  b0: -8.076461791992188, b1: 10.0\n",
      "JGrad: tensor([-0.0014]),  bGrad: tensor([-0.0010,  0.0000])\n",
      "J: 26.178611755371094,  b0: -8.075273513793945, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([-0.0065,  0.0000])\n",
      "J: 26.182052612304688,  b0: -8.070184707641602, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([0.0087, 0.0000])\n",
      "J: 26.18762969970703,  b0: -8.07100772857666, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([-0.0126,  0.0000])\n",
      "J: 26.193220138549805,  b0: -8.063895225524902, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([-0.0098,  0.0000])\n",
      "J: 26.196613311767578,  b0: -8.051382064819336, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([0.0011, 0.0000])\n",
      ">>>\t epoch 30:: loss = 0.32314833998680115, validation loss = 0.3292756974697113\n",
      "J: 26.200159072875977,  b0: -8.040802955627441, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([-0.0001,  0.0000])\n",
      "J: 26.206117630004883,  b0: -8.031177520751953, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0095, 0.0000])\n",
      "J: 26.209444046020508,  b0: -8.028430938720703, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([-0.0050,  0.0000])\n",
      "J: 26.210386276245117,  b0: -8.022810935974121, b1: 10.0\n",
      "JGrad: tensor([0.0022]),  bGrad: tensor([0.0234, 0.0000])\n",
      "J: 26.205507278442383,  b0: -8.03235912322998, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0085, 0.0000])\n",
      "J: 26.200300216674805,  b0: -8.046253204345703, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([0.0079, 0.0000])\n",
      "J: 26.192981719970703,  b0: -8.063703536987305, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0018,  0.0000])\n",
      "J: 26.188228607177734,  b0: -8.078283309936523, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0097,  0.0000])\n",
      "J: 26.18488121032715,  b0: -8.08535385131836, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([0.0025, 0.0000])\n",
      "J: 26.181461334228516,  b0: -8.093299865722656, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([0.0110, 0.0000])\n",
      "J: 26.175155639648438,  b0: -8.10739803314209, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0126,  0.0000])\n",
      "J: 26.1688289642334,  b0: -8.112150192260742, b1: 10.0\n",
      "JGrad: tensor([-0.0024]),  bGrad: tensor([-0.0146,  0.0000])\n",
      "J: 26.169437408447266,  b0: -8.107251167297363, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0040, 0.0000])\n",
      ">>>\t epoch 31:: loss = 0.3234790563583374, validation loss = 0.3290029764175415\n",
      "J: 26.16891860961914,  b0: -8.105378150939941, b1: 10.0\n",
      "JGrad: tensor([2.9678e-05]),  bGrad: tensor([0.0022, 0.0000])\n",
      "J: 26.168373107910156,  b0: -8.105087280273438, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0107,  0.0000])\n",
      "J: 26.168842315673828,  b0: -8.09804916381836, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([0.0014, 0.0000])\n",
      "J: 26.171079635620117,  b0: -8.092562675476074, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([-0.0047,  0.0000])\n",
      "J: 26.177091598510742,  b0: -8.084665298461914, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([0.0011, 0.0000])\n",
      "J: 26.185264587402344,  b0: -8.07826042175293, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([-0.0024,  0.0000])\n",
      "J: 26.195526123046875,  b0: -8.070964813232422, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0067, 0.0000])\n",
      "J: 26.20258331298828,  b0: -8.068625450134277, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([-0.0095,  0.0000])\n",
      "J: 26.207969665527344,  b0: -8.06043815612793, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([-0.0029,  0.0000])\n",
      "J: 26.2095947265625,  b0: -8.051225662231445, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([0.0047, 0.0000])\n",
      "J: 26.209787368774414,  b0: -8.045903205871582, b1: 10.0\n",
      "JGrad: tensor([0.0020]),  bGrad: tensor([0.0079, 0.0000])\n",
      "J: 26.20465850830078,  b0: -8.046168327331543, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([0.0062, 0.0000])\n",
      "J: 26.196781158447266,  b0: -8.05040168762207, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([-0.0057,  0.0000])\n",
      ">>>\t epoch 32:: loss = 0.32227399945259094, validation loss = 0.32918843626976013\n",
      "J: 26.192394256591797,  b0: -8.05055046081543, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([0.0166, 0.0000])\n",
      "J: 26.18902587890625,  b0: -8.061310768127441, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([0.0058, 0.0000])\n",
      "J: 26.190011978149414,  b0: -8.074756622314453, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([-0.0082,  0.0000])\n",
      "J: 26.19325828552246,  b0: -8.081586837768555, b1: 10.0\n",
      "JGrad: tensor([-0.0018]),  bGrad: tensor([-0.0077,  0.0000])\n",
      "J: 26.200910568237305,  b0: -8.082758903503418, b1: 10.0\n",
      "JGrad: tensor([0.0018]),  bGrad: tensor([0.0021, 0.0000])\n",
      "J: 26.203039169311523,  b0: -8.085176467895508, b1: 10.0\n",
      "JGrad: tensor([-3.7790e-05]),  bGrad: tensor([0.0026, 0.0000])\n",
      "J: 26.205059051513672,  b0: -8.089045524597168, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0104, 0.0000])\n",
      "J: 26.20467758178711,  b0: -8.099245071411133, b1: 10.0\n",
      "JGrad: tensor([-0.0018]),  bGrad: tensor([-0.0170,  0.0000])\n",
      "J: 26.209272384643555,  b0: -8.097478866577148, b1: 10.0\n",
      "JGrad: tensor([0.0025]),  bGrad: tensor([0.0085, 0.0000])\n",
      "J: 26.206642150878906,  b0: -8.101408958435059, b1: 10.0\n",
      "JGrad: tensor([0.0024]),  bGrad: tensor([-0.0035,  0.0000])\n",
      "J: 26.19791030883789,  b0: -8.102666854858398, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([0.0030, 0.0000])\n",
      "J: 26.1919002532959,  b0: -8.105755805969238, b1: 10.0\n",
      "JGrad: tensor([-0.0001]),  bGrad: tensor([-0.0224,  0.0000])\n",
      "J: 26.186840057373047,  b0: -8.094017028808594, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0192,  0.0000])\n",
      ">>>\t epoch 33:: loss = 0.3285730481147766, validation loss = 0.32906779646873474\n",
      "J: 26.184186935424805,  b0: -8.07107925415039, b1: 10.0\n",
      "JGrad: tensor([0.0028]),  bGrad: tensor([0.0057, 0.0000])\n",
      "J: 26.174318313598633,  b0: -8.054129600524902, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0017, 0.0000])\n",
      "J: 26.16319465637207,  b0: -8.03997802734375, b1: 10.0\n",
      "JGrad: tensor([-0.0021]),  bGrad: tensor([-0.0066,  0.0000])\n",
      "J: 26.158756256103516,  b0: -8.022958755493164, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0004, 0.0000])\n",
      "J: 26.152362823486328,  b0: -8.007883071899414, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([0.0093, 0.0000])\n",
      "J: 26.147729873657227,  b0: -8.00037670135498, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0006,  0.0000])\n",
      "J: 26.14557647705078,  b0: -7.993205547332764, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0073, 0.0000])\n",
      "J: 26.1429386138916,  b0: -7.991519451141357, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0185, 0.0000])\n",
      "J: 26.139623641967773,  b0: -8.00206184387207, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0094, 0.0000])\n",
      "J: 26.134342193603516,  b0: -8.017667770385742, b1: 10.0\n",
      "JGrad: tensor([0.0028]),  bGrad: tensor([0.0163, 0.0000])\n",
      "J: 26.121841430664062,  b0: -8.042304039001465, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([-0.0051,  0.0000])\n",
      "J: 26.11151695251465,  b0: -8.061203002929688, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([0.0051, 0.0000])\n",
      "J: 26.10094451904297,  b0: -8.081560134887695, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([0.0152, 0.0000])\n",
      ">>>\t epoch 34:: loss = 0.3252083957195282, validation loss = 0.32891836762428284\n",
      "J: 26.09241485595703,  b0: -8.109821319580078, b1: 10.0\n",
      "JGrad: tensor([-3.3407e-05]),  bGrad: tensor([-0.0085,  0.0000])\n",
      "J: 26.084819793701172,  b0: -8.129693031311035, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([-0.0020,  0.0000])\n",
      "J: 26.082679748535156,  b0: -8.146286010742188, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([-0.0019,  0.0000])\n",
      "J: 26.081581115722656,  b0: -8.160015106201172, b1: 10.0\n",
      "JGrad: tensor([-0.0021]),  bGrad: tensor([-0.0228,  0.0000])\n",
      "J: 26.086261749267578,  b0: -8.157435417175293, b1: 10.0\n",
      "JGrad: tensor([-0.0042]),  bGrad: tensor([-0.0260,  0.0000])\n",
      "J: 26.102018356323242,  b0: -8.13813591003418, b1: 10.0\n",
      "JGrad: tensor([-2.8188e-05]),  bGrad: tensor([-0.0112,  0.0000])\n",
      "J: 26.116296768188477,  b0: -8.113448143005371, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([-0.0078,  0.0000])\n",
      "J: 26.133697509765625,  b0: -8.086082458496094, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([-0.0020,  0.0000])\n",
      "J: 26.1471004486084,  b0: -8.060108184814453, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([0.0074, 0.0000])\n",
      "J: 26.161216735839844,  b0: -8.04158878326416, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([0.0040, 0.0000])\n",
      "J: 26.176755905151367,  b0: -8.027532577514648, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0099, 0.0000])\n",
      "J: 26.18973159790039,  b0: -8.021405220031738, b1: 10.0\n",
      "JGrad: tensor([0.0020]),  bGrad: tensor([0.0128, 0.0000])\n",
      "J: 26.195959091186523,  b0: -8.024293899536133, b1: 10.0\n",
      "JGrad: tensor([0.0054]),  bGrad: tensor([0.0011, 0.0000])\n",
      ">>>\t epoch 35:: loss = 0.33239874243736267, validation loss = 0.3293601870536804\n",
      "J: 26.186599731445312,  b0: -8.027645111083984, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([0.0032, 0.0000])\n",
      "J: 26.179553985595703,  b0: -8.032793998718262, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([0.0101, 0.0000])\n",
      "J: 26.17000961303711,  b0: -8.04410457611084, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([0.0029, 0.0000])\n",
      "J: 26.16204071044922,  b0: -8.056241989135742, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([0.0071, 0.0000])\n",
      "J: 26.15060806274414,  b0: -8.07186222076416, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([0.0052, 0.0000])\n",
      "J: 26.143699645996094,  b0: -8.089361190795898, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([-0.0183,  0.0000])\n",
      "J: 26.13401222229004,  b0: -8.092988967895508, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0239, 0.0000])\n",
      "J: 26.12407875061035,  b0: -8.112051010131836, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([-0.0064,  0.0000])\n",
      "J: 26.112443923950195,  b0: -8.12496566772461, b1: 10.0\n",
      "JGrad: tensor([-0.0022]),  bGrad: tensor([-0.0150,  0.0000])\n",
      "J: 26.108034133911133,  b0: -8.126703262329102, b1: 10.0\n",
      "JGrad: tensor([-0.0001]),  bGrad: tensor([-0.0025,  0.0000])\n",
      "J: 26.104373931884766,  b0: -8.126608848571777, b1: 10.0\n",
      "JGrad: tensor([-0.0023]),  bGrad: tensor([-0.0137,  0.0000])\n",
      "J: 26.107685089111328,  b0: -8.117484092712402, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([-0.0197,  0.0000])\n",
      "J: 26.10836410522461,  b0: -8.096236228942871, b1: 10.0\n",
      "JGrad: tensor([-0.0042]),  bGrad: tensor([-0.0066,  0.0000])\n",
      ">>>\t epoch 36:: loss = 0.3248071074485779, validation loss = 0.32895389199256897\n",
      "J: 26.120723724365234,  b0: -8.072720527648926, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([-0.0094,  0.0000])\n",
      "J: 26.134275436401367,  b0: -8.045337677001953, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([-0.0059,  0.0000])\n",
      "J: 26.145069122314453,  b0: -8.016725540161133, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([0.0048, 0.0000])\n",
      "J: 26.15703773498535,  b0: -7.994122505187988, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([-0.0051,  0.0000])\n",
      "J: 26.17096710205078,  b0: -7.970365047454834, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.0020]),  bGrad: tensor([0.0203, 0.0000])\n",
      "J: 26.177980422973633,  b0: -7.962503910064697, b1: 10.0\n",
      "JGrad: tensor([0.0026]),  bGrad: tensor([0.0218, 0.0000])\n",
      "J: 26.176939010620117,  b0: -7.969887733459473, b1: 10.0\n",
      "JGrad: tensor([0.0027]),  bGrad: tensor([0.0323, 0.0000])\n",
      "J: 26.168258666992188,  b0: -7.997818470001221, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([0.0143, 0.0000])\n",
      "J: 26.158832550048828,  b0: -8.0324068069458, b1: 10.0\n",
      "JGrad: tensor([4.5139e-09]),  bGrad: tensor([0.0077, 0.0000])\n",
      "J: 26.150339126586914,  b0: -8.068648338317871, b1: 10.0\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([-0.0023,  0.0000])\n",
      "J: 26.13873291015625,  b0: -8.099778175354004, b1: 10.0\n",
      "JGrad: tensor([-0.0024]),  bGrad: tensor([-0.0010,  0.0000])\n",
      "J: 26.135168075561523,  b0: -8.127144813537598, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([-0.0062,  0.0000])\n",
      "J: 26.129474639892578,  b0: -8.14765739440918, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([-0.0075,  0.0000])\n",
      ">>>\t epoch 37:: loss = 0.323941707611084, validation loss = 0.32926779985427856\n",
      "J: 26.127206802368164,  b0: -8.161173820495605, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([-0.0329,  0.0000])\n",
      "J: 26.122835159301758,  b0: -8.151531219482422, b1: 10.0\n",
      "JGrad: tensor([-0.0027]),  bGrad: tensor([-0.0114,  0.0000])\n",
      "J: 26.126543045043945,  b0: -8.135293006896973, b1: 10.0\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([-0.0022,  0.0000])\n",
      "J: 26.13359832763672,  b0: -8.11922550201416, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([-0.0050,  0.0000])\n",
      "J: 26.13556671142578,  b0: -8.101436614990234, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([-0.0133,  0.0000])\n",
      "J: 26.135650634765625,  b0: -8.076621055603027, b1: 10.0\n",
      "JGrad: tensor([-0.0014]),  bGrad: tensor([-0.0043,  0.0000])\n",
      "J: 26.13968276977539,  b0: -8.051405906677246, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([0.0015, 0.0000])\n",
      "J: 26.14016342163086,  b0: -8.02967643737793, b1: 10.0\n",
      "JGrad: tensor([-0.0023]),  bGrad: tensor([-0.0025,  0.0000])\n",
      "J: 26.14728546142578,  b0: -8.008398056030273, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([0.0251, 0.0000])\n",
      "J: 26.15642738342285,  b0: -8.005937576293945, b1: 10.0\n",
      "JGrad: tensor([0.0020]),  bGrad: tensor([0.0245, 0.0000])\n",
      "J: 26.15875244140625,  b0: -8.019989013671875, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0080, 0.0000])\n",
      "J: 26.158668518066406,  b0: -8.03792953491211, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0062, 0.0000])\n",
      "J: 26.15607261657715,  b0: -8.058237075805664, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([0.0014, 0.0000])\n",
      ">>>\t epoch 38:: loss = 0.3233144283294678, validation loss = 0.3289979100227356\n",
      "J: 26.15540313720703,  b0: -8.077474594116211, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([-0.0047,  0.0000])\n",
      "J: 26.152666091918945,  b0: -8.091662406921387, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([-0.0019,  0.0000])\n",
      "J: 26.145503997802734,  b0: -8.103156089782715, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([-0.0011,  0.0000])\n",
      "J: 26.14079475402832,  b0: -8.11276626586914, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([0.0013, 0.0000])\n",
      "J: 26.133037567138672,  b0: -8.122282981872559, b1: 10.0\n",
      "JGrad: tensor([-0.0014]),  bGrad: tensor([-0.0082,  0.0000])\n",
      "J: 26.129995346069336,  b0: -8.125377655029297, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0010,  0.0000])\n",
      "J: 26.128442764282227,  b0: -8.127497673034668, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([-0.0216,  0.0000])\n",
      "J: 26.12407684326172,  b0: -8.114970207214355, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([0.0046, 0.0000])\n",
      "J: 26.12289810180664,  b0: -8.106733322143555, b1: 10.0\n",
      "JGrad: tensor([-0.0019]),  bGrad: tensor([-0.0071,  0.0000])\n",
      "J: 26.12732696533203,  b0: -8.09453010559082, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([0.0005, 0.0000])\n",
      "J: 26.135604858398438,  b0: -8.083868026733398, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([-0.0029,  0.0000])\n",
      "J: 26.138397216796875,  b0: -8.072307586669922, b1: 10.0\n",
      "JGrad: tensor([-0.0019]),  bGrad: tensor([-0.0082,  0.0000])\n",
      "J: 26.146493911743164,  b0: -8.056361198425293, b1: 10.0\n",
      "JGrad: tensor([-0.0044]),  bGrad: tensor([-0.0046,  0.0000])\n",
      ">>>\t epoch 39:: loss = 0.3266347050666809, validation loss = 0.3292182683944702\n",
      "J: 26.166688919067383,  b0: -8.038918495178223, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([0.0059, 0.0000])\n",
      "J: 26.18453025817871,  b0: -8.027195930480957, b1: 10.0\n",
      "JGrad: tensor([0.0022]),  bGrad: tensor([0.0219, 0.0000])\n",
      "J: 26.194108963012695,  b0: -8.031405448913574, b1: 10.0\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([0.0155, 0.0000])\n",
      "J: 26.198589324951172,  b0: -8.045621871948242, b1: 10.0\n",
      "JGrad: tensor([9.8866e-05]),  bGrad: tensor([0.0125, 0.0000])\n",
      "J: 26.202335357666016,  b0: -8.066824913024902, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([0.0095, 0.0000])\n",
      "J: 26.209157943725586,  b0: -8.092342376708984, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0048,  0.0000])\n",
      "J: 26.214786529541016,  b0: -8.112065315246582, b1: 10.0\n",
      "JGrad: tensor([0.0023]),  bGrad: tensor([-0.0107,  0.0000])\n",
      "J: 26.21306800842285,  b0: -8.12258243560791, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([-0.0081,  0.0000])\n",
      "J: 26.21445655822754,  b0: -8.126603126525879, b1: 10.0\n",
      "JGrad: tensor([0.0012]),  bGrad: tensor([-0.0029,  0.0000])\n",
      "J: 26.21219253540039,  b0: -8.128255844116211, b1: 10.0\n",
      "JGrad: tensor([-0.0026]),  bGrad: tensor([-0.0114,  0.0000])\n",
      "J: 26.21771812438965,  b0: -8.122021675109863, b1: 10.0\n",
      "JGrad: tensor([-0.0018]),  bGrad: tensor([-0.0232,  0.0000])\n",
      "J: 26.22808265686035,  b0: -8.100767135620117, b1: 10.0\n",
      "JGrad: tensor([9.9636e-05]),  bGrad: tensor([-0.0049,  0.0000])\n",
      "J: 26.23712730407715,  b0: -8.078303337097168, b1: 10.0\n",
      "JGrad: tensor([-0.0001]),  bGrad: tensor([-0.0160,  0.0000])\n",
      ">>>\t epoch 40:: loss = 0.3296879529953003, validation loss = 0.32932808995246887\n",
      "J: 26.245643615722656,  b0: -8.047281265258789, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0059, 0.0000])\n",
      "J: 26.25201988220215,  b0: -8.023289680480957, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([0.0190, 0.0000])\n",
      "J: 26.254392623901367,  b0: -8.014578819274902, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([0.0046, 0.0000])\n",
      "J: 26.254318237304688,  b0: -8.009872436523438, b1: 10.0\n",
      "JGrad: tensor([0.0019]),  bGrad: tensor([-0.0013,  0.0000])\n",
      "J: 26.248653411865234,  b0: -8.004746437072754, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0059, 0.0000])\n",
      "J: 26.2427921295166,  b0: -8.004156112670898, b1: 10.0\n",
      "JGrad: tensor([0.0021]),  bGrad: tensor([0.0324, 0.0000])\n",
      "J: 26.231115341186523,  b0: -8.025520324707031, b1: 10.0\n",
      "JGrad: tensor([0.0021]),  bGrad: tensor([0.0068, 0.0000])\n",
      "J: 26.214176177978516,  b0: -8.049379348754883, b1: 10.0\n",
      "JGrad: tensor([0.0020]),  bGrad: tensor([-0.0004,  0.0000])\n",
      "J: 26.192893981933594,  b0: -8.070579528808594, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([0.0042, 0.0000])\n",
      "J: 26.17200469970703,  b0: -8.09249210357666, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([-0.0047,  0.0000])\n",
      "J: 26.15834617614746,  b0: -8.109024047851562, b1: 10.0\n",
      "JGrad: tensor([-1.6277e-05]),  bGrad: tensor([-0.0188,  0.0000])\n",
      "J: 26.146087646484375,  b0: -8.111172676086426, b1: 10.0\n",
      "JGrad: tensor([-0.0020]),  bGrad: tensor([-0.0041,  0.0000])\n",
      "J: 26.14095115661621,  b0: -8.110325813293457, b1: 10.0\n",
      "JGrad: tensor([-0.0032]),  bGrad: tensor([-0.0008,  0.0000])\n",
      ">>>\t epoch 41:: loss = 0.32760733366012573, validation loss = 0.32897865772247314\n",
      "J: 26.146080017089844,  b0: -8.109039306640625, b1: 10.0\n",
      "JGrad: tensor([-0.0029]),  bGrad: tensor([-0.0150,  0.0000])\n",
      "J: 26.15934944152832,  b0: -8.09770393371582, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([-0.0048,  0.0000])\n",
      "J: 26.170307159423828,  b0: -8.084198951721191, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([-0.0075,  0.0000])\n",
      "J: 26.183263778686523,  b0: -8.066927909851074, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0153, 0.0000])\n",
      "J: 26.192493438720703,  b0: -8.061772346496582, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0045, 0.0000])\n",
      "J: 26.199758529663086,  b0: -8.060162544250488, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([-0.0034,  0.0000])\n",
      "J: 26.20414924621582,  b0: -8.056402206420898, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([0.0049, 0.0000])\n",
      "J: 26.207509994506836,  b0: -8.056344032287598, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0150, 0.0000])\n",
      "J: 26.209375381469727,  b0: -8.066534996032715, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([-0.0140,  0.0000])\n",
      "J: 26.210094451904297,  b0: -8.066177368164062, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0033,  0.0000])\n",
      "J: 26.212142944335938,  b0: -8.063594818115234, b1: 10.0\n",
      "JGrad: tensor([0.0040]),  bGrad: tensor([0.0181, 0.0000])\n",
      "J: 26.201921463012695,  b0: -8.073652267456055, b1: 10.0\n",
      "JGrad: tensor([-0.0010]),  bGrad: tensor([0.0023, 0.0000])\n",
      "J: 26.195789337158203,  b0: -8.08428955078125, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0135,  0.0000])\n",
      ">>>\t epoch 42:: loss = 0.32902032136917114, validation loss = 0.3290405571460724\n",
      "J: 26.189794540405273,  b0: -8.084630012512207, b1: 10.0\n",
      "JGrad: tensor([-0.0019]),  bGrad: tensor([-0.0010,  0.0000])\n",
      "J: 26.190149307250977,  b0: -8.084218978881836, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0023,  0.0000])\n",
      "J: 26.192462921142578,  b0: -8.082276344299316, b1: 10.0\n",
      "JGrad: tensor([0.0029]),  bGrad: tensor([0.0145, 0.0000])\n",
      "J: 26.185779571533203,  b0: -8.090439796447754, b1: 10.0\n",
      "JGrad: tensor([-9.1738e-05]),  bGrad: tensor([-0.0022,  0.0000])\n",
      "J: 26.180036544799805,  b0: -8.09628963470459, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([0.0012, 0.0000])\n",
      "J: 26.174449920654297,  b0: -8.102398872375488, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([0.0103, 0.0000])\n",
      "J: 26.17047119140625,  b0: -8.114947319030762, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0029,  0.0000])\n",
      "J: 26.168201446533203,  b0: -8.124290466308594, b1: 10.0\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([-0.0134,  0.0000])\n",
      "J: 26.161754608154297,  b0: -8.1234769821167, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0237,  0.0000])\n",
      "J: 26.157352447509766,  b0: -8.106483459472656, b1: 10.0\n",
      "JGrad: tensor([-0.0021]),  bGrad: tensor([-0.0044,  0.0000])\n",
      "J: 26.159936904907227,  b0: -8.088147163391113, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([-0.0158,  0.0000])\n",
      "J: 26.16096305847168,  b0: -8.060761451721191, b1: 10.0\n",
      "JGrad: tensor([4.1314e-05]),  bGrad: tensor([0.0018, 0.0000])\n",
      "J: 26.161760330200195,  b0: -8.037309646606445, b1: 10.0\n",
      "JGrad: tensor([-0.0021]),  bGrad: tensor([0.0039, 0.0000])\n",
      ">>>\t epoch 43:: loss = 0.32459864020347595, validation loss = 0.3294105529785156\n",
      "J: 26.1689453125,  b0: -8.0188570022583, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([0.0043, 0.0000])\n",
      "J: 26.174718856811523,  b0: -8.005230903625488, b1: 10.0\n",
      "JGrad: tensor([0.0013]),  bGrad: tensor([0.0053, 0.0000])\n",
      "J: 26.175989151000977,  b0: -7.9966139793396, b1: 10.0\n",
      "JGrad: tensor([0.0028]),  bGrad: tensor([0.0108, 0.0000])\n",
      "J: 26.168350219726562,  b0: -7.9963178634643555, b1: 10.0\n",
      "JGrad: tensor([-9.2759e-05]),  bGrad: tensor([-0.0034,  0.0000])\n",
      "J: 26.161754608154297,  b0: -7.993695259094238, b1: 10.0\n",
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0117, 0.0000])\n",
      "J: 26.154518127441406,  b0: -7.999419212341309, b1: 10.0\n",
      "JGrad: tensor([0.0030]),  bGrad: tensor([0.0179, 0.0000])\n",
      "J: 26.13875389099121,  b0: -8.016924858093262, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([0.0111, 0.0000])\n",
      "J: 26.125585556030273,  b0: -8.040373802185059, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([0.0124, 0.0000])\n",
      "J: 26.11297607421875,  b0: -8.07007884979248, b1: 10.0\n",
      "JGrad: tensor([-0.0021]),  bGrad: tensor([0.0009, 0.0000])\n",
      "J: 26.10820198059082,  b0: -8.097434043884277, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([0.0034, 0.0000])\n",
      "J: 26.105730056762695,  b0: -8.124417304992676, b1: 10.0\n",
      "JGrad: tensor([-0.0025]),  bGrad: tensor([-0.0016,  0.0000])\n",
      "J: 26.111135482788086,  b0: -8.147615432739258, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([-0.0137,  0.0000])\n",
      "J: 26.114116668701172,  b0: -8.158954620361328, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([-0.0249,  0.0000])\n",
      ">>>\t epoch 44:: loss = 0.32851943373680115, validation loss = 0.32917603850364685\n",
      "J: 26.11465072631836,  b0: -8.151890754699707, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([-0.0146,  0.0000])\n",
      "J: 26.11411476135254,  b0: -8.13542652130127, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([-0.0173,  0.0000])\n",
      "J: 26.118579864501953,  b0: -8.108643531799316, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([0.0057, 0.0000])\n",
      "J: 26.11783790588379,  b0: -8.088495254516602, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([-0.0031,  0.0000])\n",
      "J: 26.116209030151367,  b0: -8.068222999572754, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([-0.0026,  0.0000])\n",
      "J: 26.118179321289062,  b0: -8.04818058013916, b1: 10.0\n",
      "JGrad: tensor([-0.0022]),  bGrad: tensor([0.0055, 0.0000])\n",
      "J: 26.12669563293457,  b0: -8.033937454223633, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([0.0151, 0.0000])\n",
      "J: 26.129459381103516,  b0: -8.031604766845703, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([0.0011, 0.0000])\n",
      "J: 26.133962631225586,  b0: -8.030269622802734, b1: 10.0\n",
      "JGrad: tensor([0.0013]),  bGrad: tensor([0.0012, 0.0000])\n",
      "J: 26.134033203125,  b0: -8.029916763305664, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([-0.0017,  0.0000])\n",
      "J: 26.136024475097656,  b0: -8.028430938720703, b1: 10.0\n",
      "JGrad: tensor([9.8118e-05]),  bGrad: tensor([0.0008, 0.0000])\n",
      "J: 26.137508392333984,  b0: -8.027654647827148, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0194, 0.0000])\n",
      "J: 26.136005401611328,  b0: -8.04051399230957, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([0.0084, 0.0000])\n",
      ">>>\t epoch 45:: loss = 0.3314368724822998, validation loss = 0.32903680205345154\n",
      "J: 26.13612174987793,  b0: -8.057927131652832, b1: 10.0\n",
      "JGrad: tensor([-0.0011]),  bGrad: tensor([0.0069, 0.0000])\n",
      "J: 26.13958740234375,  b0: -8.078400611877441, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0115,  0.0000])\n",
      "J: 26.144256591796875,  b0: -8.088790893554688, b1: 10.0\n",
      "JGrad: tensor([0.0021]),  bGrad: tensor([-0.0076,  0.0000])\n",
      "J: 26.141767501831055,  b0: -8.092851638793945, b1: 10.0\n",
      "JGrad: tensor([0.0002]),  bGrad: tensor([-0.0091,  0.0000])\n",
      "J: 26.13901138305664,  b0: -8.090143203735352, b1: 10.0\n",
      "JGrad: tensor([-0.0022]),  bGrad: tensor([-0.0005,  0.0000])\n",
      "J: 26.143644332885742,  b0: -8.087318420410156, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([-0.0143,  0.0000])\n",
      "J: 26.152917861938477,  b0: -8.07473087310791, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([0.0045, 0.0000])\n",
      "J: 26.16391944885254,  b0: -8.066526412963867, b1: 10.0\n",
      "JGrad: tensor([0.0019]),  bGrad: tensor([0.0130, 0.0000])\n",
      "J: 26.167770385742188,  b0: -8.06826114654541, b1: 10.0\n",
      "JGrad: tensor([0.0010]),  bGrad: tensor([-0.0021,  0.0000])\n",
      "J: 26.168132781982422,  b0: -8.06836986541748, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([-0.0115,  0.0000])\n",
      "J: 26.169418334960938,  b0: -8.060409545898438, b1: 10.0\n",
      "JGrad: tensor([0.0020]),  bGrad: tensor([0.0102, 0.0000])\n",
      "J: 26.164264678955078,  b0: -8.060437202453613, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([0.0007, 0.0000])\n",
      "J: 26.162628173828125,  b0: -8.060919761657715, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([0.0378, 0.0000])\n",
      ">>>\t epoch 46:: loss = 0.3295944631099701, validation loss = 0.32898667454719543\n",
      "J: 26.15955352783203,  b0: -8.087783813476562, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([0.0009, 0.0000])\n",
      "J: 26.159164428710938,  b0: -8.112652778625488, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([-0.0007,  0.0000])\n",
      "J: 26.15937614440918,  b0: -8.134592056274414, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([-0.0024,  0.0000])\n",
      "J: 26.16254425048828,  b0: -8.152664184570312, b1: 10.0\n",
      "JGrad: tensor([-0.0007]),  bGrad: tensor([-0.0048,  0.0000])\n",
      "J: 26.16753578186035,  b0: -8.165569305419922, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0070,  0.0000])\n",
      "J: 26.173479080200195,  b0: -8.172239303588867, b1: 10.0\n",
      "JGrad: tensor([0.0007]),  bGrad: tensor([-0.0126,  0.0000])\n",
      "J: 26.176485061645508,  b0: -8.169379234313965, b1: 10.0\n",
      "JGrad: tensor([-0.0006]),  bGrad: tensor([-0.0091,  0.0000])\n",
      "J: 26.181026458740234,  b0: -8.160387992858887, b1: 10.0\n",
      "JGrad: tensor([-0.0020]),  bGrad: tensor([-0.0143,  0.0000])\n",
      "J: 26.191558837890625,  b0: -8.1422700881958, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([-0.0294,  0.0000])\n",
      "J: 26.203615188598633,  b0: -8.105445861816406, b1: 10.0\n",
      "JGrad: tensor([-0.0004]),  bGrad: tensor([-0.0246,  0.0000])\n",
      "J: 26.21578598022461,  b0: -8.055156707763672, b1: 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JGrad: tensor([0.0004]),  bGrad: tensor([0.0265, 0.0000])\n",
      "J: 26.225587844848633,  b0: -8.028494834899902, b1: 10.0\n",
      "JGrad: tensor([-3.1781e-05]),  bGrad: tensor([-0.0040,  0.0000])\n",
      "J: 26.234521865844727,  b0: -8.001652717590332, b1: 10.0\n",
      "JGrad: tensor([-0.0002]),  bGrad: tensor([0.0067, 0.0000])\n",
      ">>>\t epoch 47:: loss = 0.3249165713787079, validation loss = 0.33011651039123535\n",
      "J: 26.243144989013672,  b0: -7.9821271896362305, b1: 10.0\n",
      "JGrad: tensor([0.0009]),  bGrad: tensor([0.0183, 0.0000])\n",
      "J: 26.24803924560547,  b0: -7.97737455368042, b1: 10.0\n",
      "JGrad: tensor([0.0011]),  bGrad: tensor([0.0216, 0.0000])\n",
      "J: 26.24873161315918,  b0: -7.988150596618652, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([0.0071, 0.0000])\n",
      "J: 26.244260787963867,  b0: -8.002779960632324, b1: 10.0\n",
      "JGrad: tensor([-0.0009]),  bGrad: tensor([0.0019, 0.0000])\n",
      "J: 26.24327278137207,  b0: -8.01728343963623, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([0.0034, 0.0000])\n",
      "J: 26.243379592895508,  b0: -8.032743453979492, b1: 10.0\n",
      "JGrad: tensor([-0.0017]),  bGrad: tensor([0.0059, 0.0000])\n",
      "J: 26.248912811279297,  b0: -8.05078411102295, b1: 10.0\n",
      "JGrad: tensor([8.4811e-05]),  bGrad: tensor([0.0013, 0.0000])\n",
      "J: 26.253620147705078,  b0: -8.067975997924805, b1: 10.0\n",
      "JGrad: tensor([0.0021]),  bGrad: tensor([0.0145, 0.0000])\n",
      "J: 26.251068115234375,  b0: -8.093621253967285, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([0.0011, 0.0000])\n",
      "J: 26.244022369384766,  b0: -8.117511749267578, b1: 10.0\n",
      "JGrad: tensor([0.0016]),  bGrad: tensor([-0.0040,  0.0000])\n",
      "J: 26.232389450073242,  b0: -8.136231422424316, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([-0.0226,  0.0000])\n",
      "J: 26.22687530517578,  b0: -8.137210845947266, b1: 10.0\n",
      "JGrad: tensor([0.0027]),  bGrad: tensor([-0.0055,  0.0000])\n",
      "J: 26.213176727294922,  b0: -8.13426399230957, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0063,  0.0000])\n",
      ">>>\t epoch 48:: loss = 0.32754653692245483, validation loss = 0.3291054964065552\n",
      "J: 26.202592849731445,  b0: -8.127154350280762, b1: 10.0\n",
      "JGrad: tensor([0.0014]),  bGrad: tensor([0.0030, 0.0000])\n",
      "J: 26.18852424621582,  b0: -8.122858047485352, b1: 10.0\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([-0.0135,  0.0000])\n",
      "J: 26.1801700592041,  b0: -8.109511375427246, b1: 10.0\n",
      "JGrad: tensor([6.6981e-05]),  bGrad: tensor([-0.0053,  0.0000])\n",
      "J: 26.17242431640625,  b0: -8.09372615814209, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0004, 0.0000])\n",
      "J: 26.162866592407227,  b0: -8.079808235168457, b1: 10.0\n",
      "JGrad: tensor([0.0015]),  bGrad: tensor([-0.0166,  0.0000])\n",
      "J: 26.149263381958008,  b0: -8.05560302734375, b1: 10.0\n",
      "JGrad: tensor([0.0018]),  bGrad: tensor([0.0114, 0.0000])\n",
      "J: 26.130983352661133,  b0: -8.041813850402832, b1: 10.0\n",
      "JGrad: tensor([-0.0020]),  bGrad: tensor([0.0017, 0.0000])\n",
      "J: 26.121273040771484,  b0: -8.030603408813477, b1: 10.0\n",
      "JGrad: tensor([0.0001]),  bGrad: tensor([0.0125, 0.0000])\n",
      "J: 26.11210060119629,  b0: -8.0293550491333, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([0.0048, 0.0000])\n",
      "J: 26.105432510375977,  b0: -8.031621932983398, b1: 10.0\n",
      "JGrad: tensor([0.0005]),  bGrad: tensor([0.0168, 0.0000])\n",
      "J: 26.097787857055664,  b0: -8.045487403869629, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([-0.0054,  0.0000])\n",
      "J: 26.093530654907227,  b0: -8.054132461547852, b1: 10.0\n",
      "JGrad: tensor([-0.0016]),  bGrad: tensor([-0.0082,  0.0000])\n",
      "J: 26.095029830932617,  b0: -8.05614185333252, b1: 10.0\n",
      "JGrad: tensor([0.0013]),  bGrad: tensor([0.0091, 0.0000])\n",
      ">>>\t epoch 49:: loss = 0.3274191915988922, validation loss = 0.3289346694946289\n",
      "J: 26.091920852661133,  b0: -8.064414978027344, b1: 10.0\n",
      "JGrad: tensor([-0.0013]),  bGrad: tensor([-0.0004,  0.0000])\n",
      "J: 26.093544006347656,  b0: -8.071619987487793, b1: 10.0\n",
      "JGrad: tensor([-0.0015]),  bGrad: tensor([0.0048, 0.0000])\n",
      "J: 26.09994125366211,  b0: -8.08154296875, b1: 10.0\n",
      "JGrad: tensor([0.0003]),  bGrad: tensor([0.0155, 0.0000])\n",
      "J: 26.10460090637207,  b0: -8.10143756866455, b1: 10.0\n",
      "JGrad: tensor([0.0006]),  bGrad: tensor([-0.0164,  0.0000])\n",
      "J: 26.1068172454834,  b0: -8.107691764831543, b1: 10.0\n",
      "JGrad: tensor([-0.0008]),  bGrad: tensor([-0.0134,  0.0000])\n",
      "J: 26.111473083496094,  b0: -8.103801727294922, b1: 10.0\n",
      "JGrad: tensor([-0.0003]),  bGrad: tensor([-0.0008,  0.0000])\n",
      "J: 26.116674423217773,  b0: -8.099737167358398, b1: 10.0\n",
      "JGrad: tensor([-5.8190e-05]),  bGrad: tensor([-0.0044,  0.0000])\n",
      "J: 26.121553421020508,  b0: -8.09296703338623, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([-0.0078,  0.0000])\n",
      "J: 26.123441696166992,  b0: -8.08130931854248, b1: 10.0\n",
      "JGrad: tensor([-0.0005]),  bGrad: tensor([-0.0111,  0.0000])\n",
      "J: 26.126686096191406,  b0: -8.06295108795166, b1: 10.0\n",
      "JGrad: tensor([-0.0012]),  bGrad: tensor([-0.0030,  0.0000])\n",
      "J: 26.133615493774414,  b0: -8.044259071350098, b1: 10.0\n",
      "JGrad: tensor([0.0008]),  bGrad: tensor([0.0060, 0.0000])\n",
      "J: 26.13703727722168,  b0: -8.031720161437988, b1: 10.0\n",
      "JGrad: tensor([8.9843e-05]),  bGrad: tensor([0.0074, 0.0000])\n",
      "J: 26.13981819152832,  b0: -8.025721549987793, b1: 10.0\n",
      "JGrad: tensor([0.0017]),  bGrad: tensor([0.0181, 0.0000])\n",
      ">>>\t epoch 50:: loss = 0.33150070905685425, validation loss = 0.32920241355895996\n"
     ]
    }
   ],
   "source": [
    "learning_curve = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for batch in trainloader:\n",
    "        X_batch, y_batch = Variable(batch['X'], requires_grad=False), Variable(batch['y'], requires_grad=False)\n",
    "        \n",
    "        print('J: {},  b0: {}, b1: {}'.format(j[0], b[0], b[1]))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = belief_propagation_cross_entropy_loss(j, b, X_batch, y_batch, chain_len=T)\n",
    "        loss.backward()\n",
    "        \n",
    "        b.grad.data[1].fill_(0)  # take b[1] as constant\n",
    "        print('JGrad: {},  bGrad: {}'.format(j.grad.data, b.grad.data))\n",
    "    \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        valid = next(iter(validloader))\n",
    "        X_valid, y_valid = Variable(valid['X']), Variable(valid['y']) \n",
    "        with torch.no_grad():\n",
    "            loss_valid = belief_propagation_cross_entropy_loss(j, b, X_valid, y_valid, chain_len=T)\n",
    "\n",
    "        print('>>>\\t epoch {}:: loss = {}, validation loss = {}'. format(epoch, loss, loss_valid))\n",
    "        learning_curve.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': loss,\n",
    "            'loss_valid': loss_valid,\n",
    "            'b': [b.data.clone()[0], b.data.clone()[1]],\n",
    "            'j': j.data.clone()[0],\n",
    "            'b_grad': [b.grad.data.clone()[0], b.grad.data.clone()[1]],\n",
    "            'j_grad': j.grad.data.clone()[0]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([(v['loss'], v['loss_valid']) for v in learning_curve]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a3a2d0240>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([(v['b_grad'][0], v['j_grad'],  v['b_grad'][1]) for v in learning_curve]);\n",
    "title('Gradients of the chain parameters')\n",
    "xlabel('epochs')\n",
    "legend(['b0', 'J'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYZHV97/H3t5fqvWd6m33pYZiBARwGaBYhXhGNoqDiFuOCaLzB5BIv3ItRg7mJSfS5yY1iTOKjouBygwsRcEFMREQM9+pgzzAb9CwwC7P09DLdPb1vVd/7xzk9NnO7p6t7qrqqTn1ez1NPVZ06y/dUV3/q1O/8zjnm7oiISO4ryHQBIiKSGgp0EZGIUKCLiESEAl1EJCIU6CIiEaFAFxGJCAW6YGbXmtmRDCx3sZn90sz6zOyzs5iu0czczIrmuNx+MztnLtOKZDMFumTSrUAnUO3ud87XQt290t33z9fysoGZvd/MnkrxPDOyISDTU6BLJq0GnvM8PLptrr8uMiXX6s1XCvSIMLOPm9n3Thv2eTP7x/DxB8ysJWze2G9mHzrDvNzMzp30/Otm9qlJz280s21m1mNm/9fMNp5hXleb2W/M7GR4f/XEPIFbgI+GTSCvmWLaMjP7rJkdCqd/yszKJo3yHjN70cw6zewTk6a7wsx+FdbXamb/bGaxqdYvXLcvmNmPw/dms5mtnWZdJpp6bjWzY+G875zlcm8zs33AvnDY583ssJn1mtkWM3vFpPE/aWb/amb/Eta208zWm9mfmVl7ON1rJ42/wMzuDZd91Mw+ZWaFZrYB+BLw8vC97gnHLzGzz4TvYZuZfWni/Z3Y+jazj5nZceBr0/2NJYu4u24RuBFs7Q4SNF8AFAKtwFXh8xuAtYABrwzHvTR87VrgyKR5OXDupOdfBz4VPr4UaAeuDJdxC3AQKJmiplqgG7gZKALeFT6vO32+06zTF4BfAMvDZV0NlACNYY1fAcqAi4ERYEM43WXAVeEyG4EW4I6p1i+soQu4Ihz/fuA709QzsdxvAxXAy4AO4DWzWO5j4ftSFg57L1AXTnMncBwoDV/7JDAMvC58/ZvAAeATQDHwh8CBSfP/PvDlsLZFwNPAh8LX3g88ddr6/APww7CeKuBHwP+c9JkYB/4ufM/Lpng/rmXS50a3zN8yXoBuKfxjwlPA+8LHvwu8cIZxvw/cHj5+yT8mZw70LwJ/c9q89gCvnGIZNwNPnzbsV8D7T5/vFNMWAEPAxVO8NhGsKyYNexr4/WnmdQfw8FTrF9bw1UmvvQHYPc18JpZ7/qRh/wu4dxbLvW6Gv2H3xDqHgf7YpNfeCPQDheHzqnCeC4HFBF9qZZPGfxfwRPj4JYFO8MU+AKydNOzlhF8Q4WdilPDLZZpaFehZdlO7WLR8i+Cf+JvAu8PnAJjZ64G/BNYThGU5sHMOy1gN3GJmH540LAYsm2LcZcCh04YdItjinkk9UAq8cIZxjk96PAhUApjZeuBuoIlgPYuALbOdzxkcnvT4EMGWerLLnTwtYZPNfyZ4rxyoJlj3CW2THg8Bne4en/ScsN5lBFvtrWY2MX7B6cubpCGsccuk8Y3gl9CEDncfnmZ6yUJqQ4+WfwWuNbMVwFsIA93MSoAHgc8Ai919IfAowT/wVAYJ/tknLJn0+DDwaXdfOOlW7u7fnmI+xwi+ACZbBRxNYl06CZobpmzPnsEXgd3AOnevBu5i+nWdi5WTHq8iWM9kl3tqB3DYXv4x4PeAmvDvcnKOtR4m2EKvn/R3qXb3C09fbqiT4AvhwknjL3D3yV9mebezOtcp0CPE3TsI2py/RvDTuSV8KUbQDtoBjIdb66+dciaBbcC7wx1q1xO0uU/4CvBHZnalBSrM7AYzq5piPo8C683s3WZWZGbvBC4AHkliXRLAfcDdZrYsrOXl4ZfTTKqAXqDfzM4H/jiJaWbjf5hZuZldCHwA+O4cl1tF0E7dARSZ2V8QbKHPmru3Aj8FPmtm1WZWYGZrzWzib9cGrJjYSRu+v18BPmdmiwDMbLmZvW4uy5fsoECPnm8Br2FSc4u79wH/FXiAoI323QQ7w6ZzO0F7bQ/wHoL29ol5NRPsjPvncF7PE7TP/n/c/QRwI8HOvhPAR4Eb3b0zyXX5CEGz0G8Idlz+Hcl9Zj9CsI59BKH13TOPPmtPEqz348Bn3P2nc1zuvwM/AfYSNN0MM30TSTLeR/Dl/RzB3+Z7wNLwtZ8DzwLHzWzi/f9YuB6/NrNe4GfAebNcprbis4i56+8hkgwzayToZVLs7uOZrSbzzOxNwF+7+6ZM1yIBbaGLyKxZcKDR24DmTNciv6VeLiIyK2a2gKBpaAtBM49kCTW5iIhEhJpcREQiYl6bXOrr672xsXE+FykikvO2bNnS6e4NM403r4He2NhIc7P2oYiIzIaZnX7E9ZTU5CIiEhEKdBGRiFCgi4hEhAJdRCQiFOgiIhGhQBcRiQgFuohIROhcLlmgvXeY51p7GR6LMzQWZ2g0wdBYnOGxOEUFxqWra9i4YgElRYUzz0wkSz3f3seuo728cn0DNRWxmSfIoHjCefpAF2PxBOcvqaKhqoRJV3bKWgr0DNpzvI97frmfH24/ylj8zOfUKSkq4NJVNVx5Ti1XrKnl0lU1lBYr4HPR4Og4BzoHWLagjIXlxUkFRSLhmJEToTLZCx39/HhHKz/e0cqetj4g+CzftGk577t6NRcuW5DhCn/L3dl1tJeHnznKj3Yco6Nv5NRrC8uLWb+4ivOXVLF+cRWXN9Zy3pKprumSWfN6cq6mpibP9yNF3Z1f7T/BPb/czy/2dFBWXMg7L1/JDRuXUllSRFlxIWWxQkqLCykrLmRgZJynD3axeX8Xmw+c4LnWXtyhqMBYsqCU5QvLWFFTzvKaMlYsLGPZwjLKYoWYQYEZRnhvUB4rpLYiRnVpMQUFyYXIeMKJJ5zxRILxePDc3akuK57zF8p4PMHweIKh0eBXyMh4nOGxxEvuR8cTFJhRWGAUFBiF4eOiAqOqtJiaimJqymMp/VLrGhhl2+FuWlr7GBmLM5ZwxsYTjCecsXiCeMJpqCphZW05q2rLWV1XzuKq0qTey66BUX7W0sZPnz3Of+zrZGQ8AUBVSdGp+a2qK2dJdSk9Q2N09A3T1jtCW+8w7X0jdPYH4VJSVEBpcSGlRYWUFgePNyyt5veaVnLVObVnDPznjvXy7adfZOuL3Vy2uoZXrm/g5WvrKI/NbbsunnD6hscYGI0zODJ+6r5/ZJy9bX08sqOV3cf7MIPLV9dyw8alXLismge3HuX7zxxlaCxO0+oabrm6kesvWkKBGQc6+3mutY/njvXS0trL7uPB572+soS6yhgNlSXUV5VQXxljdV0Fl62uob4ymYtYTW1oNM7h7kH+bddxvr/tKPs7BogVFvCq8xu4adNyFpbH2HO8lz1t/ext62Pv8T76RoJT4b9yfQN/fO1arlxz5vc9Fcxsi7s3zTieAn3+PLGnnbt/upedR09SXxnjlpc38t6rVs/q5+fJoTGaD3bxzIs9HO4e5Gj3EEe6h2jrGybZP2WBwcLyGAvLi6ktj1FSXMDASJyh0TgDo+MMjsYZGBk/FTrTqSwpoq4yRl1FjLrKEuoqYsQTHkw/Os7AyDgDI3EGw3lONCPN9GtkNkqKCqgJ16UsVkhxYQGxwgKKCu3U4/JY4an66ipj1FbEqKsoIe7O9sM9PPNiN88c7uHQicGXzLs4nEdRgRErKsDMONE/QmJS+bGiAlbWlLFkQSl1FSXUVsSorwzej9qKGK09Q/z7s208fbCLeMJZtqCU1164hMtW19DWO8zhrkFeDG+Hu4cYHU9gBnUVJSyuLmFxdSmLqkqCn/zA8HiC4fB9HB5LMDgaZ/OBE/QNj9NYV87vXb6St1+6gkXVpUDwa+CR7a186+kX2Xa4h1hRAZtWLGTn0ZMMjcWJFRZw+Zog3K9eW09ZrJDR8URwiwf3I+Nx2ntHONozFNy6g/vjJ4cZT0z/t2xaXcMNG5fy+ouWsmRB6UteOzk4xr9uOcz//vUhDp0YpKa8OPx8JE699+sWVXH+0iqKCwro7B8Jb6N09o+85LPZWFfOZatraWqsoWl1DWvqK+gZGgvG7xulo3+Yzr5guokvyIn7vuHfXqfkqnNquWnTcl5/0VIWlBdPuU7uztGeIX6w7Rj3PXWAEwOjXLpqIf/l2nO57vxFL/lyH4sneL69n+eO9fLssV7ef3Ujq+rKp5zvTBToWeaZF7t5+5d+xaracv7wFefw1kuXp3TrcnQ8wfGTwxztGWI0nsDdcQfHSSQg4UHQdg+O0j0wStfgKN0DY3QPjjIynqA8VkhFrIjykt/elxUHATmxZVxUYBQWFmAEXyyd/SOc6B+layD4ZzkxMEpRgVEeK6SypIjyWBEVJUVUhPOa/MujrDjYwiwpLgy3OMPH4X2ssICEOwkPfiFMvvUOj9E9GNTeMzhG98Ao3YNjp7bsJ7aoJ0JpYGScroHRab9IFlWVcMmqhVyyqoZNKxdy0fIFVMQKp9zqGosnONYzxItdgxw6Mcjh8L69b5gTA6N09Y+e2oKbcO6iSq6/cAmvu3AJFy2vnnZrLpFweobGqC4toqgw+f4KQ6NxfrKrle/85jBPH+iisMC47vxFLK4u4QfPHKNvZJxzF1XyritW8bZLg63OkfE4zQe7eXJvB0/u6TjVHHImBQZLqktZXhP8Ely+sIy6yhIqSwopjxWFf/NCKkqKWFRdwqKq0hnnmUg4T+7t4Ifbj1FbEeOCpdVcsKyatQ2VxIqmfg/cPfwV0E/zwS6aD3Wz5VA3XQOjZ1xWrKiARVW//ZJcXF1KQ3h/9do6li0sm7HeyYbH4jzQfJgvP7mfoz1DnLe4ijdtWsbhrkGePdbLnrY+RsMvntLiAr743st41XmLZrWMCSkLdDNbCXyT4MrvCeAed/98+NqHgT8huNDtj939o2eaV74Gev/IOG/4/H8QTziP3v4KFpRN/e0v6ePu9I2Mh19AwRdRwmHjigUsXVCa0p/Mw2NxugaCL7qKkiLW1FekbN4zeaGjnweaD/PgliP0Do9zw8uW8q4rVnF5Y80Z17H15BC/OdiNu1NSVECsqIBYYWFwX1RAXUWMJQtKKZ7FF818cnf2dw6w5WA3h7sHqauIUV9VcqqJpqGqhKqSorQ0jYzFEzyy4xhf/MUL7G3rZ2F5MRcuq+bCZQvC+2rW1FdSmETT3HRSGehLgaXuvjW8svsW4CZgMfAJ4AZ3HzGzRe7efqZ55Wug//cHtvH9Z47y3Q+9nMsbazNdjuSBsXiwz6Msph3n8yWRcLoGR6mriKX8iyPZQJ9xb4i7twKt4eM+M2sBlhNc+f1v3X0kfO2MYZ6vfrDtKA9tPcrtr16nMJd5U1xYgDpBza+CAjurHbQpqWE2I4dXPb8E2AysB15hZpvN7Ekzu3yaaW41s2Yza+7o6DjbenPK4a5B/vzhXVy2uoYPX3dupssRkYhLOtDNrBJ4ELjD3XsJtu5rgKuAPwUesCl+Z7j7Pe7e5O5NDQ0zXnAjMsbjCe747jYA/uGdm2a1k0tEZC6SShkzKyYI8/vd/aFw8BHgIQ88TbDDtD49Zeaef/r582w51M2n3nIRK2vn1lVJRGQ2Zgz0cKv7XqDF3e+e9NL3gevCcdYDMaAzHUXmmt8c7OKffr6Pt16ynDdvWp7pckQkTyRziNg1wM3ATjPbFg67C7gPuM/MdgGjwC0+n53as9TwWJw7vrONFTXl/NWbL8x0OSKSR5Lp5fIUMF0fnPemtpzc9/Pd7RztGeJrH7icqlL1NxeR+aM9dSn2yI5j1FfGeMW52p0gIvNLgZ5C/SPjPN7SzhtetlS9WkRk3il1UujxljZGxhPcuHFZpksRkTykQE+hH20/xpLqUppW12S6FBHJQwr0FDk5OMaTezu4cePSpM6PLSKSagr0FPn3544zFnduvFjNLSKSGQr0FHlkRysra8u4eEX2XFJLRPKLAj0FTvSP8H+e7+TGjcty7pqPIhIdCvQU+Mmu48QTzhvVu0VEMkiBngKP7DjG2oYKNizNvquAi0j+UKCfpbbeYTYf6FJzi4hknAL9LD26sxV3eOPFSzNdiojkOQX6WfrR9mOcv6SKcxepuUVEMkuBfhaOdA+y9cUe3qi+5yKSBRToZ+HHO1oB1LtFRLKCAv0sPLKjlYtXLGBVnS4xJyKZp0Cfo4OdA+w8elLNLSKSNZK5puhKM3vCzFrM7Fkzuz0c/kkzO2pm28LbG9JfbvZ46vng8qm/e8HiDFciIhJI5pqi48Cd7r7VzKqALWb2WPja59z9M+krL3ttP9xDbUWMVbVqbhGR7JDMNUVbgdbwcZ+ZtQB5fyn7HUdOcvGKBTqYSESyxqza0M2sEbgE2BwO+hMz22Fm95nZlFd1MLNbzazZzJo7OjrOqthsMTAyzr72PjauWJjpUkRETkk60M2sEngQuMPde4EvAmuBTQRb8J+dajp3v8fdm9y9qaGhIQUlZ96uoydJOGxaqUAXkeyRVKCbWTFBmN/v7g8BuHubu8fdPQF8BbgifWVml+1HegDYqHOfi0gWSaaXiwH3Ai3ufvek4ZNPXvIWYFfqy8tO24+cZEVNGXWVJZkuRUTklGR6uVwD3AzsNLNt4bC7gHeZ2SbAgYPAh9JSYRbafriHi9V+LiJZJpleLk8BU3XleDT15WS/E/0jHOke4n0vX53pUkREXkJHis7SjiMnAbSFLiJZR4E+S9uP9FBgcNFy7RAVkeyiQJ+l7Yd7WLeoioqSZHY/iIjMHwX6LLg724+cVHdFEclKCvRZONI9RNfAKBfrgCIRyUIK9FmYOKBIO0RFJBsp0Gdhx5GTxIoKOG+Jrh8qItlHgT4L2w73cMHSamJFettEJPsomZIUTzi7jp7UCblEJGsp0JP0fHs/g6Nx9XARkaylQE/SqR2i2kIXkSylQE/S9sM9VJUUsaauItOliIhMSYGepB1HTrJx5QIKCnTJORHJTgr0JAyPxWlp7dUl50QkqynQk9DS2st4wnVAkYhkNQV6ErYfntghqh4uIpK9FOhJ2H7kJIuqSlhSXZrpUkREpqVAT8L2Iz1sXLGQ4PKqIiLZKZmLRK80syfMrMXMnjWz2097/SNm5mZWn74yM+fk0Bj7OwbYpOYWEclyyVylYRy40923mlkVsMXMHnP358xsJfC7wItprTKDdh0NLjmnHi4iku1m3EJ391Z33xo+7gNagOXhy58DPgp42irMsIkjRHXIv4hku1m1oZtZI3AJsNnM3gQcdfftM0xzq5k1m1lzR0fHnAvNlOeO9bKipoyF5bFMlyIickZJB7qZVQIPAncQNMN8AviLmaZz93vcvcndmxoaGuZcaKbsOd7H+UuqM12GiMiMkgp0MysmCPP73f0hYC2wBthuZgeBFcBWM1uSrkIzYXgszv7OATYs1QUtRCT7zbhT1IK+evcCLe5+N4C77wQWTRrnINDk7p1pqjMjnm/vJ55wXaFIRHJCMlvo1wA3A9eZ2bbw9oY015UV9hzvA1CTi4jkhBm30N39KeCMR9S4e2OqCsomu4/3EisqoLGuPNOliIjMSEeKnsHu432sX1xJUaHeJhHJfkqqM9itHi4ikkMU6NM40T9CR98I52uHqIjkCAX6NLRDVERyjQJ9Gi1hoKvLoojkCgX6NPYc76W+MkZDVUmmSxERSYoCfRq7j/dp61xEcooCfQrxhLO3TT1cRCS3KNCncOjEAMNjCfVwEZGcokCfwm71cBGRHKRAn8Lu430UGKxbXJnpUkREkqZAn8Lu1l4a6ysoLS7MdCkiIklToE9hT1sfG9TcIiI5RoF+moGRcQ6dGNQOURHJOQr00+xp0xGiIpKbFOinmTiHy4alanIRkdyiQD/N7tZeKmKFLF9YlulSRERmZcZAN7OVZvaEmbWY2bNmdns4/G/MbEd4Sbqfmtmy9JebfhOH/BcUnPEiTSIiWSeZLfRx4E533wBcBdxmZhcAf+/uG919E/AI8BdprHNeuHsY6GpuEZHcM2Ogu3uru28NH/cBLcByd++dNFoF4Okpcf609Y5wcmiMDUu1Q1REcs+MF4mezMwagUuAzeHzTwPvA04Cr5pmmluBWwFWrVo190rnQcvx4DtKh/yLSC5KeqeomVUCDwJ3TGydu/sn3H0lcD/wJ1NN5+73uHuTuzc1NDSkoua02d0adllcrC10Eck9SQW6mRUThPn97v7QFKN8C3hbKgvLhD3He1m2oJQF5cWZLkVEZNaS6eViwL1Ai7vfPWn4ukmjvQnYnfry5pcuaiEiuSyZNvRrgJuBnWa2LRx2F/BBMzsPSACHgD9KT4nzY3Q8wQsd/bzq/EWZLkVEZE5mDHR3fwqYqlP2o6kvJ3P2d/YzFnedw0VEcpaOFA1N7BBVDxcRyVUK9NDu430UFxrnNFRkuhQRkTlRoIf2HO9lbUMlxYV6S0QkNym9Qi90DHDuIl1yTkRylwIdGBmPc6R7kHMaFOgikrsU6MChE4MkHNaq/VxEcpgCHdjf0Q/AOfXaQheR3KVAJ2g/B1ijLXQRyWEKdGB/xwCLqkqoLJnVySdFRLKKAh040Nmv/ucikvMU6MD+zgH1cBGRnJf3gd41MErP4Bjn1GsLXURyW94H+kQPl7XaQheRHKdAD3u4qA1dRHJd3gf6C539FBcayxeWZboUEZGzkveBfqBjgNV1FRTppFwikuPyPsX2dw5oh6iIREIy1xRdaWZPmFmLmT1rZreHw//ezHab2Q4ze9jMFqa/3NQajyc4dEJdFkUkGpLZQh8H7nT3DcBVwG1mdgHwGHCRu28E9gJ/lr4y0+NI9xBjcdcOURGJhBkD3d1b3X1r+LgPaAGWu/tP3X08HO3XwIr0lZke+zsnuiwq0EUk982qDd3MGoFLgM2nvfQHwE9SU9L8meiyuEZnWRSRCEg60M2sEngQuMPdeycN/wRBs8z900x3q5k1m1lzR0fH2dabUvs7B1hYXkxtRSzTpYiInLWkAt3MignC/H53f2jS8FuAG4H3uLtPNa273+PuTe7e1NDQkIqaU2Z/R796uIhIZCTTy8WAe4EWd7970vDrgY8Bb3L3wfSVmD77O9TDRUSiI5kTgF8D3AzsNLNt4bC7gH8ESoDHgszn1+7+R2mpMg36hsdo7xtRDxcRiYwZA93dnwJsipceTX058+dAZ3gOF+0QFZGIyNsjRXVSLhGJmvwN9M4BCgxW15VnuhQRkZTI30Dv6GdFTTklRYWZLkVEJCXyONAH1NwiIpGSl4GeSDgHOge0Q1REIiUvA/147zBDY3FtoYtIpORloJ/q4aKjREUkQvIy0A+EZ1nUUaIiEiV5GegvdAxQEStkcXVJpksREUmZvAz0/Z0DrGmoIDxlgYhIJORnoHf0q4eLiERO3gX68Ficoz1D6uEiIpGTd4F+6MQg7rBGPVxEJGLyLtD3d0xcR1RNLiISLfkX6J0T1xHVFrqIREveBfoLHf0sqS6loiSZa3uIiOSOvAt0nZRLRKIqrwLd3dnf0a/mFhGJpGQuEr3SzJ4wsxYze9bMbg+HvyN8njCzpvSXevY6+kboHR5n3SLtEBWR6EmmIXkcuNPdt5pZFbDFzB4DdgFvBb6czgJTaW9b0MNl/eKqDFciIpJ6yVwkuhVoDR/3mVkLsNzdHwNy6vD5vW19AKxToItIBM2qDd3MGoFLgM2zmOZWM2s2s+aOjo7ZVZdi+9r7qCkvpr4yltE6RETSIelAN7NK4EHgDnfvTXY6d7/H3ZvcvamhoWEuNabMnuN9rFtclVO/KkREkpVUoJtZMUGY3+/uD6W3pPRwd/a19bN+sXaIikg0JdPLxYB7gRZ3vzv9JaXH8d5h+kbGtUNURCIrmV4u1wA3AzvNbFs47C6gBPgnoAH4sZltc/fXpafMszfRw2XdIgW6iERTMr1cngKma3R+OLXlpM++sIeLmlxEJKry5kjRvW191FXEqKvUZedEJJryKND7WaetcxGJsLwIdHfn+fZ+7RAVkUjLi0A/dnKY/pFxHSEqIpGWF4E+ccj/ep2US0QiLC8C/bc9XLSFLiLRlReBvretn/rKEmoqdA4XEYmuvAj0fW196n8uIpEX+UBPJJx96uEiInkg8oF+tGeIwdG4+qCLSORFPtD3tWuHqIjkh8gH+qnLzumkXCIScXkQ6H0sqiphQXlxpksREUmryAd6cFELbZ2LSPRFOtATieAcLtohKiL5INKBfqR7iKGxuLbQRSQvRDrQ9+qiFiKSR5K5puhKM3vCzFrM7Fkzuz0cXmtmj5nZvvC+Jv3lzs7esMviuerhIiJ5IJkt9HHgTnffAFwF3GZmFwAfBx5393XA4+HzrLKvrZ8l1aUsKFMPFxGJvhkD3d1b3X1r+LgPaAGWA28GvhGO9g3gpnQVOVd72/q0Q1RE8sas2tDNrBG4BNgMLHb3VghCH1g0zTS3mlmzmTV3dHScXbWzEE/oKkUikl+SDnQzqwQeBO5w995kp3P3e9y9yd2bGhoa5lLjnBzuGmRkPKEdoiKSN5IKdDMrJgjz+939oXBwm5ktDV9fCrSnp8S5mejhosvOiUi+SKaXiwH3Ai3ufvekl34I3BI+vgX4QerLm7t97cE5XNbpsnMikieKkhjnGuBmYKeZbQuH3QX8LfCAmX0QeBF4R3pKnJu9bX0sW1BKVal6uIhIfpgx0N39KcCmefnVqS0ndfa29au5RUTySiSPFI0nnBc6+rVDVETySiQD/UDnAKPjCW2hi0heiWSgNx/sAuDSVVl3NgIRkbSJZKBvPtBFfWWMtQ0VmS5FRGTeRC7Q3Z3N+09wxZpagh6XIiL5IXKBfqR7iGMnh7lyTV2mSxERmVeRC/Rf7z8BwJXn1Ga4EhGR+RW5QN98oIuF5cWs1znQRSTPRDDQT3BFYy0FBWo/F5H8EqlAP9YzxOGuIa48R+3nIpJ/IhXomw+E7edr1H4uIvknWoG+v4uq0iI2LK3OdCkiIvMuWoF+oIsrGmspVPu5iOShyAR6e+8wBzoH1F1RRPJWZAL91weC87fogCIRyVeRCfTN+09QWVLEhcvUfi6D6+FvAAAHm0lEQVQi+Sk6gX6gi8tW11BUGJlVEhGZlUikX2f/CM+396v9XETyWjIXib7PzNrNbNekYReb2a/MbKeZ/cjMMtrO8bTaz0VEktpC/zpw/WnDvgp83N1fBjwM/GmK65qVzftPUFZcyMYVCzJZhohIRs0Y6O7+S6DrtMHnAb8MHz8GvC3Fdc3KRPt5sdrPRSSPzTUBdwFvCh+/A1g53YhmdquZNZtZc0dHxxwXN72ewVH2tPXpcH8RyXtzDfQ/AG4zsy1AFTA63Yjufo+7N7l7U0NDwxwXN72nD3Thjk7IJSJ5r2guE7n7buC1AGa2HrghlUXNxuYDXZQUFXDxSrWfi0h+m1Ogm9kid283swLgz4Evpbasl/rW5hdpPtjFqzcs5j+tr6eqtPjUa5sPnOCSVQspKSpMZwkiIllvxkA3s28D1wL1ZnYE+Eug0sxuC0d5CPha2ioEeoZG+fmedh565ijFhcaVa+q47vxFXHlOLc8d6+XD161L5+JFRHKCufu8Laypqcmbm5vnNO14PMHWF3t4vKWNn7W08ULHwKnXvvWHV3L12vpUlSkiklXMbIu7N8003pyaXDKhqLCAK9bUcsWaWv7sDRs42DnA47vbOdYzxOWN6uEiIpIzgX66xvoKPvg7azJdhohI1tCROCIiEaFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJdRCQi5vXQfzPrAA7NcfJ6oDOF5eQKrXf+ydd113pPb7W7z3j+8XkN9LNhZs3JnMsgarTe+Sdf113rffbU5CIiEhEKdBGRiMilQL8n0wVkiNY7/+Trumu9z1LOtKGLiMiZ5dIWuoiInIECXUQkInIi0M3sejPbY2bPm9nHM11PupjZfWbWbma7Jg2rNbPHzGxfeF+TyRrTwcxWmtkTZtZiZs+a2e3h8Eivu5mVmtnTZrY9XO+/CoevMbPN4Xp/18xima41Hcys0MyeMbNHwueRX28zO2hmO81sm5k1h8NS9jnP+kA3s0LgC8DrgQuAd5nZBZmtKm2+Dlx/2rCPA4+7+zrg8fB51IwDd7r7BuAq4Lbwbxz1dR8BrnP3i4FNwPVmdhXwd8DnwvXuBj6YwRrT6XagZdLzfFnvV7n7pkl9z1P2Oc/6QAeuAJ539/3uPgp8B3hzhmtKC3f/JdB12uA3A98IH38DuGlei5oH7t7q7lvDx30E/+TLifi6e6A/fFoc3hy4DvheODxy6w1gZiuAG4Cvhs+NPFjvaaTsc54Lgb4cODzp+ZFwWL5Y7O6tEAQfsCjD9aSVmTUClwCbyYN1D5sdtgHtwGPAC0CPu4+Ho0T18/4PwEeBRPi8jvxYbwd+amZbzOzWcFjKPue5cJFom2KY+lpGkJlVAg8Cd7h7b7DRFm3uHgc2mdlC4GFgw1SjzW9V6WVmNwLt7r7FzK6dGDzFqJFa79A17n7MzBYBj5nZ7lTOPBe20I8AKyc9XwEcy1AtmdBmZksBwvv2DNeTFmZWTBDm97v7Q+HgvFh3AHfvAX5BsA9hoZlNbGxF8fN+DfAmMztI0IR6HcEWe9TXG3c/Ft63E3yBX0EKP+e5EOi/AdaFe8BjwO8DP8xwTfPph8At4eNbgB9ksJa0CNtP7wVa3P3uSS9Fet3NrCHcMsfMyoDXEOw/eAJ4ezha5Nbb3f/M3Ve4eyPB//PP3f09RHy9zazCzKomHgOvBXaRws95ThwpamZvIPgGLwTuc/dPZ7iktDCzbwPXEpxOsw34S+D7wAPAKuBF4B3ufvqO05xmZr8D/Aewk9+2qd5F0I4e2XU3s40EO8EKCTauHnD3vzazcwi2XGuBZ4D3uvtI5ipNn7DJ5SPufmPU1ztcv4fDp0XAt9z902ZWR4o+5zkR6CIiMrNcaHIREZEkKNBFRCJCgS4iEhEKdBGRiFCgi4hEhAJd5AzM7NqJswGKZDsFuohIRCjQJRLM7L3hucW3mdmXw5Ne9ZvZZ81sq5k9bmYN4bibzOzXZrbDzB6eOP+0mZ1rZj8Lz0++1czWhrOvNLPvmdluM7s/PLIVM/tbM3sunM9nMrTqIqco0CXnmdkG4J0EJz7aBMSB9wAVwFZ3vxR4kuDIW4BvAh9z940ER6dODL8f+EJ4fvKrgdZw+CXAHQTn4z8HuMbMaoG3ABeG8/lUetdSZGYKdImCVwOXAb8JT0X7aoLgTQDfDcf5F+B3zGwBsNDdnwyHfwP4T+E5Npa7+8MA7j7s7oPhOE+7+xF3TwDbgEagFxgGvmpmbwUmxhXJGAW6RIEB3wivArPJ3c9z909OMd6ZznNxpnP1Tj6fSBwoCs/bfQXBGSJvAv5tljWLpJwCXaLgceDt4TmmJ67RuJrg8z1x9r53A0+5+0mg28xeEQ6/GXjS3XuBI2Z2UziPEjMrn26B4bnbF7j7owTNMZvSsWIis5ELF7gQOSN3f87M/pzgSjAFwBhwGzAAXGhmW4CTBO3sEJyi9EthYO8HPhAOvxn4spn9dTiPd5xhsVXAD8yslGDr/r+leLVEZk1nW5TIMrN+d6/MdB0i80VNLiIiEaEtdBGRiNAWuohIRCjQRUQiQoEuIhIRCnQRkYhQoIuIRMT/A1h2Bf7qkg3MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([v['j'] for v in learning_curve]);\n",
    "title('value of chain parameter J')\n",
    "xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([v['b'][0] for v in learning_curve]);\n",
    "title('value of chain parameter b0')\n",
    "xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = belief_propagation_cross_entropy_loss(j, b, X_test, torch.Tensor(y_test), chain_len=T, train=False)\\\n",
    "    .detach()\\\n",
    "    .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.93      0.74      3661\n",
      "           1       0.94      0.66      0.78      6339\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     10000\n",
      "   macro avg       0.78      0.80      0.76     10000\n",
      "weighted avg       0.82      0.76      0.76     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : 0, 1: 1}\n",
    "\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2c9cca20>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(200)\n",
    "plot(X_test[i], 'o')\n",
    "plot(y_test[i] + 0.05, 'ro')\n",
    "plot(y_pred[i] + 0.1, 'ko')\n",
    "legend(['observations', 'labels', 'NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity - check that we can reach loss zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(1000)\n",
    "j = [2.5] #[1]\n",
    "b = [-0.8, 1.]\n",
    "labels = y_dataset[ind]\n",
    "observations = X_dataset[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50,), (50,))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape, observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.expand_dims(labels, axis=0)\n",
    "observations = np.expand_dims(observations, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = torch.Tensor(j)\n",
    "b = torch.Tensor(b)\n",
    "labels = torch.Tensor(labels)\n",
    "observations = torch.Tensor(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 ms, sys: 1.31 ms, total: 16.3 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)\n",
    "beliefs = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T, train=False)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4884),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]], dtype=torch.uint8),\n",
       " tensor(1, dtype=torch.uint8))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, torch.eq(labels, beliefs.float()), torch.all(torch.eq(labels, beliefs.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Plot the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  target loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4877), 1)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = [2.5]\n",
    "b = [-0.8, 1.]\n",
    "\n",
    "len_ = len(X_train[:10])\n",
    "\n",
    "j = torch.Tensor(j)\n",
    "b = torch.Tensor(b)\n",
    "\n",
    "observations = torch.Tensor(X_train[:10])\n",
    "labels = torch.Tensor(y_train[:10])\n",
    "\n",
    "target_loss = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)\n",
    "beliefs = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T, train=False)\n",
    "\n",
    "target_loss, int(torch.all(torch.eq(labels, beliefs.float())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = progressbar.ProgressBar(maxval=3000, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "res = {'b0': [], 'b1': [], 'j': [], 'loss': [], 'zero_one_loss': []}\n",
    "\n",
    "bar.start()\n",
    "for i_sample in range(3000):\n",
    "    bar.update(i_sample + 1)\n",
    "    j_val = 2.5 + 5 * (np.random.rand() - 0.5)\n",
    "    b_base = [2 * (np.random.rand() - 0.5) , 1]\n",
    "  \n",
    "    j = torch.Tensor([j_val])\n",
    "    b = torch.Tensor(b_base)\n",
    "    \n",
    "    labels = torch.Tensor(y_train[:10])\n",
    "    observations = torch.Tensor(X_train[:10])\n",
    "    \n",
    "    res['b0'].append(b_base[0])\n",
    "    res['b1'].append(b_base[1])\n",
    "    res['j'].append(j_val)\n",
    "    res['loss'].append(float(belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)))\n",
    "    \n",
    "    beliefs = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T, train=False)\n",
    "    res['zero_one_loss'].append(int(torch.all(torch.eq(labels, beliefs.float()))))\n",
    "    \n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2995\n",
       "1       5\n",
       "Name: zero_one_loss, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.zero_one_loss.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "        x=df['b0'],\n",
    "        y=df['j'], \n",
    "        z=df['loss'], \n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=df['zero_one_loss'],                # set color to an array/list of desired values\n",
    "            colorscale='Viridis',   # choose a colorscale\n",
    "            opacity=0.8\n",
    "        ),\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "scene = go.layout.Scene(\n",
    "        annotations=[\n",
    "            dict(\n",
    "                x=-.8,\n",
    "                y=2.5,\n",
    "                z=target_loss,\n",
    "                text=\"target\",\n",
    "                textangle=0,\n",
    "                ax=0,\n",
    "                ay=-75,\n",
    "                font=dict(\n",
    "                    color=\"red\",\n",
    "                    size=18\n",
    "                ),\n",
    "                arrowcolor=\"red\",\n",
    "                arrowsize=3,\n",
    "                arrowwidth=1,\n",
    "                arrowhead=1\n",
    "        )],\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(trace)\n",
    "fig.update_layout(scene=scene)\n",
    "fig.write_html('loss_vs_data_term.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
