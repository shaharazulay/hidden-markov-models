{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _chain import Chain\n",
    "from _pytorch_chain_loss import belief_propagation_cross_entropy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Binary HMM "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ">>> phi(x,_i y_i) represents the data term\n",
    ">>> phi(y_i, y_i+1) represents the smoothness term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_phi(x1, x2):\n",
    "#     p = np.array([\n",
    "#     [0.58, 0.42],\n",
    "#     [0.42, 0.58]])\n",
    "#     return p[x1, x2]\n",
    "    b = [-0.32, 0.4]\n",
    "    return np.round(exp(b[x2] * (x1 - 0.5)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_psi(x1, x2):\n",
    "#     p = np.array([\n",
    "#     [0.62, 0.38],\n",
    "#     [0.34, 0.66]])\n",
    "#     return p[x1, x2]\n",
    "    j = 1\n",
    "    return np.round(exp(j * (x1 - 0.5) * (x2 - 0.5)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = f_phi\n",
    "psi = f_psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50 # chain length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = Chain(length=T, phi=phi, psi=psi, possible_values=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Random Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_values = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.72 s, sys: 21.4 ms, total: 5.74 s\n",
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "X_dataset = []\n",
    "y_dataset= []\n",
    "\n",
    "for i in range(N):\n",
    "    x = np.random.rand(T)\n",
    "    x_binary = 1 * (x > 0.5)\n",
    "    \n",
    "    chain.update_observed(x_binary)\n",
    "    y = chain.get_max_apostriori_beliefs()\n",
    "\n",
    "    X_dataset.append(x_binary)\n",
    "    y_dataset.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn to numpy arrays\n",
    "X_dataset = np.array([np.array(xi) for xi in X_dataset])\n",
    "y_dataset = np.array([np.array(yi) for yi in y_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a27677080>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(X_dataset[0], 'o')\n",
    "plot(y_dataset[0] + 0.05, 'ro')\n",
    "legend(['observations', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dummy Model (predicts y = x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.79      0.69      3903\n",
      "           1       0.84      0.69      0.75      6097\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     10000\n",
      "   macro avg       0.73      0.74      0.72     10000\n",
      "weighted avg       0.75      0.73      0.73     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : 0, 1: 1}\n",
    "\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    features = [\n",
    "        'x.current=' + str(x)\n",
    "    ]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(y):\n",
    "    return str(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for xseq, yseq in zip(X_dataset, y_dataset):\n",
    "    X_features = [extract_features(x_i) for x_i in xseq]\n",
    "    y_labels = [extract_labels(y_i) for y_i in yseq]\n",
    "    \n",
    "    X.append(X_features)\n",
    "    y.append(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 193 ms, sys: 4.04 ms, total: 197 ms\n",
      "Wall time: 197 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0,\n",
    "    c2=0,  # regulate this up to 1 if needed\n",
    "    max_iterations=5000,\n",
    "    all_possible_transitions=True,\n",
    "    all_possible_states=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      3812\n",
      "           1      1.000     1.000     1.000      6188\n",
      "\n",
      "   micro avg      1.000     1.000     1.000     10000\n",
      "   macro avg      1.000     1.000     1.000     10000\n",
      "weighted avg      1.000     1.000     1.000     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions:\n",
      "1      -> 1       342.563882\n",
      "0      -> 0       302.655716\n",
      "1      -> 0       -321.898039\n",
      "0      -> 1       -323.321560\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States:\n",
      "231.897001 1        x.current=1\n",
      "222.593344 0        x.current=0\n",
      "-222.593344 1        x.current=0\n",
      "-231.897001 0        x.current=1\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"States:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training FC NN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "batch_size, D_in, D_hidden, D_out = 256, T, T, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_out),\n",
    "          torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network has 15300 parameters, notice your training set size!\n"
     ]
    }
   ],
   "source": [
    "print('Network has {} parameters, notice your training set size!'.format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, flatten=True):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'X': torch.from_numpy(self._X[idx]).float(),\n",
    "            'y': torch.from_numpy(self._y[idx]).float()  \n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ChainDataset(X_train, y_train)\n",
    "testset = ChainDataset(X_test, y_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10:: loss = 0.6386070847511292, validation loss = 0.6420876383781433\n",
      "epoch 20:: loss = 0.5417201519012451, validation loss = 0.5618528723716736\n",
      "epoch 30:: loss = 0.4871368110179901, validation loss = 0.543056070804596\n",
      "epoch 40:: loss = 0.4642716944217682, validation loss = 0.5319937467575073\n",
      "epoch 50:: loss = 0.426086962223053, validation loss = 0.5039685964584351\n",
      "epoch 60:: loss = 0.3601410984992981, validation loss = 0.4992850124835968\n",
      "epoch 70:: loss = 0.3880794942378998, validation loss = 0.5033949017524719\n",
      "epoch 80:: loss = 0.3555992841720581, validation loss = 0.5435436964035034\n",
      "epoch 90:: loss = 0.30707454681396484, validation loss = 0.5567889213562012\n",
      "epoch 100:: loss = 0.3293323814868927, validation loss = 0.5889564156532288\n",
      "epoch 110:: loss = 0.2705768644809723, validation loss = 0.620589554309845\n",
      "epoch 120:: loss = 0.26991507411003113, validation loss = 0.6075847148895264\n",
      "epoch 130:: loss = 0.2661522924900055, validation loss = 0.6937414407730103\n",
      "epoch 140:: loss = 0.2466992884874344, validation loss = 0.642142653465271\n",
      "epoch 150:: loss = 0.23383773863315582, validation loss = 0.6901923418045044\n",
      "epoch 160:: loss = 0.2348562777042389, validation loss = 0.7198590636253357\n",
      "epoch 170:: loss = 0.20908235013484955, validation loss = 0.7527441382408142\n",
      "epoch 180:: loss = 0.16872523725032806, validation loss = 0.742645263671875\n",
      "epoch 190:: loss = 0.18181857466697693, validation loss = 0.839095413684845\n",
      "epoch 200:: loss = 0.1568867713212967, validation loss = 0.8617414832115173\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "learning_curve = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for batch in trainloader:\n",
    "        \n",
    "        X_batch, y_batch = Variable(batch['X']), Variable(batch['y'])\n",
    "        model.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        loss = F.binary_cross_entropy(y_pred, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        valid = next(iter(validloader))\n",
    "        X_valid, y_valid = Variable(valid['X']), Variable(valid['y']) \n",
    "        y_pred_valid = model(X_valid)\n",
    "        loss_valid = F.binary_cross_entropy(y_pred_valid, y_valid)\n",
    "        \n",
    "        print('epoch {}:: loss = {}, validation loss = {}'. format(epoch, loss, loss_valid))\n",
    "        learning_curve.append((loss, loss_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a2d73e5c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XlclOX+//HXxSaLgIC4sQjuW7iAYm6ltqiZlnlMy3LN02Jl59TJTnun3/m2nNN2MktNKzPNLMu0tDLLJUXBXdwQF1BUBEUUUGCu3x/3aIgsAwxzD/h5Ph7zYGbue+77w+345ppr7vu6lNYaIYQQtYuL2QUIIYSwPwl3IYSohSTchRCiFpJwF0KIWkjCXQghaiEJdyGEqIUk3IUQohaScBdCiFpIwl0IIWohN7N2XL9+fR0REWHW7oUQokZKSEg4pbUOLm8908I9IiKC+Ph4s3YvhBA1klLqsC3rSbeMEELUQhLuQghRC0m4CyFELWRan3tJ8vPzSU1NJS8vz+xSagVPT09CQ0Nxd3c3uxQhhIM5Vbinpqbi6+tLREQESimzy6nRtNZkZGSQmppKZGSk2eUIIRzMqbpl8vLyCAoKkmC3A6UUQUFB8ilIiGuUU4U7IMFuR3Ishbh2OV24CyFErXUmBVb9G9L3VvuunKrPXQghap3CfNi3HBI+haRfjOfqNoDg1tW6W2m5F3HmzBk++OCDCr9u0KBBnDlzpsKvGzt2LIsWLarw64QQNUDmQfjlZXi7PXw5Gk7sgj5PwZTt0HVite9eWu5FXAr3hx9++IrnCwsLcXV1LfV1P/zwQ3WXJoSoCQouwt5lkPAJJP8GygVa3grRY6DFzeDquMh12nB/+ftdJB47a9dttmvix4u3ty91+dSpUzlw4ACdOnXC3d2dunXr0rhxY7Zu3UpiYiJ33HEHKSkp5OXl8fjjjzNp0iTgz3Fyzp07x8CBA+nVqxd//PEHISEhfPfdd3h5eZVb28qVK3nyyScpKCiga9euTJ8+nTp16jB16lSWLFmCm5sbt9xyC//5z3/46quvePnll3F1dcXf35/Vq1fb7RgJISrhVBJs/hS2fgE5p8A/DPo+C53uBf8QU0py2nA3w2uvvcbOnTvZunUrv/32G7fddhs7d+68fJ747NmzCQwMJDc3l65du3LXXXcRFBR0xTb279/P/PnzmTlzJiNGjODrr79m9OjRZe43Ly+PsWPHsnLlSlq1asX999/P9OnTuf/++1m8eDF79uxBKXW56+eVV15hxYoVhISEVKo7SAhhB/l5sPt7I9QPrQHlCq0HQvQ4aN4XXEr/tO8IThvuZbWwHaVbt25XXAD03nvvsXjxYgBSUlLYv3//VeEeGRlJp06dAIiOjubQoUPl7mfv3r1ERkbSqlUrAMaMGcO0adOYPHkynp6eTJw4kdtuu43BgwcD0LNnT8aOHcuIESMYNmyYPX5VIYSt0vdBwhzYNh9yT0O9ptD/BaOV7tvI7Oouc9pwdwY+Pj6X7//222/88ssvrF+/Hm9vb2688cYSLxCqU6fO5fuurq7k5uaWux+tdYnPu7m5sXHjRlauXMmCBQt4//33+fXXX/nwww+Ji4tj2bJldOrUia1bt171R0YIUQ3StsHM/sb9NrdB9FiIvAFcnO/cFAn3Inx9fcnOzi5xWVZWFgEBAXh7e7Nnzx42bNhgt/22adOGQ4cOkZSURIsWLZg7dy433HAD586dIycnh0GDBtG9e3datGgBwIEDB4iNjSU2Npbvv/+elJQUCXchqpvFAsueBE9/eHAt+DU2u6IySbgXERQURM+ePenQoQNeXl40bNjw8rIBAwbw4YcfEhUVRevWrenevbvd9uvp6cmcOXP4y1/+cvkL1QcffJDMzEyGDh1KXl4eWmvefvttAJ566in279+P1pr+/fvTsWNHu9UihCjF9i8hdSMMed/pgx1AldYlUN1iYmJ08ZmYdu/eTdu2bU2pp7aSYyqEHeSdhf9FQ70wmPCLqd0wSqkErXVMeetJy10IIcrz++twPh3uWeCU/eslkXB3gEceeYR169Zd8dzjjz/OuHHjTKpICGGzk3sg7kPoch+ERJtdjc0k3B1g2rRpZpcghKgMreHHf4CHD/R/0exqKqRmfL4QQggzJH4HB3+Hvs+BT32zq6kQm8JdKTVAKbVXKZWklJpawvJwpdQqpdQWpdR2pdQg+5cqhBAOdDEHVjwLDTtAzHizq6mwcsNdKeUKTAMGAu2AUUqpdsVWew5YqLXuDIwEKj60ohBCOJO1b8HZVBj0pkMH/LIXW1ru3YAkrXWy1voisAAYWmwdDfhZ7/sDx+xXohBCOFhmMqx7D677CzTtYXY1lWJLuIcAKUUep1qfK+olYLRSKhX4AXjULtU5ubp16wJw7Ngxhg8fXuI6N954I8XP5y8qIiKCU6dOVUt9QohKWv5PcHWHm/9ldiWVZku4lzQRZ/Ern0YBn2itQ4FBwFyl1FXbVkpNUkrFK6Xi09PTK16tk2rSpIlMuiFEbbHvJ9j3ozGxRg24ErU0tnQkpQJhRR6HcnW3ywRgAIDWer1SyhOoD5wsupLWegYwA4wrVMvc649T4fgOG8qrgEbXwcDXSl389NNP07Rp08uTdbz00ksopVi9ejWnT58mPz+fV199laFDr+yVOnToEIMHD2bnzp3k5uYybtw4EhMTadu2rU0Dh13y1ltvMXv2bAAmTpzIlClTOH/+PCNGjCA1NZXCwkKef/557r777hLHeRdCVFHBBVj+NAS1gO4Pl7++E7Ml3DcBLZVSkcBRjC9M7ym2zhGgP/CJUqot4AnUuKb5yJEjmTJlyuVwX7hwIcuXL+eJJ57Az8+PU6dO0b17d4YMGYJSJX2ggenTp+Pt7c327dvZvn07Xbp0sWnfCQkJzJkzh7i4OLTWxMbGcsMNN5CcnEyTJk1YtmwZYAxglpmZWeI470KIKlr/vtHfPvobcPMwu5oqKTfctdYFSqnJwArAFZittd6llHoFiNdaLwH+DsxUSj2B0WUzVld10JoyWtjVpXPnzpw8eZJjx46Rnp5OQEAAjRs35oknnmD16tW4uLhw9OhRTpw4QaNGJY/bvHr1ah577DEAoqKiiIqKsmnfa9eu5c4777w8zPCwYcNYs2YNAwYM4Mknn+Tpp59m8ODB9O7dm4KCghLHeRdCVEHWUVj9H2gzGFr0N7uaKrPp/B6t9Q8YX5QWfe6FIvcTgZ72Lc0cw4cPZ9GiRRw/fpyRI0cyb9480tPTSUhIwN3dnYiIiBLHcS+qtFZ9WUr7W9iqVSsSEhL44YcfeOaZZ7jlllt44YUXShznXQhRBT89B9oCt/4/syuxC7lCtZiRI0eyYMECFi1axPDhw8nKyqJBgwa4u7uzatUqDh8+XObr+/Tpw7x58wDYuXMn27dvt2m/ffr04dtvvyUnJ4fz58+zePFievfuzbFjx/D29mb06NE8+eSTbN68mXPnzpGVlcWgQYN455132Lp1a5V/byGuaQfXwK5voOcUCIgwuxq7qHln5lez9u3bk52dTUhICI0bN+bee+/l9ttvJyYmhk6dOtGmTZsyX//QQw8xbtw4oqKi6NSpE926dbNpv126dGHs2LGX1584cSKdO3dmxYoVPPXUU7i4uODu7s706dPJzs4ucZx3IUQlFOYb48fUC4deU8yuxm5kPPdaTo6pEOXYMB2WT4W750Fb5//+ytbx3KVbRghx7Tp3Elb9G5r3M+ZErUWkW8ZBYmNjuXDhwhXPzZ07l+uuu86kioQQ/PIy5OfCwDegEidCODOnC3etdaXONnF2cXFxDt+nWV1uQtQIqfGw9XPo8RjUb2l2NXbnVN0ynp6eZGRkSCjZgdaajIwMPD09zS5FCOdjKYRlf4e6jeCGf5hdTbVwqpZ7aGgoqamp1KZxZ8zk6elJaGio2WUIYR+F+RA/G9ZPA+9AaNAeGraHhu2M+3WDbd/WlrmQthWGzYI6vtVXs4mcKtzd3d2JjIw0uwwhhLNJ+sUYqfHUXgi/HtzqwP4VRrfKJT7BRtg3uBT47SC4DXh4X7mtnEyjrz28B1xX8miutYFThbsQQlzhVBL89CzsWw4BkTDyC2g96M8vP8+lw8ldcCIRTuwy7sfPhgLrgH3KBQKbGUHf0NrS37sc8s7AoNr3JWpREu5CCOeTlwW/vwFxH4GbJ9z0MnR/yGixF1U3GOreCM1u/PM5SyFkHvwz9E/ughM7Yff3XB6tvOsDxiixtZiEuxDCeVgKYfNn8OurkJMBnUdDv+fBt6Ht23BxhfotjFu7IsNzXzwP6XuM4G9d+6d5lnAXQjiHQ2uNeRxO7DD61Qd8DU062W/7Hj4QEm3crgES7kIIc50+DD8/D4nfgX8YDJ8N7YfV6v5wR5BwF0KY48I5WPsW/PG+0ZXS91no8Si4e5ldWa0g4S6EcCyLBbZ/Cb+8BOeOw3Uj4KaXwD/E5MJqFwl3IYTjJP8OK1+GownQpAvcPRfCbBsWW1SMhLsQovqlbIJfX4GDq8G3CdzxIUTdDS5ONQJKrSLhLoSoPsd3GKc17lsO3vXh1v+DmPHgLmMeVTebwl0pNQB4F2OC7Fla69eKLX8b6Gt96A000FrXs2ehQoga5NR+WPX/YNdi8PQ3zlWPfRDq1DW7smtGueGulHIFpgE3A6nAJqXUEuuk2ABorZ8osv6jQOdqqFUI4exOH4bfX4dt88HNC3o/CT0mg1eA2ZVdc2xpuXcDkrTWyQBKqQXAUCCxlPVHAS/apzwhRI1wNg3W/AcSPjXGc4l9CHo9UbGRGoVd2RLuIUBKkcepQGxJKyqlmgKRwK9VL00I4fTOZ8C6t2HjTLAUQOf7oM9TclqjE7Al3Eu6TKy02TRGAou01oUlbkipScAkgPDwcJsKFEIUYSmEA6sgope5X0rmZRnjqq//AC6eM858ufFpYwRG4RRsCfdUIKzI41DgWCnrjgQeKW1DWusZwAyAmJgYmW5JiIpa9w6sfAUiesPIecaXlY5UWADr34e1bxvD5rYdYlxZ2qCNY+sQ5bIl3DcBLZVSkcBRjAC/p/hKSqnWQACw3q4VCiEMJ3fDb69Boyg4sh7m3AajF4FvI8fsPy8LvhoLB36FFjdDv+fsO7CXsKtyryDQWhcAk4EVwG5godZ6l1LqFaXUkCKrjgIWaJkAVQj7KyyA7x4Bj7ow+hu450vITIaPbzYmtKhumckw62bjIqQh/zP+qEiwOzVlVhbHxMTo+Ph4U/YtRI2z9h345UVjxMQOdxnPHU2AeX8x7t/7VfUNZXv4D1hwL6BhxFyI7F09+xE2UUolaK1jyltPrv0Vwtml74NV/4a2txtD4V4SEg3jfzLGKf/kdmOeUXvbMg8+HQLeQTBxpQR7DSLhLoQzsxTCdw8bkzzf9tbVY5zXbwETfjbOUvnibti+0E77tcDPLxr7jugJE3+GoOb22bZwCAl3IZzZhg8gdRMMfBPqNih5Hd9GMG6ZMXvRNw/AH/+r2j4vnoeF9xln5sSMh3sXyRWmNZCEuxDO6tR+Y9Ct1rfBdcPLXtfTH0Z/bcwZ+tNzxs1iqfg+s47C7AGw9wcY8LrxacHVvXL1C1PJqJBCOCNLoXF2jJsnDC6hO6YkbnVg+Bz48Wmj9X7uJAydZns4H02A+fcYLfd7FkLLm6v2OwhTSbgL4YziPoKUOLjzo4qdx+7iCoPeBN+GRqv//CkY8Vn5ozHuWgyLHzS6fu5bDA3bVa1+YTrplhHC2WQcMK5CbTXAuKy/opQyxne5/T1IXgWf3m6EfEm0ht/fNC5OatwJJv4qwV5LSLgL4UwsFmt3jAcMfse27pjSRI+Bu+fByUT4+BZjON6i8vPgm0mw6lWIGgljlsgojrWIhLsQzmTjDGNogQGvgV/jqm+vzSC4/zvIyTCuZj2+w3j+XLrRot+x0JhI484PjT57UWvUzHC/cM7sCoSwv8xkY/LoFjdDx1H22254dxi/HFzcYM4gY8z1mf2MoB/xGfR5smqfEIRTqnnhvnEmlve7Qk6m2ZUIYT8WC3z3qBHAt79r/7Bt0BYm/AR+TeD7x8CSD+N/NE6dFLVSjQv37zJCKcw+Sf63k40vg4SoDeI/hsNr4dZ/V99EF/6hMO5H6PscPPArNJHZMGuzGhfuzaN68GbBCNz3LYPNn5ldjhBVd/qQcal/8/7QeXT17ss7EG54ymjBi1qtxoV7hxB/cro8yDpLByw/Pm1cxSdETWWxwHeTjXlHh7wnfd/CbmpcuAP8/da2vOw6mfOFbuivJ0LBRbNLEqJyEubAoTVw66tGt4kQdlIjwz3Ax4P7bu3BkxcmotK2wm//NrskISru9GH4+QVodiN0GWN2NaKWqZHhDnBPt3CONOzPEpeb0GvfgYNrzC5J1HYFF4xJoaf3goX3G/dTEyr3yVFr46wVMGY2ku4YYWc1dmwZVxfFy0PaM+aje+hVbx+Bi/8KD62ToUmF/WkNid/CLy8ZX36GRMOxLZD4nbHczROadIHwWAiLhdBu4BNU9jY3fwrJv8Hgt6FeeDX/AuJaVGPDHaBbZCC3dGrGxJ1/5WuPF1HfT4G/fCKtIGE/R+Lgp2eNMdUbtDeG1W1xk7HsbJoxuFfKRuPnH++D5W1jWVBLI+jDuhkXEQW1BBfrB+UzKbDiOYjsA9HjzPm9RK1nU7grpQYA7wKuwCyt9WslrDMCeAnQwDat9T12rLNUzwxsS7/EE3zjP5a7EmfB1i+g872O2LWozTIOGC313UvAtzEMeR863WOMuniJX2Nof4dxA8jPNVr0lwJ/34+w9XNjmWc9I+jDYo0Wu7ZId4yoVuWGu1LKFZgG3AykApuUUku01olF1mkJPAP01FqfVkqVMmWM/TXy9+TRfi15ank+/cJ3EPDjP6wtJZkSTFTC+QxY/QZsmgWudaDvs3D9I8Y8peVx94KmPYwbGN05GQesYb/BCPz9PxnLBv0HAiKq7dcQQulyrvJUSl0PvKS1vtX6+BkArfX/FVnnDWCf1nqWrTuOiYnR8fHxlSq6uAsFhQx4Zw0NLOkssPwdFdTSGEtDZpARtsrPg40fwer/wsVs6HI/3PhPY1x0e8o9DZkHjatDpdUuKkEplaC1jilvPVvOlgkBUoo8TrU+V1QroJVSap1SaoO1G8dh6ri58sLt7YjL9Obn5v+Eo/Hw++uOLEHUVBYL7FgE73c1TksM7w4P/WGM72LvYAfjC/+QLhLsotrZ0ude0ruweHPfDWgJ3AiEAmuUUh201meu2JBSk4BJAOHh9j1DoG/rBtzUtgFP7HAl/rqReK35LzTv9+dHZCGKO7TWmGv02BZodB0M/c4451yIWsCWlnsqEFbkcShwrIR1vtNa52utDwJ7McL+ClrrGVrrGK11THCw/ScFeH5wO/Itmpcu3g/1mhoTEeSeKf+F4tpyar8xV+gntxnzjN75EUxaLcEuahVbwn0T0FIpFamU8gBGAkuKrfMt0BdAKVUfo5sm2Z6F2qJpkA+Tejfjyx1nSOzxXzh7DH540tFlCGd1PgN+eAqmxcLB1dD/BXg0ATqO/PM0RSFqiXLf0VrrAmAysALYDSzUWu9SSr2ilBpiXW0FkKGUSgRWAU9prTOqq+iyPNy3OU38PXnyDw8sN0yFHV/Bti/NKEU4i4IL8Mf/4L3OsOljiB4Lj22B3n83znARohYq92yZ6mLPs2WKW7r9GJO/2MKrQ9syevfDcHwnPLRWTj271mhtnKf+8wvGlaUtb4Gb/wUN2phdmRCVZs+zZWqc265rzPXNgvjPz0lkDZhmnJnwzSQoLDC7NOEoRzcbU8otvB/cvGD0N3DvVxLs4ppRK8NdKcVLQ9qTnVfAG3E5xvgdKXGw5r9mlyaqW9ZR+OavMLMvZOyHwe/Ag2uhRX+zKxPCoWr02DJlad3Il/u6N+XT9YcY1e1mOkTdbZz73ryvcRm4qF0unIN17xp969oCvf4GvZ4ATz+zKxPCFLWy5X7JEze3ItDbg5eW7EIPetOYDOHriZB31uzShL1YCmHzXPhfF2PYgDaD4NF4uOlFCXZxTavV4e7v5c4/BrQm/vBpvtt9DobNhKwUYxztnEyzyxNVlfw7zLgBlkw2hs2d8DMMny1D6ApBLQ93gL9Eh9Ex1J9//7Cbcw2jjfFCdi2GN1vAZ3dAwidw/pTZZYqKOLUf5o+Cz4ZAbpYR6BN+lu42IYqoladCFrflyGnu/OAP/npDM54Z2BaObTUmWkj8FjKTjcmJI3pBu6HQdgjUddiglsIW2SeMURWPWG9p28DdG/r8HWIfAndPsysUwmFsPRXymgh3gKe+2sa3W4+yfEofmgfXNZ7UGk7sNIJ+17fG2RUoaNrTGvS3G2N2C8exWODUPjiy3jjD6cgGOH3QWObmacyC1LQndJsEde0/hIUQzk7CvZj07Av0+89vdGkawCfjuqKKj8qnNZzcbW3RfwfpuwFljBJ4Kehldnr7y8+DY5v/bJWnxEGedTwg7/rG8Q/vDmHdoXFHcPMwt14hTCbhXoKP1x7kX0sTmXl/DDe3K2c41/S9kLjE6Lo5sdN4LrQrtLsD2txmXO0qw7ZWXGEBJP0Mh9cZU9ilbYVC6wTT9VsZMxWFd4fw6yGwmRxjIYqRcC9BfqGFQe+uIa+gkG8f7klQ3Tq2vfBUEuy2tujTthnPeQUaLcnGUcbPRh2NMJIBqEqXmWxcKZy6CVw9jAkrwmKNIA+LLX9SaSGEhHtp4g9lcu+sOMIDvfl8YiwN/Sr4ZVzmQUj6xQj549vhRCJY8o1lHnWhUVSRwI+C4NYyI5TWsOVzWD4VlCsMesP4BCRfhApRYRLuZVh/IIMJn24i2LcO8ybGEhrgXfmNFVw0+ufTtv8Z+Md3QH6Osdy1DjRsZ23lW1v4DdtdO6MRns+ApY/D7u8hojfcMR3qhZX/OiFEiSTcy7H5yGnGzN6Ibx035j3Qncj6NkyAbCtLoTExcto2OL7N+Jm2DfKyjOXu3hA9Dno+Br6N7LdfZ5P0C3z7sHHBWP8X4PrJ0m0lRBVJuNtg59Es7p+9ERelmDcxltaNfKtvZ1rDmSNGyO9ZZowz7+JmjC3e83HwLz4tbQ2Wnws/v2hMOB3cFu6aaUxjJ4SoMgl3G+0/kc29s+LIL7Tw2fhYrgv1d8yOM5NhzVuwbb5xEVXn0cZAVzX90vm0bfD1A3Bqr3GB0U0vXjtdUEI4gIR7BRzOOM89M+M4m5vPnHFdiYkIdNzOTx+Gde8Yg1+hoeMo6P0348ybmsRSaIzI+Our4B0Ed3wgw+wKUQ0k3Cvo6JlcRs+K43hWHh+PiaFHi/qOLSAr1RiyNuFTsBRA1Ajo/STUb+HYOirjTAosfhAOrzUu9rr9PfB24B9IIa4hEu6VcDI7j/tmbeRgxnk+HN2Ffm3KudCpOmQfh3XvQfxsKLwA7YdBn6ecdwah7V/Bsr+DLoSBb0Cne+TCIyGqkV2n2VNKDVBK7VVKJSmlppawfKxSKl0ptdV6m1iZos3WwNeTBZO607qhL3+dm8APO9IcX4RvIxjwb5iyA3o8Cnt/hA+6w8IxxlywziL3DCyaAN9MNP7wPLgWOt8rwS6Ekyi35a6UcgX2ATcDqcAmYJTWOrHIOmOBGK31ZFt37Iwt90vO5uUzbs4mthw5zZvDO3JXtIljypzPgA0fQNxHcDEb2gw2Qj+wudH14eLq+JoOrobFD8G543DjVOj5BLjW2km9hHAqtrbcbfkf2Q1I0lonWze8ABgKJJb5qhrMz9OduRO68cBn8fz9q23k5hcyuntTc4rxCYL+z0OPybDhQ4ibDnuWWhcq8AoAn/rGIFs+Qdaf9Yv8DPrzsXfQlQNvFeYbLfDc05CbafzMsf4s8bkzxnMXz0FQC5jwkzFKoxDC6dgS7iFASpHHqUBsCevdpZTqg9HKf0JrnVLCOjWGt4cbH4/pysPzNvPctzvJyy9kYm8Tz2DxCoC+z8D1D0PSSjifbkwyknPK+jMD0vdBzh/WWaZK+URWxx/q+MKFs8atNMrV2Oelm18TaNjeGFPHP8Q4P9/Djhd+CSHsypZwL6kTtXhyfA/M11pfUEo9CHwK9LtqQ0pNAiYBhIc7//ncnu6ufDg6mie+3Mqry3Zz/kIhj/VvcfVwwQ4tyh86DCt7HUuh0dK+IvxPGV08OaeMyaQ9/Y3Q9g60Bng9I7gvPefhK1eTClGD2RLuqUDRwUBCgWNFV9BaZxR5OBN4vaQNaa1nADPA6HOvUKUm8XBz4d2RnfB0d+XtX/aRk1/A1AFtzA348ri4Gl0xPg4+nVMI4TRsCfdNQEulVCRwFBgJ3FN0BaVUY631pVNLhgC77VqlydxcXXhzeBReHi589HsyZ3ML+MetrQnwkYkjhBDOqdxw11oXKKUmAysAV2C21nqXUuoVIF5rvQR4TCk1BCgAMoGx1VizKVxcFP8a2gEfDzc+Wp3M1wmpDLyuEfd0C6dbZKBzt+SFENccuYipEvYcP8v8uCN8s+Uo2XkFNA/2YVS3cO7qEiqteSFEtZIrVB0g92IhS7cfY/7GI2w+cgYPNxcGdWjEKGnNCyGqiYS7g+1OO8uCjdKaF0JULwl3k1xqzX+x8QhbirTm74ltSteIAGnNCyGqRMLdCexOO8v8jUdYvPko2RcKaNGgrrU1H0I9b2nNCyEqTsLdieRcLGDp9jTmW1vz3h6uPD2gDfd1b4qLi7TkhRC2k3B3UonHzvL68j38vi+d7s0CeeOujoQHVWGCbiHENcWuQ/4K+2nXxI9PxnXljbui2HX0LAPeXc1n6w9hsdSIC3aFEDWEhLsJlFKM6BrGiif6EBMRyAvf7eLeWXGkZOaYXZoQopaQcDdRk3pefDquK68Nu44dR7O49Z3VzN1wWFrxQogqk3A3mVKKkd3CWfFEH6KbBvD8tzsZ/bG04oUQVSPh7iRC6nnx2fhu/N+w69iemsWAd1bz+YbDmPWFtxCiZpNwdyJKKUZZW/GdwwN4ztqKTz0trXghRMVIuDuhkHpezJ3QjX/feR1bj5zh1rdXMy9OWvFCCNtJuDsppRT3xIazfEofOoXX49nFO7l/9kaOnsk1uzQhRA0g4e7kwgK9+XxCLK/BCaHsAAAWZUlEQVTe0YGEw6e59e3VLNh4xOyyhBBOTsK9BlBKMbp7U1ZM6UNUqD9Tv9nB7LUHzS5LCOHEJNxrkLBAb+ZOiOWWdg3517JEftp13OyShBBOSsK9hnF1Ubw7sjNRIf48tmAL21LOmF2SEMIJSbjXQF4erswa05X6desw4dN4ueBJCHEVm8JdKTVAKbVXKZWklJpaxnrDlVJaKVXuiGWiaoJ96/DJuK5cLChk3CebyMrNN7skIYQTKTfclVKuwDRgINAOGKWUalfCer7AY0CcvYsUJWvRwJcP74vmcMZ5HpybwMUCi9klCSGchC0t925AktY6WWt9EVgADC1hvX8BbwB5dqxPlKNH8/q8flcU65MzeOabHXKhkxACsC3cQ4CUIo9Trc9dppTqDIRprZfasTZho2FdQplyU0u+3pzKeyuTzC5HCOEE3GxYp6R54C43D5VSLsDbwNhyN6TUJGASQHh4uG0VCps83r8lRzJzePuXfYQGeHFXdKjZJQkhTGRLyz0VCCvyOBQ4VuSxL9AB+E0pdQjoDiwp6UtVrfUMrXWM1jomODi48lWLqyileG1YFNc3C2LqN9tZfyDD7JKEECayJdw3AS2VUpFKKQ9gJLDk0kKtdZbWur7WOkJrHQFsAIZora+9CVJN5uHmwof3RdM0yIe/zo0n6WS2XbdvsWiW7zzOS0t2sTvtrF23LYSwr3LDXWtdAEwGVgC7gYVa611KqVeUUkOqu0BRMf5e7swZ2xUPNxfGztlEevaFKm+z0KJZuv0Yg95bw4OfJ/Dp+kPc9t4anvlmB6fOVX37Qgj7U2adXRETE6Pj46VxX122pZzh7hnrad3QlwWTrsfLw7XC2ygotPD99mO8/2sSB9LP06JBXSb3bUHvlvV5f1USc9cfxsvdlcn9WjC2ZwR13Cq+DyFExSilErTW5V5LJOFei/206zh//TyBW9o15IN7o3F1Kem78avlF1pYvOUoH6xK4lBGDm0a+TK5XwsGdmh8xTYOpJ/j38t2s3LPScIDvXlmYBsGdGiEUrbtRwhRcRLuAoDZaw/yytJEJvSK5PnBV117doULBYUsSkhl+m8HSD2dS4cQPx7t15Kb2zbEpYw/DGv2p/Pq0t3sPZFNt8hAXhjcjg4h/vb+VYQQ2B7utpwKKWqw8b0iOZKZw8drDxIW4MXYnpFXrZOXX8iCjUf4aHUyaVl5dAqrxytD29O3dQObWuG9Wwaz7LEgFmxK4a2f93H7+2sZ3iWUp25tTQM/z+r4tYQQ5ZCW+zWg0KL569wEft1zghn3xXBTu4YA5Fws4Is4I9TTsy/QNSKAx/q3pFeL+pXuWjmbl8+0X5OYve4g7q4uPNK3BRN6ReLpLv3xQtiDdMuIK+RcLGDkjA3sP3GO2WO7sjXlDLPWJJNx/iI9mgfxaL+WdG8WaLf+8kOnzvN/P+5mxa4ThNTzYurANgyOaiz98UJUkYS7uMrJ7DzunPbH5XlYb2gVzGP9WxDdNLDa9rn+QAb/WppIYtpZopsG8PzgdnQKq1dt+xOitpNwFyVKOnmOT/84xF3RoQ4L2UKLZlFCCm+u2MepcxcY1jmEl4a2x8/T3SH7F6I2kXAXTufchQI+WJXEjNXJRNb3YfbYroQFeptdlhA1iq3hLjMxCYepW8eNfwxow2fju3HibB53frCOzUdOm12WELWShLtwuB4t6rP4kZ741HFj5IwNLNl2rPwXCSEqRMJdmKJ5cF0WP9yTTqH1eGz+Ft5buV8mGhHCjiTchWkCfTyYO7EbwzqH8NbP+/jbwm1cKCg0uywhagW5QlWYqo6bK/8d0ZFmwT7856d9pJ7O4aP7Ygj08TC7NCFqNGm5C9MppZjcryXv39OZbalZ3PnBOpJOnquWfVksmtTTOdWybSGciYS7cBqDo5qwYFJ3zl8oYNgH61iXdMpu207LyuW9lfvp8+Yqer2+ig9/P2C3bQvhjCTchVPpEh7A4od70sjfkzGzN7Jg45FKbyu/0MLynWmMm7ORnq/9yls/76NpkDd9Wwfz2o97mL32oB0rF8K5SJ+7cDphgd4seqgHk7/YwtRvdnDw1HmeHtCmzGGHizqQfo6Fm1L4enMqp85dpKFfHR7p24K/RIcRHuRNfqGFyV9s5pWliXi4uTC6e9Nq/o2EcDwJd+GU/DzdmT0mhleWJvLR6mQOnjrPOyM74e1R8ls292Ihy3aksXBTChsPZeLmoujXpgEju4XRp2Uwbq5/fkh1d3Xhf6O68NDnCTz37U48XF0Y0TWsxO0KUVPJ8APC6X2yzphwpF0TPz4e05WG1jHitdbsPHqWBZuOsGTrMbIvFBBZ34e7u4YxrEsIDXzLHks+L7+QBz6LZ23SKd4a0ZE7O4c64tcRokrsOraMUmoA8C7gCszSWr9WbPmDwCNAIXAOmKS1TixrmxLuoiJ+3XOCR7/Ygq+nO++M7MS+E9ks2JhCYtpZPN1dGHRdY+6OCaNbZMWGLc7LL2TcnE3EHczgvVGdGRzVpBp/CyGqzm7hrpRyBfYBNwOpwCZgVNHwVkr5aa3PWu8PAR7WWg8oa7sS7qKidqedZcInmziWlQdAhxA/7u4azpCOTfD3qvwIkzkXCxgzeyObj5zhg3u7cGv7RvYqWQi7s+c0e92AJK11snXDC4ChwOVwvxTsVj6AXEcu7K5tYz++faQn329PIzYy0G7ztHp7uDF7bFfu+3gjk7/YzEf3RdOvTUO7bFsIs9hyKmQIkFLkcar1uSsopR5RSh0A3gAes095QlypgZ8nE3pF2n0Cbl9Pdz4d3402jfx48PPNrNmfbtftC+FotoR7SR2YV7XMtdbTtNbNgaeB50rckFKTlFLxSqn49HT5zyOci7+XO5+N70az+j488Fk8G5IzzC5JiEqzJdxTgaLniYUCZY3RugC4o6QFWusZWusYrXVMcHCw7VUK4SABPh58PjGWsABvxn+yifhDmWaXJESl2BLum4CWSqlIpZQHMBJYUnQFpVTLIg9vA/bbr0QhHKt+3TrMmxhLQz9Pxs7ZxNaUM2aXJESFlRvuWusCYDKwAtgNLNRa71JKvWI9MwZgslJql1JqK/A3YEy1VSyEAzTw8+SLB2IJ9PHg/o/j2Hk0y+yShKgQuYhJiDKkns7h7o82cP5iAQsmdadNIz+zSxLXOJlDVQg7CA3w5osHYvF0c+XemXEkncw2uyQhbCLhLkQ5mgb5MO+BWJRS3DMzjoOnzptdkhDlkm4ZIWy070Q2I2dswEUpOoT44aoULi4KV6Vwdbl0nxKes95XClcXcHN1oW4dN/y93K+6+Xm54+fpdsVAZ0IUZc8rVIUQQKuGvnw+IZb/90MimecvUmjRFFo0Fn3pJyU8p4s8ZywvsFjILyy7UXUp/P283PH3csPP888/AIF1PejTMpj2TfwqNI6OuLZIy10IE+TlF5KVm//nLSefs3n5Vz6Xm8/Zyz8LLj+Xm29MIt6svg+DoxozuGMTWjX0Nfk3Eo4iLXchnJinuyue7q6Xhy+uiMzzF1m+8zhLtx/j/VVJvPdrEq0a1uX2qCYM7tiEyPo+1VCxqGmk5S5EDXYyO48fdxhBv+nQaQDaN/FjcFQTBkc1JizQ2+QKhb3ZdTz36iDhLoR9pWXlsmx7Gku3p12+qrZTWD0GRzXmtqjGNPb3MrlCYQ8S7kJcw1Iyc1i2I43vtx1j1zFjRO6uEQHc3rEJAzs0Jti3jskVisqScBdCAHDw1HmWbjvG0u1p7D2RjVLQqoEvXZrWo0t4ANFNA4is7yNn3tQQEu5CiKvsP5HNil3HiT98ms2HT3M2rwCAAG93uoQH0KVpAF3CA+gY5l/qZOTCXHK2jBDiKi0b+tLSetqkxaI5kH6OzUdOk3D4NJuPnGHlnpMAuLoo2jX2o0t4Pbo0NVr3IfW8pHVfg0jLXQhx2Zmci2w5cuZy4G9NOUPOReO8+ga+dYhuGkBUaD3quLlQaNHkWywUFmryLZqCQovxXKGm0GK5/FyBRVNQqK3LLCgFAzo0YnBUE9zlStwKk24ZIUSVFRRa2Hsim82H/2zdH8nMKXFdNxeFm6vCzcXF+tO47+qicHdV1p8uZOcVcPRMLo38PBnXM4JRseH4eVZ+gvNrjYS7EKJanM3Lx2LRuLm6WAPcCG5bu2wsFs3v+9KZsTqZ9ckZ+Hi4MrJbOON6RhAaIOfll0fCXQjh9HYezWLmmmSWbk8DYNB1jXmgdyRRofVMrsx5SbgLIWqMo2dy+WTdQeZvTOHchQJiIwN5oHcz+rVpgIuLfIlblIS7EKLGyc7L58tNKcxee5BjWXk0C/bhgd7NuLNzCJ7urmaX5xQk3IUQNVZ+oYUfdqQxc00yO4+eJcjHg/uub8p93ZsSVPfavrrWruGulBoAvAu4ArO01q8VW/43YCJQAKQD47XWh8vapoS7EKI8WmvWJ2cwa81Bft1zkjpuLgyPDuXxm1rSwLfiI2rWBnYLd6WUK7APuBlIBTYBo7TWiUXW6QvEaa1zlFIPATdqre8ua7sS7kKIikg6mc2sNQf5ZvNRfD3deP2uKG5q19DsshzOnhNkdwOStNbJWuuLwAJgaNEVtNartNaXTn7dAIRWtGAhhChLiwa+vHZXFMse60UDP08mfhbPPxfvIOdigdmlOSVbwj0ESCnyONX6XGkmAD9WpSghhChNy4a+fPtIDyb1acb8jUcY/N5adqRmmV2W07El3Es6D6nEvhyl1GggBnizlOWTlFLxSqn49PR026sUQogi6ri58s9BbZk3IZbc/ELu/GAd01YlUWgx5wQRZ2RLuKcCYUUehwLHiq+klLoJeBYYorW+UNKGtNYztNYxWuuY4ODgytQrhBCX9WhRn+WP9+HWDo14c8VeRs3YQOrpkodHuNbYEu6bgJZKqUillAcwElhSdAWlVGfgI4xgP2n/MoUQomT+3u68P6oz//1LRxLTzjLwnTV8u+Wo2WWZrtxw11oXAJOBFcBuYKHWepdS6hWl1BDram8CdYGvlFJblVJLStmcEELYnVKKu6JD+fHx3rRu5MuUL7fy2PwtZOXmm12aaeQiJiFErVJQaGH6bwd4Z+V+Gvl58t8RHeneLKjS29Nak5KZS8KRTOIPnWbP8Wy6Nwvkvu4RNPJ3/Ln2coWqEOKatjXlDFMWbOFwZg4P3tCcJ25qhYdb+T3RFwss7DqWRYJ1mOP4w6dJzza+Rqxbx43mwT5sP5qFq1LcFtWYcT0j6RTmuIHOJNyFENe88xcKeHVZIvM3ptAhxI937u5MiwZ1r1jnTM7FyyGecOg021LPcKHAAkBogBcxTQOIjggkOjyA1o18cXVRHMnI4dP1h/hykzHQWZfweozvFcmA9o1wq+YJSCTchRDCasWu40z9eju5+YX849Y21PV0I+HQaeIPZ3Ig/TxgTDbSvokf0U0DiYkwphZs6Fd2t0t2Xj6LElL55I9DHM7IobG/J/dfH8GobmHU8/aolt9Fwl0IIYo4eTaPJxdtZ/U+4xobfy93oq3zw0Y3DaBjaD28PCo38mShRbNqz0lmrzvIHwcy8HR3YViXUMb3jKBFA197/hoS7kIIUZzFotlwMIPgunVoHly3WsaK3512lk/WHWLx1qNcLLDQp1Uw43tG0KdlsF32J+EuhBAmyjh3gS/ijjB3w2FOZl+gWbAP43pGcleXELw93Cq9XQl3IYRwAhcLjLHpZ687yPbULPw83fjXHR0Y2qmsIbpKZ2u4V/7PhxBCiHJ5uLlwR+cQhnZqQsLh08xZd4iwwOqfCFzCXQghHEApRUxEIDERgQ7ZX/WekCmEEMIUEu5CCFELSbgLIUQtJOEuhBC1kIS7EELUQhLuQghRC0m4CyFELSThLoQQtZBpww8opdKBw5V8eX3glB3LsTepr2qkvqpz9hqlvsprqrUOLm8l08K9KpRS8baMrWAWqa9qpL6qc/Yapb7qJ90yQghRC0m4CyFELVRTw32G2QWUQ+qrGqmv6py9RqmvmtXIPnchhBBlq6ktdyGEEGVw6nBXSg1QSu1VSiUppaaWsLyOUupL6/I4pVSEA2sLU0qtUkrtVkrtUko9XsI6NyqlspRSW623FxxVn3X/h5RSO6z7vmraK2V4z3r8tiulujiwttZFjstWpdRZpdSUYus4/PgppWYrpU4qpXYWeS5QKfWzUmq/9WdAKa8dY11nv1JqjINqe1Mptcf677dYKVWvlNeW+V6o5hpfUkodLfLvOKiU15b5/70a6/uySG2HlFJbS3mtQ46h3WitnfIGuAIHgGaAB7ANaFdsnYeBD633RwJfOrC+xkAX631fYF8J9d0ILDXxGB4C6pexfBDwI6CA7kCcif/WxzHO3zX1+AF9gC7AziLPvQFMtd6fCrxewusCgWTrzwDr/QAH1HYL4Ga9/3pJtdnyXqjmGl8CnrThPVDm//fqqq/Y8v8CL5h5DO11c+aWezcgSWudrLW+CCwAhhZbZyjwqfX+IqC/Usr+05mXQGudprXebL2fDewGKjcponmGAp9pwwagnlKqsQl19AcOaK0re1Gb3WitVwOZxZ4u+j77FLijhJfeCvystc7UWp8GfgYGVHdtWuuftNYF1ocbgFB77rOiSjl+trDl/3uVlVWfNTtGAPPtvV8zOHO4hwApRR6ncnV4Xl7H+gbPAoIcUl0R1u6gzkBcCYuvV0ptU0r9qJRq79DCQAM/KaUSlFKTSlhuyzF2hJGU/h/KzON3SUOtdRoYf9SBBiWs4wzHcjzGJ7GSlPdeqG6TrV1Hs0vp1nKG49cbOKG13l/KcrOPYYU4c7iX1AIvfmqPLetUK6VUXeBrYIrW+myxxZsxuho6Av8DvnVkbUBPrXUXYCDwiFKqT7HlznD8PIAhwFclLDb7+FWEqcdSKfUsUADMK2WV8t4L1Wk60BzoBKRhdH0UZ/p7ERhF2a12M49hhTlzuKcCYUUehwLHSltHKeUG+FO5j4SVopRyxwj2eVrrb4ov11qf1Vqfs97/AXBXStV3VH1a62PWnyeBxRgffYuy5RhXt4HAZq31ieILzD5+RZy41F1l/XmyhHVMO5bWL28HA/dqa+dwcTa8F6qN1vqE1rpQa20BZpayb1Pfi9b8GAZ8Wdo6Zh7DynDmcN8EtFRKRVpbdyOBJcXWWQJcOithOPBraW9ue7P2z30M7NZav1XKOo0ufQeglOqGcbwzHFSfj1LK99J9jC/edhZbbQlwv/Wsme5A1qXuBwcqtbVk5vErpuj7bAzwXQnrrABuUUoFWLsdbrE+V62UUgOAp4EhWuucUtax5b1QnTUW/R7nzlL2bcv/9+p0E7BHa51a0kKzj2GlmP2Nblk3jLM59mF8i/6s9blXMN7IAJ4YH+eTgI1AMwfW1gvjY+N2YKv1Ngh4EHjQus5kYBfGN/8bgB4OrK+Zdb/brDVcOn5F61PANOvx3QHEOPjf1xsjrP2LPGfq8cP4Q5MG5GO0JidgfI+zEthv/RloXTcGmFXkteOt78UkYJyDakvC6Ku+9B68dPZYE+CHst4LDjx+c63vr+0Ygd24eI3Wx1f9f3dEfdbnP7n0viuyrinH0F43uUJVCCFqIWfulhFCCFFJEu5CCFELSbgLIUQtJOEuhBC1kIS7EELUQhLuQghRC0m4CyFELSThLoQQtdD/B8KzQucvDm7OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot([tr_loss for tr_loss, valid_loss in learning_curve]);\n",
    "plot([valid_loss for tr_loss, valid_loss in learning_curve]);\n",
    "legend(['train_loss', 'valid_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (9): ReLU()\n",
       "  (10): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (11): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([model(torch.from_numpy(xseq).float()).detach().numpy() for xseq in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = 1 * (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74      4579\n",
      "           1       0.77      0.82      0.79      5421\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {0 : 0, 1: 1}\n",
    "\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a32098ef0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(200)\n",
    "plot(X_test[i], 'o')\n",
    "plot(y_test[i] + 0.05, 'ro')\n",
    "plot(y_pred[i] + 0.1, 'ko')\n",
    "legend(['observations', 'labels', 'NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training MPNN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size, D_in, D_hidden = 256, T, T\n",
    "D_out = 3 # J is one parameter, b is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, D_hidden),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(D_hidden, D_out),\n",
    "          torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "optimizer = optim.Adam(energy_model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "energy_model.train()\n",
    "learning_curve = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    for batch in trainloader:\n",
    "        X_batch, y_batch = Variable(batch['X']), Variable(batch['y'])\n",
    "        energy_model.zero_grad()\n",
    "        \n",
    "        energy = energy_model(X_batch)\n",
    "        j, b = energy[:, 0], energy[:, 1:]\n",
    "        print(j.mean(0).detach(), b.mean(0).detach())\n",
    "        loss = belief_propagation_cross_entropy_loss(j, b, X_batch, y_batch)\n",
    "        print(\"ACTUAL::\", belief_propagation_cross_entropy_loss(j_real, b_real, X_batch, y_batch))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            valid = next(iter(validloader))\n",
    "            X_valid, y_valid = Variable(valid['X']), Variable(valid['y']) \n",
    "            energy_valid = energy_model(X_valid)\n",
    "            j_valid, b_valid = energy_valid[:, 0], energy_valid[:, 1:]\n",
    "            loss_valid = belief_propagation_cross_entropy_loss(j_valid, b_valid, X_valid, y_valid)\n",
    "\n",
    "            print('epoch {}:: loss = {}, validation loss = {}'. format(epoch, loss, loss_valid))\n",
    "            learning_curve.append((loss, loss_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=3, bias=True)\n",
       "  (3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_pred = energy_model(torch.from_numpy(X_test).float()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = energy_pred[:, 0]\n",
    "b = energy_pred[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = belief_propagation_cross_entropy_loss(j, b, X_test, torch.Tensor(y_test), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0 : 0, 1: 1}\n",
    "\n",
    "predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "truths = np.array([labels[tag] for row in y_test for tag in row])\n",
    "\n",
    "print(classification_report(\n",
    "    truths, predictions,\n",
    "    target_names=[\"0\", \"1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### backout of efficient implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belief_propagation_cross_entropy_loss_efficient(j, b, observations, labels):\n",
    "    batch_size = labels.size()[0]\n",
    "    len_ = T # length of chain\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for b_idx in range(batch_size):\n",
    "\n",
    "        values = torch.Tensor([0, 1]) - 0.5\n",
    "        pairs = torch.mul(values.view(-1, 2).t(), values)\n",
    "        unit_msg = torch.ones([2, 1])\n",
    "        \n",
    "        forward_messages = torch.Tensor()\n",
    "        msg_left = unit_msg # no information traveling left to x1\n",
    "        # forward pass    \n",
    "        for i in range(0, len_ - 1):\n",
    "            \n",
    "            phi = torch.exp(torch.mul(b[b_idx][int(observations[b_idx][i])], values))\n",
    "            psi = torch.exp(torch.mul(j[b_idx], pairs))\n",
    "  \n",
    "            step1 = torch.mul(phi, msg_left.t())\n",
    "            step2 = torch.mul(step1, psi)\n",
    "            step3, _ = torch.max(step2, dim=1)\n",
    "\n",
    "            msg = step3.view(-1 ,1)\n",
    "            msg_with_data_term = torch.mul(phi.view(-1, 1), msg_left)\n",
    "            \n",
    "            forward_messages = torch.cat((forward_messages, msg_with_data_term), dim=1)    \n",
    "            msg_left = msg\n",
    "        \n",
    "        msg_with_data_term = torch.mul(phi.view(-1, 1), msg_left)\n",
    "        forward_messages = torch.cat((forward_messages, msg_with_data_term), dim=1) # last message\n",
    "        \n",
    "        backward_messages = unit_msg\n",
    "        msg_right = unit_msg # no information traveling right to x_n\n",
    "        # backward pass    \n",
    "        for i in range(len_ - 1, 0, -1):\n",
    "\n",
    "            phi = torch.exp(torch.mul(b[b_idx][int(observations[b_idx][i])], values))\n",
    "            psi = torch.exp(torch.mul(j[b_idx], pairs))\n",
    "            step1 = torch.mul(phi, msg_right.t())\n",
    "            step2 = torch.mul(step1, psi)\n",
    "            step3, _ = torch.max(step2, dim=1)\n",
    "\n",
    "            msg = step3.view(-1 ,1)\n",
    "            backward_messages = torch.cat((msg, backward_messages), dim=1)    \n",
    "            msg_right = msg\n",
    "\n",
    "        # calculate beliefs\n",
    "        messages = torch.mul(forward_messages, backward_messages)\n",
    "\n",
    "        norm_ = torch.norm(messages, p=1, dim=0)  # L1 norm\n",
    "        beliefs_norm = torch.div(messages, norm_)\n",
    "        beliefs_softmax = torch.softmax(beliefs_norm, dim=0)\n",
    "        loss += F.binary_cross_entropy(beliefs_softmax[1, :], labels[b_idx])\n",
    "        \n",
    "    return loss #, beliefs_norm[1, :] > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity - check that we can reach loss zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(1000)\n",
    "j = np.array([1])\n",
    "b = np.array([-0.32, 0.4])\n",
    "labels = y_dataset[ind]\n",
    "observations = X_dataset[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), (2,), (50,), (50,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.shape, b.shape, labels.shape, observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = np.expand_dims(j, axis=0)\n",
    "b = np.expand_dims(b, axis=0)\n",
    "labels = np.expand_dims(labels, axis=0)\n",
    "observations = np.expand_dims(observations, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = torch.Tensor(j)\n",
    "b = torch.Tensor(b)\n",
    "labels = torch.Tensor(labels)\n",
    "observations = torch.Tensor(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 ms, sys: 1.55 ms, total: 17.3 ms\n",
      "Wall time: 16.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)\n",
    "beliefs = belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T, train=False)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5671),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1]], dtype=torch.uint8),\n",
       " tensor(1, dtype=torch.uint8))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, torch.eq(labels, beliefs.float()), torch.all(torch.eq(labels, beliefs.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss as a function of b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'b0': [], 'b1': [], 'loss': []}\n",
    "\n",
    "for i_sample in range(1000):\n",
    "    labels = y_dataset[1]\n",
    "    observations = X_dataset[1]\n",
    "    j = 1  \n",
    "    b_base = 2 * (np.random.rand(2) - 0.5)\n",
    "  \n",
    "    j = np.expand_dims(j, axis=0)\n",
    "    b = np.expand_dims(b_base, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)\n",
    "    observations = np.expand_dims(observations, axis=0)\n",
    "    \n",
    "    j = torch.Tensor(j)\n",
    "    b = torch.Tensor(b)\n",
    "    labels = torch.Tensor(labels)\n",
    "    observations = torch.Tensor(observations)\n",
    "    \n",
    "    res['b0'].append(b_base[0])\n",
    "    res['b1'].append(b_base[1])\n",
    "    res['loss'].append(float(belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)))\n",
    "\n",
    "# make sure real values are on the graph\n",
    "b_base = [-0.32, 0.4]\n",
    "b = np.expand_dims(b_base, axis=0)\n",
    "b = torch.Tensor(b)\n",
    "res['b0'].append(b_base[0])\n",
    "res['b1'].append(b_base[1])\n",
    "res['loss'].append(float(belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df, x=\"b0\", y=\"b1\", z=\"loss\", color=\"loss\",\n",
    "                 hover_data=['b0', 'b1', 'loss'])\n",
    "fig.write_html('loss_vs_data_term.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing the same as a function of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'b0': [], 'b1': [], 'j': [], 'loss': []}\n",
    "\n",
    "for i_sample in range(1000):\n",
    "    labels = y_dataset[1]\n",
    "    observations = X_dataset[1]\n",
    "    \n",
    "    j_val = np.random.rand() + 0.5\n",
    "    b_base = 2 * (np.random.rand(2) - 0.5)\n",
    "    \n",
    "    b = np.expand_dims(b_base, axis=0)\n",
    "    j = np.expand_dims(j_val, axis=0)\n",
    "    labels = np.expand_dims(labels, axis=0)\n",
    "    observations = np.expand_dims(observations, axis=0)\n",
    "    \n",
    "    j = torch.Tensor(j)\n",
    "    b = torch.Tensor(b)\n",
    "    labels = torch.Tensor(labels)\n",
    "    observations = torch.Tensor(observations)\n",
    "    \n",
    "    res['b0'].append(b_base[0])\n",
    "    res['b1'].append(b_base[1])\n",
    "    res['j'].append(j_val)\n",
    "    res['loss'].append(float(belief_propagation_cross_entropy_loss(j, b, observations, labels, chain_len=T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b0</th>\n",
       "      <th>b1</th>\n",
       "      <th>j</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090164</td>\n",
       "      <td>-0.328447</td>\n",
       "      <td>0.665573</td>\n",
       "      <td>0.811473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294405</td>\n",
       "      <td>0.163597</td>\n",
       "      <td>1.357335</td>\n",
       "      <td>0.575703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768406</td>\n",
       "      <td>-0.701573</td>\n",
       "      <td>0.826904</td>\n",
       "      <td>0.778174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.640219</td>\n",
       "      <td>-0.255443</td>\n",
       "      <td>1.000309</td>\n",
       "      <td>0.670103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.166367</td>\n",
       "      <td>-0.980200</td>\n",
       "      <td>0.997439</td>\n",
       "      <td>0.924915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.254867</td>\n",
       "      <td>0.557632</td>\n",
       "      <td>0.574188</td>\n",
       "      <td>0.608870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.518469</td>\n",
       "      <td>0.773864</td>\n",
       "      <td>1.273343</td>\n",
       "      <td>0.547626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.117375</td>\n",
       "      <td>0.713426</td>\n",
       "      <td>1.154906</td>\n",
       "      <td>0.563393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.843897</td>\n",
       "      <td>0.160723</td>\n",
       "      <td>0.730916</td>\n",
       "      <td>0.604344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.599323</td>\n",
       "      <td>0.096696</td>\n",
       "      <td>1.267062</td>\n",
       "      <td>0.865352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.624101</td>\n",
       "      <td>-0.329190</td>\n",
       "      <td>1.343289</td>\n",
       "      <td>0.674779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.878865</td>\n",
       "      <td>-0.886040</td>\n",
       "      <td>1.045779</td>\n",
       "      <td>0.954345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.490426</td>\n",
       "      <td>-0.615959</td>\n",
       "      <td>0.866116</td>\n",
       "      <td>0.899202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.070756</td>\n",
       "      <td>-0.150041</td>\n",
       "      <td>0.566140</td>\n",
       "      <td>0.792885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.216931</td>\n",
       "      <td>-0.063722</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.782594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.093667</td>\n",
       "      <td>-0.283081</td>\n",
       "      <td>0.778705</td>\n",
       "      <td>0.838945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.596789</td>\n",
       "      <td>0.820830</td>\n",
       "      <td>1.464748</td>\n",
       "      <td>0.559547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.157004</td>\n",
       "      <td>0.712135</td>\n",
       "      <td>0.592145</td>\n",
       "      <td>0.587783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.050683</td>\n",
       "      <td>0.521987</td>\n",
       "      <td>1.251693</td>\n",
       "      <td>0.560285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.061211</td>\n",
       "      <td>0.821241</td>\n",
       "      <td>1.430845</td>\n",
       "      <td>0.554475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.392045</td>\n",
       "      <td>0.068510</td>\n",
       "      <td>0.955102</td>\n",
       "      <td>0.596572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.071748</td>\n",
       "      <td>0.123086</td>\n",
       "      <td>0.508936</td>\n",
       "      <td>0.627664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.120642</td>\n",
       "      <td>0.343796</td>\n",
       "      <td>0.586321</td>\n",
       "      <td>0.604806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.614600</td>\n",
       "      <td>-0.744414</td>\n",
       "      <td>1.279660</td>\n",
       "      <td>0.843241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.306057</td>\n",
       "      <td>-0.634771</td>\n",
       "      <td>1.321900</td>\n",
       "      <td>0.943823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.107058</td>\n",
       "      <td>-0.105753</td>\n",
       "      <td>1.484414</td>\n",
       "      <td>0.688940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.614971</td>\n",
       "      <td>-0.825196</td>\n",
       "      <td>1.157282</td>\n",
       "      <td>0.838354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.516094</td>\n",
       "      <td>-0.038394</td>\n",
       "      <td>0.948955</td>\n",
       "      <td>0.609363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.914858</td>\n",
       "      <td>0.234640</td>\n",
       "      <td>1.382248</td>\n",
       "      <td>0.575882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.851696</td>\n",
       "      <td>0.984404</td>\n",
       "      <td>0.599800</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>-0.436863</td>\n",
       "      <td>0.303083</td>\n",
       "      <td>1.285356</td>\n",
       "      <td>0.681425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>0.518182</td>\n",
       "      <td>-0.453185</td>\n",
       "      <td>0.528659</td>\n",
       "      <td>0.745115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>0.730334</td>\n",
       "      <td>0.322891</td>\n",
       "      <td>1.466802</td>\n",
       "      <td>0.570490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>0.580759</td>\n",
       "      <td>0.459338</td>\n",
       "      <td>0.793396</td>\n",
       "      <td>0.586067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.211353</td>\n",
       "      <td>-0.936812</td>\n",
       "      <td>0.965041</td>\n",
       "      <td>0.887490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>-0.082354</td>\n",
       "      <td>-0.718081</td>\n",
       "      <td>1.238591</td>\n",
       "      <td>0.931201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.200649</td>\n",
       "      <td>0.780542</td>\n",
       "      <td>1.183532</td>\n",
       "      <td>0.562006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>-0.839438</td>\n",
       "      <td>-0.952547</td>\n",
       "      <td>1.281417</td>\n",
       "      <td>0.977569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>-0.644515</td>\n",
       "      <td>-0.888251</td>\n",
       "      <td>0.533870</td>\n",
       "      <td>0.886186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>-0.080528</td>\n",
       "      <td>-0.468065</td>\n",
       "      <td>1.086857</td>\n",
       "      <td>0.896246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-0.993770</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>1.405043</td>\n",
       "      <td>0.893839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>0.551191</td>\n",
       "      <td>0.893366</td>\n",
       "      <td>0.553955</td>\n",
       "      <td>0.579050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-0.429426</td>\n",
       "      <td>-0.810593</td>\n",
       "      <td>0.652571</td>\n",
       "      <td>0.884754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>0.841011</td>\n",
       "      <td>0.721164</td>\n",
       "      <td>1.459912</td>\n",
       "      <td>0.562702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>0.314571</td>\n",
       "      <td>0.698451</td>\n",
       "      <td>0.960457</td>\n",
       "      <td>0.571150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>-0.410489</td>\n",
       "      <td>0.844609</td>\n",
       "      <td>0.710962</td>\n",
       "      <td>0.595574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.128932</td>\n",
       "      <td>-0.748287</td>\n",
       "      <td>0.736610</td>\n",
       "      <td>0.853457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>-0.585142</td>\n",
       "      <td>0.264183</td>\n",
       "      <td>0.960598</td>\n",
       "      <td>0.738441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>-0.493110</td>\n",
       "      <td>0.778773</td>\n",
       "      <td>0.895126</td>\n",
       "      <td>0.590396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>-0.194920</td>\n",
       "      <td>0.153910</td>\n",
       "      <td>0.983524</td>\n",
       "      <td>0.659889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>-0.326255</td>\n",
       "      <td>0.547607</td>\n",
       "      <td>0.642106</td>\n",
       "      <td>0.612676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-0.697589</td>\n",
       "      <td>-0.551317</td>\n",
       "      <td>0.749472</td>\n",
       "      <td>0.888207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>0.112887</td>\n",
       "      <td>-0.286097</td>\n",
       "      <td>1.275719</td>\n",
       "      <td>0.889084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.947648</td>\n",
       "      <td>0.445795</td>\n",
       "      <td>1.043755</td>\n",
       "      <td>0.578791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-0.323417</td>\n",
       "      <td>-0.529746</td>\n",
       "      <td>1.364003</td>\n",
       "      <td>0.942208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.439486</td>\n",
       "      <td>-0.043872</td>\n",
       "      <td>1.437057</td>\n",
       "      <td>0.917240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.343217</td>\n",
       "      <td>-0.250082</td>\n",
       "      <td>1.030316</td>\n",
       "      <td>0.882496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.725647</td>\n",
       "      <td>-0.304922</td>\n",
       "      <td>1.339887</td>\n",
       "      <td>0.655820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.201295</td>\n",
       "      <td>-0.703504</td>\n",
       "      <td>0.805765</td>\n",
       "      <td>0.884480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.182571</td>\n",
       "      <td>-0.784148</td>\n",
       "      <td>0.680323</td>\n",
       "      <td>0.842619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           b0        b1         j      loss\n",
       "0    0.090164 -0.328447  0.665573  0.811473\n",
       "1    0.294405  0.163597  1.357335  0.575703\n",
       "2    0.768406 -0.701573  0.826904  0.778174\n",
       "3    0.640219 -0.255443  1.000309  0.670103\n",
       "4   -0.166367 -0.980200  0.997439  0.924915\n",
       "5   -0.254867  0.557632  0.574188  0.608870\n",
       "6   -0.518469  0.773864  1.273343  0.547626\n",
       "7    0.117375  0.713426  1.154906  0.563393\n",
       "8    0.843897  0.160723  0.730916  0.604344\n",
       "9   -0.599323  0.096696  1.267062  0.865352\n",
       "10   0.624101 -0.329190  1.343289  0.674779\n",
       "11  -0.878865 -0.886040  1.045779  0.954345\n",
       "12  -0.490426 -0.615959  0.866116  0.899202\n",
       "13  -0.070756 -0.150041  0.566140  0.792885\n",
       "14  -0.216931 -0.063722  0.510051  0.782594\n",
       "15  -0.093667 -0.283081  0.778705  0.838945\n",
       "16   0.596789  0.820830  1.464748  0.559547\n",
       "17  -0.157004  0.712135  0.592145  0.587783\n",
       "18  -0.050683  0.521987  1.251693  0.560285\n",
       "19   0.061211  0.821241  1.430845  0.554475\n",
       "20   0.392045  0.068510  0.955102  0.596572\n",
       "21  -0.071748  0.123086  0.508936  0.627664\n",
       "22   0.120642  0.343796  0.586321  0.604806\n",
       "23   0.614600 -0.744414  1.279660  0.843241\n",
       "24  -0.306057 -0.634771  1.321900  0.943823\n",
       "25   0.107058 -0.105753  1.484414  0.688940\n",
       "26   0.614971 -0.825196  1.157282  0.838354\n",
       "27   0.516094 -0.038394  0.948955  0.609363\n",
       "28   0.914858  0.234640  1.382248  0.575882\n",
       "29  -0.851696  0.984404  0.599800  0.631579\n",
       "..        ...       ...       ...       ...\n",
       "970 -0.436863  0.303083  1.285356  0.681425\n",
       "971  0.518182 -0.453185  0.528659  0.745115\n",
       "972  0.730334  0.322891  1.466802  0.570490\n",
       "973  0.580759  0.459338  0.793396  0.586067\n",
       "974  0.211353 -0.936812  0.965041  0.887490\n",
       "975 -0.082354 -0.718081  1.238591  0.931201\n",
       "976  0.200649  0.780542  1.183532  0.562006\n",
       "977 -0.839438 -0.952547  1.281417  0.977569\n",
       "978 -0.644515 -0.888251  0.533870  0.886186\n",
       "979 -0.080528 -0.468065  1.086857  0.896246\n",
       "980 -0.993770  0.113100  1.405043  0.893839\n",
       "981  0.551191  0.893366  0.553955  0.579050\n",
       "982 -0.429426 -0.810593  0.652571  0.884754\n",
       "983  0.841011  0.721164  1.459912  0.562702\n",
       "984  0.314571  0.698451  0.960457  0.571150\n",
       "985 -0.410489  0.844609  0.710962  0.595574\n",
       "986  0.128932 -0.748287  0.736610  0.853457\n",
       "987 -0.585142  0.264183  0.960598  0.738441\n",
       "988 -0.493110  0.778773  0.895126  0.590396\n",
       "989 -0.194920  0.153910  0.983524  0.659889\n",
       "990 -0.326255  0.547607  0.642106  0.612676\n",
       "991 -0.697589 -0.551317  0.749472  0.888207\n",
       "992  0.112887 -0.286097  1.275719  0.889084\n",
       "993  0.947648  0.445795  1.043755  0.578791\n",
       "994 -0.323417 -0.529746  1.364003  0.942208\n",
       "995 -0.439486 -0.043872  1.437057  0.917240\n",
       "996 -0.343217 -0.250082  1.030316  0.882496\n",
       "997  0.725647 -0.304922  1.339887  0.655820\n",
       "998 -0.201295 -0.703504  0.805765  0.884480\n",
       "999  0.182571 -0.784148  0.680323  0.842619\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter_3d(df, x=\"b0\", y=\"b1\", z=\"j\", color=\"loss\",\n",
    "                 hover_data=['b0', 'b1', 'j', 'loss'],\n",
    "                   )\n",
    "fig.write_html('loss_vs_all.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
